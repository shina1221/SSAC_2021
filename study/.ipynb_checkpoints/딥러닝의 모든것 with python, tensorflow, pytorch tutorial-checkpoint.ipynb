{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d8f2087",
   "metadata": {},
   "source": [
    "- 뉴런 : 뉴런은 입력값과 출력값이 있음\n",
    "\n",
    "범주형 범주가 output value가 될 경우\n",
    "출력값이 1개가 아니라 여러개가 될 수 있음\n",
    "이는 범주를 나타내는 더미변수이기 때문\n",
    "\n",
    "#함수와 가중치의 합\n",
    "\n",
    "batch gradient descent\n",
    "\n",
    "stochastic gradient descent (SGD) 확률적 경사하강법\n",
    "한번에 한 열을 실행하고 가중치 조정\n",
    "local extraneural 또는 local minimum 문제를 피하는데 적합\n",
    "\n",
    "한번에 모든 열을 하나씩 하기 때문에 Batch gradient descent보다 빠름\n",
    "모든 데이터를 메모리에 로드하지 않고 해당 열이 모두 실행될 때까지\n",
    "실행하고 기다릴 필요가 없기 때문\n",
    "\n",
    "무작위로 가능한 열을 선택하고\n",
    "확률적인 방법으로 신경망을 업데이트\n",
    "\n",
    "미니 배치 경사하강법\n",
    "열의 개수를 5, 10, 100, ...k개\n",
    "한번에 이 수의 열을 실행한 다음 가중치를 업데이트\n",
    "\n",
    "역전파\n",
    "이 알고리즘은 모든 가중치가 동시에 조정되게 함\n",
    "만약 수동으로 하게 하거나 다른 알고리즘 타입도 생각해내야 한다면\n",
    "우리가 아무리 오류를 산출해내고\n",
    "모든 가중치가 오류에 어떤 영향을 주는지 이해를 해야한다면\n",
    "모든 가중치를 독립적이거나 각각 따로 조정해야함.\n",
    "역전파의 가장 큰 장점은\n",
    "역전파 과정동안\n",
    "다른 이유없이 그저 알고리즘 구조상의 이유로 모든 가중치를 한번에 조정할 수 있게됨\n",
    "그래서 신경망에 있는 각각의 가중치를 한번에 조정할 수 있게됨\n",
    "그래서 신경망에 있는 각각의 가중치에 오류가 문제가 있는지 알수 있는 것임\n",
    "\n",
    "모든 가중치를 동시에 조정\n",
    "\n",
    "신경파 과정\n",
    "1. 무작위로 가중치들을 0은 아니지만 0과 가까운 숫자로 설정\n",
    "가중치는 어느시점에서든 실행되어야 하기 때문\n",
    "\n",
    "역전파 과정동안 이 가중치들은 오류가 최소화 될때까지 조정됨\n",
    "=비용함수가 최소화 될 때까지\n",
    "\n",
    "2. 데이터셋의 첫번째 관측값을 input layer에 입력\n",
    "각각의 feature는 1개의 inputnode가 됨\n",
    "행을 input node에 넣음\n",
    " \n",
    "3. 왼쪽에서 오른쪽으로 뉴런들은 가중치에 의해 제안되면서 최종적으로 y_hat이 나올때가지 각 뉴런의 활성화 과정에 영향을 미침 \n",
    "가중치가 각 뉴런 활성화를 결정\n",
    "\n",
    "4. 실제 결과와 예측 결과 비교하고 오류를 측정\n",
    "\n",
    "5. 오른쪽에서 왼쪽으로 역전파\n",
    "가중치를 오류에 얼마만틈 책임이 있느냐에 따라 업데이트\n",
    "학습률에 따라 가중치의 업데이트률이 정해짐\n",
    "학습률은 신경망안에서 제어할 수 있는 파라미터를 말함\n",
    "\n",
    "6. 5번째 단계를 다시한번 반복하고 각 관측치에 따라 가중치를 업데이트\n",
    "이를 강화형 기계학습 혹은 강화학습이라 함.\n",
    "배치관찰 후에만 가중치를 업데이트하면 배치학습\n",
    "\n",
    "7. 전체 훈련 세트가 인공신경망을 지나 계속해서 더 많은 에포크를 생성\n",
    "계속해서 반복적으로 훈련하며 신경망이 훈련되고 비용함수를 최소화하며 \n",
    "지속적으로 스스로를 조정하게 됨.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fb2a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a5d45a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad2e474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4766f260",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
