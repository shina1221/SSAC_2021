{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fdac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#딥러닝을 이용한 자연어 처리\n",
    "\"\"\"\n",
    "텍스트의 토큰화\n",
    ":입력된 텍스트를 잘게 나누는 과정\n",
    "\n",
    "토큰\n",
    ":입력할 텍스트가 준비되면 이를 단어별, 문장별, 형태소별로 나눌 수 있는데, 이렇게 작게 나누어진 하나의 단위\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e3ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#케라스에서는 text_to_word_sequence를 통해 손쉽게 토크나이저 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8dc395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#텍스트의 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acbd0eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['해보지', '않으면', '해낼수', '없다']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "text='해보지 않으면 해낼수 없다'\n",
    "result= text_to_word_sequence(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08b2c610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('먼저', 1), ('텍스트의', 2), ('각', 1), ('단어를', 1), ('나누어', 1), ('토큰화합니다', 1), ('단어로', 1), ('토큰화해야', 1), ('딥러닝에서', 2), ('인식됩니다', 1), ('토큰화한', 1), ('결과는', 1), ('사용할', 1), ('수', 1), ('있습니다', 1)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "docs= ['먼저 텍스트의 각 단어를 나누어 토큰화합니다.',\n",
    "      '텍스트의 단어로 토큰화해야 딥러닝에서 인식됩니다.',\n",
    "      '토큰화한 결과는 딥러닝에서 사용할 수 있습니다.']\n",
    "\n",
    "token=Tokenizer()\n",
    "token.fit_on_texts(docs)\n",
    "print(token.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed1c7250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'텍스트의': 2, '먼저': 1, '토큰화합니다': 1, '각': 1, '단어를': 1, '나누어': 1, '인식됩니다': 1, '딥러닝에서': 2, '토큰화해야': 1, '단어로': 1, '결과는': 1, '토큰화한': 1, '수': 1, '사용할': 1, '있습니다': 1})\n",
      "{'텍스트의': 1, '딥러닝에서': 2, '먼저': 3, '각': 4, '단어를': 5, '나누어': 6, '토큰화합니다': 7, '단어로': 8, '토큰화해야': 9, '인식됩니다': 10, '토큰화한': 11, '결과는': 12, '사용할': 13, '수': 14, '있습니다': 15}\n"
     ]
    }
   ],
   "source": [
    "print(token.word_docs)\n",
    "print(token.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f48f24e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문: 해보지 않으면 해낼수 없다\n",
      "토큰화: ['해보지', '않으면', '해낼수', '없다']\n",
      "단어 카운트: OrderedDict([('먼저', 1), ('텍스트의', 2), ('각', 1), ('단어를', 1), ('나누어', 1), ('토큰화합니다', 1), ('단어로', 1), ('토큰화해야', 1), ('딥러닝에서', 2), ('인식됩니다', 1), ('토큰화한', 1), ('결과는', 1), ('사용할', 1), ('수', 1), ('있습니다', 1)])\n",
      "문장 카운트 3\n",
      "문장 카운트 3\n",
      "각 단어가 몇개의 문장에 포함되어 있는가 defaultdict(<class 'int'>, {'텍스트의': 2, '먼저': 1, '토큰화합니다': 1, '각': 1, '단어를': 1, '나누어': 1, '인식됩니다': 1, '딥러닝에서': 2, '토큰화해야': 1, '단어로': 1, '결과는': 1, '토큰화한': 1, '수': 1, '사용할': 1, '있습니다': 1})\n",
      "각 단어에 매겨진 인덱스 값 {'텍스트의': 1, '딥러닝에서': 2, '먼저': 3, '각': 4, '단어를': 5, '나누어': 6, '토큰화합니다': 7, '단어로': 8, '토큰화해야': 9, '인식됩니다': 10, '토큰화한': 11, '결과는': 12, '사용할': 13, '수': 14, '있습니다': 15}\n"
     ]
    }
   ],
   "source": [
    "#주어진 문장을 단어로 토큰화하기\n",
    "\n",
    "#텍스트 전처리 함수 text_to_sequece 호출\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "#전처리할 텍스트 정하기\n",
    "text='해보지 않으면 해낼수 없다'\n",
    "\n",
    "#해당 텍스트 토큰화\n",
    "result= text_to_word_sequence(text)\n",
    "print('원문:', text)\n",
    "print('토큰화:', result)\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "docs= ['먼저 텍스트의 각 단어를 나누어 토큰화합니다.',\n",
    "      '텍스트의 단어로 토큰화해야 딥러닝에서 인식됩니다.',\n",
    "      '토큰화한 결과는 딥러닝에서 사용할 수 있습니다.']\n",
    "\n",
    "#토큰화 함수를 이용해 전처리하는 과정\n",
    "token = Tokenizer() #토큰화 함수 지정\n",
    "token.fit_on_texts(docs) #토큰화 함수에 문장 적용하기\n",
    "\n",
    "#각 옵션에 맞춰 단어의 빈도 수를 계산한 결과 출력\n",
    "print('단어 카운트:', token.word_counts)\n",
    "\n",
    "#츨력되는 순서는 랜덤\n",
    "print('문장 카운트', token.document_count)\n",
    "\n",
    "#출석 되는 순서는 랜덤\n",
    "print('문장 카운트', token.document_count)\n",
    "print('각 단어가 몇개의 문장에 포함되어 있는가', token.word_docs)\n",
    "print('각 단어에 매겨진 인덱스 값', token.word_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f78478db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'오랫동안': 1, '꿈꾸는': 2, '이는': 3, '그': 4, '꿈을': 5, '닮아간다': 6}\n"
     ]
    }
   ],
   "source": [
    "#파이썬의 배열 인덱스는 0부터 시작하므로, 맨 앞에 0이 추가되는 것에 주의\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "text='오랫동안 꿈꾸는 이는 그 꿈을 닮아간다'\n",
    "\n",
    "token=Tokenizer()\n",
    "token.fit_on_texts([text])\n",
    "print(token.word_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7554aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4, 5, 6]]\n"
     ]
    }
   ],
   "source": [
    "#원 핫 인코딩 방식으로표현\n",
    "#케라스에서 제공하는 Tokenizer의 texts_to_sequences( ) 함수를 사용해서 \n",
    "#앞서 만들어진 토큰의 인덱스로만 채워진 새로운 배열을 만들어 줌\n",
    "\n",
    "x= token.texts_to_sequences([text])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fa33d4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'to_categorical' from 'keras.utils' (C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\utils\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25136/2299162702.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#단어의 원핫 인코딩\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#인덱스 수에 하나를 추가해서 원 핫 인코딩 배열 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mword_sixe\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'to_categorical' from 'keras.utils' (C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\utils\\__init__.py)"
     ]
    }
   ],
   "source": [
    "#단어의 원핫 인코딩\n",
    "from keras.utils import to_categorical\n",
    "#인덱스 수에 하나를 추가해서 원 핫 인코딩 배열 생성\n",
    "\n",
    "word_sixe= len(t.word_index)+1\n",
    "x= to_categorical(x, num_classes=word_size)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8949c2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#단어 임베딩\n",
    "\"\"\"\n",
    "원-핫 인코딩을 그대로 사용하면 벡터의 길이가 너무 길어진다는 단점이 있음\n",
    "공간적 낭비를 해결하기 위해 등장한 것이 단어 임베딩(word embedding)이라는 방법\n",
    "단어 임베딩은 주어진 배열을 정해진 길이로 압축시킴\n",
    "\n",
    "단어 임베딩으로 얻은 결과가 밀집된 정보를 가지고 있고 \n",
    "공간의 낭비가 적다는 것을 알 수 있음\n",
    "이런 결과가 가능한 이유는 각 단어 간의 유사도를 계산했기 때문임\n",
    "\n",
    "단어간 유사도 계산은 오차 역전파가 또 다시 등장\n",
    "적절한 크기로 배열을 바꾸어 주기 위해 최적의 유사도를 계산하는 학습 과정을 거치는 것\n",
    "이 과정은 케라스에서 제공하는 Embedding( ) 함수를 사용하면 간단히 해낼 수 있음\n",
    "\"\"\"\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8685567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(16,4))\n",
    "\n",
    "#Embedding(16,4)가 의미하는 바는 입력될 총 단어 수는 16,\n",
    "#임베딩 후 출력되는 벡터 크기는 4로 하겠다는 뜻\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2384f36",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25136/3084509122.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#긍정리뷰는 1, 부정리뷰는 0으로 클래스 지정\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#???\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'array' is not defined"
     ]
    }
   ],
   "source": [
    "#짧은 리뷰 10개를 불러와 각각 긍정이면 1이라는 클래스를 부정적이면 0이라는 클래스로 지정\n",
    "\n",
    "#텍스트 리뷰 자료 지정\n",
    "docs=['너무 재밌네요',' 최고에요', '참 잘 만든 영화에요', '추천하고 싶은 영화입니다', '한 번 더 보고싶네요', '글쎄요', '별로에요', '생각보다 지루하네요', '연기가 어색해요', '재미없어요']\n",
    "\n",
    "#긍정리뷰는 1, 부정리뷰는 0으로 클래스 지정\n",
    "classes = array([1,1,1,1,1,0,0,0,0,0])\n",
    "\n",
    "#???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acb3d342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'텍스트의': 1, '딥러닝에서': 2, '먼저': 3, '각': 4, '단어를': 5, '나누어': 6, '토큰화합니다': 7, '단어로': 8, '토큰화해야': 9, '인식됩니다': 10, '토큰화한': 11, '결과는': 12, '사용할': 13, '수': 14, '있습니다': 15}\n"
     ]
    }
   ],
   "source": [
    "#케라스에서 제공하는 Tokenizer( ) 함수의 fit_on_text를 이용해 \n",
    "#각 단어를 하나의 토큰으로 변환함\n",
    "\n",
    "#토큰화\n",
    "token=Tokenizer()\n",
    "token.fit_on_texts(docs)\n",
    "print(token.word_index)\n",
    "\n",
    "#???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51ff64f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 1, 4, 5, 6, 7], [1, 8, 9, 2, 10], [11, 12, 2, 13, 14, 15]]\n"
     ]
    }
   ],
   "source": [
    "#토큰에 지정된 인덱스로 새로운 배열 생성\n",
    "x= token.texts_to_sequences(docs)\n",
    "print(x)\n",
    "\n",
    "#???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b81d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#패딩\n",
    "\"\"\"\n",
    "패딩( padding) 과정 :\n",
    "     길이를 똑같이 맞춰 주는 작업\n",
    "패딩은 자연어 처리뿐 아니라 GAN에서도 중요한 역할을 함\n",
    "패딩 작업을 위해 케라스는 pad_sequence( ) 함수를 제공함\n",
    "pad_sequnce( ) 함수를 사용하면 원하는 길이보다 짧은 부분은 숫자 0을 넣어서 채워주고, 긴 데이터는 잘라서 같은 길이로 맞춤\n",
    "\"\"\"\n",
    "padded_x = pad_sequnces(x,4) #서로다른 길이의 데이터를 4로 맞추기\n",
    "print(padded_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9581e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "임베딩 함수에 필요한 세 가지 파라미터는 ‘입력, 출력, 단어 수’임\n",
    "총 몇 개의 단어 집합에서(입력), 몇 개의 임베딩 결과를 사용할 것인지(출력), 그리고 매번 입력될 단어 수는 몇 개로 할지(단어 수)를 정해야 하는 것\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "먼저 총 몇 개의 인덱스가 ‘입력’되어야 하는지를 정함\n",
    "word_size라는 변수를 만든 뒤, 길이를 세는 len( ) 함수를 이용해 word_index 값을 앞서 만든 변수에 대입함\n",
    "이때 전체 단어의 맨 앞에 0이 먼저 나와야 하므로 총 단어 수에 1을 더하는 것을 잊지 마시기 바람\n",
    "#???\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "몇 개의 임베딩 결과를 사용할 것인지, 즉 ‘출력’을 정할 차례임\n",
    "word_size만큼의 입력 값을 이용해 8개의 임베딩 결과를 만듦\n",
    "여기서 8이라는 숫자는 임의로 정한 것\n",
    "데이터에 따라 적절한 값으로 바꿀 수 있음\n",
    "이때 만들어진 8개의 임베딩 결과는 우리 눈에 보이지 않음\n",
    "내부에서 계산하여 딥러닝의 레이어로 활용됨\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "끝으로 매번 입력될 ‘단어 수’를 정함\n",
    "패딩 과정을 거쳐 4개의 길이로 맞춰 주었으므로 4개의 단어가 들어가게 설정하면 임베딩 과정은 다음 한 줄로 표현됨\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Embedding(word_size, 8, input_length=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9123399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어 임베딩을 포함하여 딥러닝 모델을 만들고 결과를 출력\n",
    "model = Sequential()\n",
    "model.add(Embedding(word_size, 8, input_length=4))\n",
    "model.add(Flatten())\n",
    "#긍정 혹은 부정 출력이므로 1\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(padded_x, labels, epochs=20)\n",
    "print('Accuracy:%.4f' % (model.evaluate(padded_x, labels)[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63986ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'너무': 1, '재밌네요': 2, '최고에요': 3, '참': 4, '잘': 5, '만든': 6, '영화에요': 7, '추천하고': 8, '싶은': 9, '영화입니다': 10, '한': 11, '번': 12, '더': 13, '보고싶네요': 14, '글쎄요': 15, '별로에요': 16, '생각보다': 17, '지루하네요': 18, '연기가': 19, '어색해요': 20, '재미없어요': 21}\n",
      "패딩결과 [[ 4  5  6  7]\n",
      " [ 8  9  2 10]\n",
      " [ 2 13 14 15]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25136/964495089.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy:%.4f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "#영화리뷰가 긍정적인지 부정적인지 예측하기\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "from numpy import array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Embedding\n",
    "\n",
    "#짧은 리뷰 10개를 불러와 각각 긍정이면 1이라는 클래스를 부정적이면 0이라는 클래스로 지정\n",
    "\n",
    "#텍스트 리뷰 자료 지정\n",
    "docs=['너무 재밌네요',' 최고에요', '참 잘 만든 영화에요', '추천하고 싶은 영화입니다', '한 번 더 보고싶네요', '글쎄요', '별로에요', '생각보다 지루하네요', '연기가 어색해요', '재미없어요']\n",
    "\n",
    "#긍정리뷰는 1, 부정리뷰는 0으로 클래스 지정\n",
    "classes = array([1,1,1,1,1,0,0,0,0,0])\n",
    "\n",
    "#토큰화\n",
    "token=Tokenizer()\n",
    "token.fit_on_texts(docs)\n",
    "print(token.word_index)\n",
    "\n",
    "padded_x = pad_sequences(x,4) #서로다른 길이의 데이터를 4로 맞추기\n",
    "print('패딩결과',padded_x)\n",
    "\n",
    "#임베딩에 입력될 단어 수 지정\n",
    "word_size = len(token.word_index)+1\n",
    "\n",
    "#단어 임베딩을 포함하여 딥러닝 모델을 만들고 결과 출력\n",
    "model = Sequential()\n",
    "model.add(Embedding(word_size, 8, input_length=4))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(padded_x, labels, epochs=20)\n",
    "print('Accuracy:%.4f' % (model.evaluate(padded_x, labels)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e7242be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'너무': 1, '재밌네요': 2, '최고예요': 3, '참': 4, '잘': 5, '만든': 6, '영화예요': 7, '추천하고': 8, '싶은': 9, '영화입니다': 10, '한번': 11, '더': 12, '보고싶네요': 13, '글쎄요': 14, '별로예요': 15, '생각보다': 16, '지루하네요': 17, '연기가': 18, '어색해요': 19, '재미없어요': 20}\n",
      "[[ 4  5  6  7]\n",
      " [ 8  9  2 10]\n",
      " [ 2 13 14 15]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25136/1609954422.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n Accuracy: %.4f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import tensorflow as tf\n",
    "from numpy import array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Embedding\n",
    "  \n",
    "# 텍스트 리뷰 자료 지정\n",
    "docs = ['너무 재밌네요','최고예요','참 잘 만든 영화예요','추천하고 싶은 영화입니다.','한번 더 보고싶네요','글쎄요','별로예요','생각보다 지루하네요','연기가 어색해요','재미없어요']\n",
    "  \n",
    "# 긍정 리뷰는 1, 부정 리뷰는 0으로 클래스 지정\n",
    "classes = array([1,1,1,1,1,0,0,0,0,0])\n",
    "  \n",
    "# 토큰화 \n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(docs)\n",
    "print(token.word_index)\n",
    "  \n",
    "# 패딩, 서로 다른 길이의 데이터를 4로 맞춤\n",
    "padded_x = pad_sequences(x, 4)  \n",
    "\"\\n패딩 결과\\n\", print(padded_x)\n",
    "  \n",
    "# 임베딩에 입력될 단어 수 지정\n",
    "word_size = len(token.word_index)+1\n",
    "  \n",
    "# 단어 임베딩을 포함하여 딥러닝 모델을 만들고 결과 출력\n",
    "model = Sequential()\n",
    "model.add(Embedding(word_size, 8, input_length=4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(padded_x, labels, epochs=20)\n",
    " \n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(padded_x, classes)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66636cae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 카테고리\n",
      "8982 학습용 뉴스 기사\n",
      "2246 테스트용 뉴스 기사\n",
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 2, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 2, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "#LSTM을 이용한 로이터 뉴스 카테고리 분류하기\n",
    "from keras.datasets import reuters\n",
    "\n",
    "#불러온 데이터를 학습셋과 테스트 셋으로 나누기\n",
    "(X_train, Y_train), (X_test, Y_test) = reuters.load_data(num_words=1000, test_split=0.2)\n",
    "\n",
    "#데이터 확인 후 출력\n",
    "category = numpy.max(Y_train)+1\n",
    "\n",
    "print(category, '카테고리')\n",
    "print(len(X_train), '학습용 뉴스 기사')\n",
    "print(len(X_test),'테스트용 뉴스 기사')\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7089575",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "딥러닝은 단어를 그대로 사용하지 않고 숫자로 변환한 다음 학습할 수 있음\n",
    "여기서는 데이터 안에서 해당 단어가 몇 번이나 나타나는지 세어 빈도에 따라 번호를 붙임\n",
    "이러한 작업을 위해서 tokenizer( ) 같은 함수를 사용하는데, 케라스는 이 작업을 이미 마친 데이터를 불러올 수 있음\n",
    "#중요\n",
    "모든 단어를 다 사용하는 것은 비효율적이므로 빈도가 높은 단어만 불러와 사용함\n",
    "\n",
    "사용하는 인자가 바로 테스트셋과 학습셋으로 나눌 때 함께 적용했던 num_word=1000의 의미\n",
    ">>>빈도가 1~1,000에 해당하는 단어만 선택해서 불러오는 것\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f6338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#또 하나 주의해야 할 점은 각 기사의 단어 수가 제각각 다르므로 이를 동일하게맞춰야 한다는 것\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "#데이터 전처리\n",
    "x_train = sequence.pad_sequences(X_train, maxlen=100)\n",
    "x_test = sequence.pad_sequences(X_test, maxlen=100)\n",
    "\n",
    "\"\"\"\n",
    "여기서 maxlen=100은 단어 수를 100개로 맞추라는 뜻임\n",
    "만일 입력된 기사의 단어 수가 100보다 크면 100개째 단어만 선택하고 나머지는 버림\n",
    "100에서 모자랄 때는 모자라는 부분을 모두 0으로 채움\n",
    "이제 y 데이터에 원-핫 인코딩 처리를 하여 데이터 전처리 과정을 마침\n",
    "\"\"\"\n",
    "y_train = np_utils.to_categorical(Y_train)\n",
    "y_test = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b878c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리 과정이 끝났으므로 딥러닝의 구조를 만듦\n",
    "model = Sequential()\n",
    "model.add(Embedding(1000,100))\n",
    "model.add(LSTM(100, activation='tanh'))\n",
    "model.add(Dense(46, activation='softmax'))\n",
    "\"\"\"\n",
    "Embedding\n",
    "데이터 전처리 과정을 통해 입력된 값을 받아 다음 층이 알아들을 수 있는 형태로 변환하는 역할을 함\n",
    "Embedding('불러온 단어의 총 개수', '기사당 단어 수') 형식으로 사용하며, 모델 설정 부분의 맨 처음에 있어야 함\n",
    "\n",
    "LSTM\n",
    "RNN에서 기억 값에 대한 가중치를 제어하며, LSTM(기사당 단어 수, 기타 옵션)의 형식으로 적용됨\n",
    "LSTM의 활성화 함수로는 tanh를 사용함\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13201ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#컴파일, 실행 및 정확도를 측정해보기\n",
    "\n",
    "#모델의 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#모델의 실행\n",
    "history = model.fit(x_train, y_train, batch_size=100, epochs=20, validation_data=(x_test, y_test))\n",
    "\n",
    "#테스트 정확도 출력\n",
    "print('test accuracy %.4f' % (model.evaluate(x_test, y_test)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7fe427f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 카테고리\n",
      "8982 학습용 뉴스 기사\n",
      "2246 테스트용 뉴스 기사\n",
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 2, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 2, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - 19s 184ms/step - loss: 2.5777 - accuracy: 0.3497 - val_loss: 2.1698 - val_accuracy: 0.4488\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 18s 206ms/step - loss: 2.0353 - accuracy: 0.4901 - val_loss: 1.9301 - val_accuracy: 0.5120\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 18s 200ms/step - loss: 1.9073 - accuracy: 0.5066 - val_loss: 1.8073 - val_accuracy: 0.5503\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - 22s 244ms/step - loss: 1.7661 - accuracy: 0.5445 - val_loss: 1.7396 - val_accuracy: 0.5557\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - 19s 215ms/step - loss: 1.6994 - accuracy: 0.5617 - val_loss: 1.6931 - val_accuracy: 0.5672\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - 16s 182ms/step - loss: 1.6247 - accuracy: 0.5826 - val_loss: 1.6604 - val_accuracy: 0.5824\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - 20s 218ms/step - loss: 1.5499 - accuracy: 0.6126 - val_loss: 1.5656 - val_accuracy: 0.6131ss: 1.5550 - accu\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - 21s 231ms/step - loss: 1.4445 - accuracy: 0.6404 - val_loss: 1.4991 - val_accuracy: 0.6331\n",
      "Epoch 9/20\n",
      "90/90 [==============================] - 18s 198ms/step - loss: 1.3320 - accuracy: 0.6659 - val_loss: 1.4288 - val_accuracy: 0.6465\n",
      "Epoch 10/20\n",
      "90/90 [==============================] - 18s 195ms/step - loss: 1.2304 - accuracy: 0.6890 - val_loss: 1.3807 - val_accuracy: 0.6451\n",
      "Epoch 11/20\n",
      "90/90 [==============================] - 17s 184ms/step - loss: 1.1654 - accuracy: 0.6997 - val_loss: 1.3769 - val_accuracy: 0.6647\n",
      "Epoch 12/20\n",
      "90/90 [==============================] - 18s 201ms/step - loss: 1.1181 - accuracy: 0.7163 - val_loss: 1.3131 - val_accuracy: 0.6754\n",
      "Epoch 13/20\n",
      "90/90 [==============================] - 17s 187ms/step - loss: 1.0523 - accuracy: 0.7306 - val_loss: 1.2648 - val_accuracy: 0.6799\n",
      "Epoch 14/20\n",
      "90/90 [==============================] - 18s 198ms/step - loss: 0.9992 - accuracy: 0.7454 - val_loss: 1.2437 - val_accuracy: 0.6906\n",
      "Epoch 15/20\n",
      "90/90 [==============================] - 19s 213ms/step - loss: 0.9507 - accuracy: 0.7558 - val_loss: 1.2481 - val_accuracy: 0.7012\n",
      "Epoch 16/20\n",
      "90/90 [==============================] - 17s 191ms/step - loss: 0.9322 - accuracy: 0.7620 - val_loss: 1.2208 - val_accuracy: 0.6972\n",
      "Epoch 17/20\n",
      "90/90 [==============================] - 21s 228ms/step - loss: 0.8954 - accuracy: 0.7688 - val_loss: 1.2239 - val_accuracy: 0.7053\n",
      "Epoch 18/20\n",
      "90/90 [==============================] - 18s 201ms/step - loss: 0.8480 - accuracy: 0.7835 - val_loss: 1.2083 - val_accuracy: 0.7066\n",
      "Epoch 19/20\n",
      "90/90 [==============================] - 19s 207ms/step - loss: 0.8156 - accuracy: 0.7908 - val_loss: 1.2293 - val_accuracy: 0.7030\n",
      "Epoch 20/20\n",
      "90/90 [==============================] - 19s 210ms/step - loss: 0.7720 - accuracy: 0.8043 - val_loss: 1.2409 - val_accuracy: 0.7053\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 1.2409 - accuracy: 0.7053 0s - loss: 1.2146 - accuracy\n",
      "test accuracy 0.7053\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA9YUlEQVR4nO3de5zN5fbA8c+aO8Yl14RCSilMRjEpZmhCKXKUOlKopB/pHiqd7unQVZ3kSEqik1CpXJJLMk4uEaIIB+mqDFOMuazfH88exrT33Pbsveey3q/X9zV7vt/nu/eabew13+/zPOsRVcUYY4zJKyzUARhjjCmdLEEYY4zxyhKEMcYYryxBGGOM8coShDHGGK8iQh1ASapdu7Y2bty4WOf+8ccfVKlSpWQDKkEWn38sPv9YfP4pzfGtWbPmV1Wt4/WgqpabLT4+Xotr8eLFxT43GCw+/1h8/rH4/FOa4wNWq4/PVLvFZIwxxitLEMYYY7yyBGGMMcarctVJbYwpfTIyMtizZw+HDx8O2GtUr16dzZs3B+z5/VUa4ouJiaFhw4ZERkYW+hxLEMaYgNqzZw9Vq1alcePGiEhAXuPgwYNUrVo1IM9dEkIdn6qyb98+9uzZQ5MmTQp9nt1iMsYE1OHDh6lVq1bAkoMpmIhQq1atIl/FWYIAUlJg2rSTSUkJdSTGlE+WHEKvOP8GFT5BLF0KnTrBq682oUsXLEkYY4xHhU8Qn38OGRmgKhw5AkuWhDoiY4wpHSp8gkhKgvBwACUqChITQxyQMaZE7du3j7i4OOLi4jjxxBNp0KDB0e+PHDlS4PlLlixhxYoVxXrtnTt38tZbbxX4/D169CjW8wdahU8QCQkwYgSAMHGi+94YE2IpKfDkkyVyz7dWrVqsW7eOdevWMWTIEO64446j30dFRRV4fqATRGlmw1yBW26BJ56An38OdSTGlHO33w7r1uXfJjUVvvoKsrMhLAxatYLq1X23j4uDRx8tUhhr1qzhzjvvJC0tjdq1azNlyhTq16/PCy+8wIQJE4iIiKBFixaMGTOGCRMmEB4ezptvvsn48eP58ccfefjhhwkPD6d69eosW7aMrKwsRo4cyZIlS0hPT2fo0KHcfPPNjBw5ks2bN9OhQwcGDhzIHXfckW9cv/32G4MGDWL79u1UrlyZiRMn0qpVK5YuXcptt90GuM7mZcuWkZaWRt++fTlw4ACZmZm8/PLLXHjhhUV6HwpiCQJo2BBOOeUPFi6swp13hjoaYyq41FSXHMB9TU3NP0EUkapy66238t5771GnTh3efvtt7r//fiZPnsyYMWPYsWMH0dHR7N+/nxo1ajBkyBBiY2O5++67AWjZsiXz58+nQYMG7N+/H4BXX32V6tWrs2rVKtLT0+nQoQMXX3wxY8aMYdy4cUyfPr1Q8yD+8Y9/cM455zBnzhw+/fRTrrvuOtatW8e4ceN46aWX6NChA2lpacTExDBx4kS6du3K/fffT1ZWFn/++WeJvUc5LEF4xMf/zscfV+HwYYiJCXU0xpRTzz1XcJuUFOjSBY4cgagomDat4Hu/Bw8WOoT09HQ2btxIcnIyAFlZWdSvXx+AVq1a0a9fP3r16kWvXr28nt+hQwcGDBjAVVddRe/evQFYsGABX331FTNnzgQgNTWVrVu3FuoWVm7Lly/n3XffBaBz587s27eP1NRUOnTowJ133km/fv3o3bs3DRs25Nxzz2XQoEFkZGTQq1cv4uLiivRahRGwPggRaSQii0Vks4hsEpHbvLRJFJFUEVnn2R7MdaybiHwjIttEZGSg4szRtu3vHDoExbzVaIwpKQkJsGiRu220aFGJdwyqKmedddbRfogNGzawYMECAD788EOGDh3KmjVriI+PJzMz8y/nT5gwgccee4zdu3cTFxfHvn37UFXGjx9/9Dl37NjBxRdfXKzY8hIRRo4cyaRJkzh06BDt27dny5YtdOzYkWXLltGgQQP69+/PG2+8UfQ3owCB7KTOBO5S1TOB9sBQEWnhpd1nqhrn2R4BEJFw4CWgO9ACuMbHuSWmdev9RETAwoWBfBVjTKEkJMCoUQEZNRIdHc0vv/xCiqcDPCMjg02bNpGdnc3u3btJSkrin//8J/v37yctLY2qVatyMNcVynfffUe7du145JFHqF27Nrt376Zr1668/PLLZGRkAPDtt9/yxx9//OXcgnTs2JFp06YBrnO8du3aVKtWje+++46WLVsyYsQI2rZty5YtW/jf//5H3bp1uemmm7jhhhtYu3ZtCb5LTsBuManqD8APnscHRWQz0AD4uhCnnwdsU9XtACIyA+hZyHOLpXLlLBISXIJ48slAvYoxJtTCwsKYOXMmw4cPJzU1lczMTG6//XZOP/10rr32WlJTU1FV7rjjDmrUqMFll11Gnz59eO+99xg/fjzPPvssW7duRVXp0qULrVu3plWrVuzcuZM2bdqgqtSpU4c5c+bQqlUrIiIiOP/88xk0aFCBndQPPfQQAwcOpFWrVlSuXJnXX38dgOeee47FixcTHh5OixYt6N69OzNmzGDs2LFERkYSGxsbkCsI8XZJU+IvItIYWAacraoHcu1PBN4F9gB7gbtVdZOI9AG6qeqNnnb9gXaqOszLcw8GBgPUq1cvfsaMGcWKMS0tjVmzzmLKlMbMnv051av/9dIylNLS0oiNjQ11GD5ZfP4pz/FVr16dZs2alXBEx8vKyiLcTWgqlUpLfNu2bSM1NfW4fUlJSWtUta3XE3wtNVdSGxALrAF6ezlWDYj1PL4E2Op5fCUwKVe7/sD4gl7L3yVHU1JUQfXtt4v9NAFTmpcsVLX4/FWe4/v6669LLhAfDhw4EPDX8Edpic/bvwWhWnJURCJxVwjTVHWWl+R0QFXTPI8/AiJFpDbuiqJRrqYNcVcYAdW2rRtNZ/0QxpiSNn/+/KMzuHO2K664ItRh5StgfRDiSge+CmxW1Wd8tDkR+ElVVUTOw3Wa7wP2A6eJSBPge+Bq4O+BijVHRAR07uwShCpYAUpjTEnp2rUrXbt2DXUYRRLIeRAdcLeGNojIOs+++4CTAVR1AtAHuEVEMoFDwNWeS55MERkGzAfCgcmquimAsR6VnAyzZ8O2bXDaacF4RWOMKZ0COYppOZDv3+Cq+iLwoo9jHwEfBSC0fHnmzrBwoSUIY0zFVuGL9eV16qnQuLH1QxhjjCWIPETcVcSnn4KXSZTGGFNhWILwIjkZDhyAVatCHYkxxl/+rAexevVqhg8fXqLxTJkyhb178x+UmZiYyOrVq0v0dYvDivV50bmzu5JYuNDWhzAmFFJS3OqOiYn+/x/MWQ8C3Ezl3JVZATIzM4mI8P5R2LZtW9q29T6HrLimTJnC2WefzUknnVSizxsIliC8qFXLzYlYuBAefLDg9saYwikly0EwYMAAatasyZdffkmbNm3o27cvt99+O4cOHaJSpUq89tprNG/enCVLljBu3Djmzp3LQw89xK5du9i+fTu7du3i9ttvZ/jw4fzxxx9cddVV7Nmzh6ysLEaPHk3fvn2PW3OiRo0avPnmm3z++eesXr2afv36UalSJVJSUqhUqVK+sU6fPp0nnngCVeXSSy/lqaeeIisrixtuuIHVq1cjIkfLeORdz6K4lSVyWILwITkZnnrK3WqqVi3U0RhTcQR4OYijvv32Wz755BPCw8M5cOAAy5YtIyIigk8++YT77rvvaNnt3LZs2cLixYs5ePAgzZs355ZbbmHevHmcdNJJfPjhh574U8nIyDhuzYkpU6YcXXPixRdfZNy4cYW6Mtm7dy8jRoxgzZo1nHDCCVx88cXMmTOHRo0a8f3337Nx40aAo+tS5F3Pwl+WIHxITnarzC1ZApdfHupojCkfSsFyEEddeeWVR+sjpaamcv3117N161ZE5GhV1rwuvfRSoqOjiY6Opm7duvz000+0bNmSu+++mxEjRtCjRw8uvPBCNm7ceNyaExkZGTRo0KDIMa5atYrExETq1KkDQL9+/Vi2bBmjR49m+/bt3HrrrVx66aVHS4sXZj2LorBOah8SEqByZRvuakywBXg5iKOqVKly9PHo0aNJSkpi48aNfPDBBxw+fNjrOdHR0Ucfh4eHk5mZyemnn86aNWto2bIlo0aN4pFHHvnLmhMrV648uuZEUaiPYqonnHAC69evJzExkZdeeokbb7wRKNx6FkVhCcKH6Gjo1MkShDGhEMDlILxKTU09+hf+lClTinTu3r17qVy5Mtdeey133303a9eupXnz5l7XnACKtEZEu3btWLp0Kb/++itZWVlMnz6dTp068euvv5Kdnc3f/vY3Hn30UdauXetzPQt/2C2mfCQnw513wu7d0KhRwe2NMWXTvffey/XXX88zzzxD586di3Tuhg0buOeeewgLCyMyMpKXX36ZqKio49acOHLkCHfeeSdnnXUWAwYMYMiQIYXqpK5fvz5PPvkkSUlJqCqXXHIJPXv2ZP369QwcOJBsT2fNk08+SVZWltf1LPziq8xrWdz8Lfed14YNrvz3q68W+2lLTHkuBx0MFp9/rNy3f0pLfKWq3HdZd9ZZUL++3WYyxlRMdospHyJw0UXw8cfHxmQbY0xJueKKK9ixY8dx+5566qlSUxbcEkQBkpNh6lRYvx7OOSfU0RhTNqkqYgus/MXs2bOD9lpajOWl7W/iAlx0kftqt5mMKZ6YmBj27dtXrA8oUzJUlX379hETE1Ok8+wKogD168PZZ7sEce+9oY7GmLKnYcOG7Nmzh19++SVgr3H48OEif/gFU2mILyYmhoYNGxbpHEsQhZCcDP/6Fxw6BAWUTTHG5BEZGUmTJk0C+hpLlizhnFJ8D7i0x+eL3WIqhORkSE+H5ctDHYkxxgRPwBKEiDQSkcUisllENonIbV7a9BORrzzbChFpnevYThHZICLrRCSkhdE7dnQ1YawfwhhTkQTyFlMmcJeqrhWRqsAaEVmoql/narMD6KSqv4tId2Ai0C7X8SRV/TWAMRZKlSrQoYMlCGNMxRKwKwhV/UFV13oeHwQ2Aw3ytFmhqr97vl0JFK0HJYiSk10d+59+CnUkxhgTHBKMoWci0hhYBpytqgd8tLkbOENVb/R8vwP4HVDgFVWd6OO8wcBggHr16sUXd4GMtLQ0YmNjfR7/5puqDBkSz/33f81FF/1crNfwR0HxhZrF5x+Lzz8WX/ElJSWtUVXvi1P4qsFRUhsQC6wBeufTJgl3hVEr176TPF/rAuuBjgW9VknXYsotM1O1Zk3VAQOK/RJ+Kc+1eoLB4vOPxeef0hwfoarFJCKRwLvANFWd5aNNK2AS0FNV9+XsV9W9nq8/A7OB8wIZa0HCw90iJgsXgs33McZUBIEcxSTAq8BmVX3GR5uTgVlAf1X9Ntf+Kp6ObUSkCnAxsDFQsRZWcjJ8/z1s2RLqSIwxJvACOYqpA9Af2CAi6zz77gNOBlDVCcCDQC3gX546LZnq7oXVA2Z79kUAb6nqvADGWiie1QNZuBDOPDO0sRhjTKAFLEGo6nIg3+pc6jqkb/SyfzvQ+q9nhFbjxtCsmUsQw4eHOhpjjAksm0ldRMnJsGQJ+FjT3Bhjyg1LEADLl3Py1KngWT82P8nJkJYGK1cGIS5jjAkhSxDz50PHjjR57TU3TKmAJJGU5BYOslnVxpjyzhLEmjWgiqjCkSPu/lE+atSA886zBGGMKf8sQSQlQUwMR6c2JCYWeEpyMnzxBezfH8C4jDEmxCxBJCTAp5/ye5s2kJUFf/xR4CnJyW6N6sWLgxCfMcaEiCUIgIQENj75JJx6Kgwd6hZ/yEf79hAba7eZjDHlmyUIj+yoKHjpJfj2Wxg7Nt+2kZHuztSCBUEKzhhjQsASRG5du8KVV8Ljj8P27fk2TU6G776DHTuCFJsxxgSZJYi8nn0WIiLg1lvzrcqXu+yGMcaUR5Yg8mrQAB5+GD76CN57z2ez5s2hYUNLEMaY8ssShDe33gotW7qCS2lpXpuIuKuIRYvc4CdjjClvLEF4ExkJL78Mu3fDo4/6bJacDL//DmvXBjE2Y4wJEksQvnToAIMGwTPPwKZNXpt06eK+2m0mY0x5ZAkiP089BdWqwf/9n9cO67p1IS7OEoQxpnyyBJGf2rVdkli2DKZO9dokORk+/7xQE7CNMaZMsQRRkEGD3NTpu+92HQ55JCe7tSGGDi1UtXBjjCkzLEEUJCzMdVjv2wf33/+Xw5GR7uvrrxeqWrgxxpQZAUsQItJIRBaLyGYR2SQit3lpIyLygohsE5GvRKRNrmPdROQbz7GRgYqzUOLi3NDXCRNcGddcUlJcDgE4dAhmzw5+eMYYEwiBvILIBO5S1TOB9sBQEWmRp0134DTPNhh4GUBEwoGXPMdbANd4OTe4HnkETjwRbrnluIkPiYkQHX0sSbz6qltiwhhjyrqAJQhV/UFV13oeHwQ2Aw3yNOsJvKHOSqCGiNQHzgO2qep2VT0CzPC0DZ1q1VwZjrVr3ZWER0KCmyz32GPw1ltQtSp06uQmYhtjTFkmmk+9oRJ7EZHGwDLgbFU9kGv/XGCMqi73fL8IGAE0Brqp6o2e/f2Bdqo6zMtzD8ZdfVCvXr34GTNmFCvGtLQ0YmNj82+kSqt77qHali188cYbHKlZ8y9NfvstipEjW/Ldd7Hcfvu3XHbZD8WKp1jxhZDF5x+Lzz8WX/ElJSWtUdW2Xg+qakA3IBZYA/T2cuxD4IJc3y8C4oErgUm59vcHxhf0WvHx8VpcixcvLlzDb75RjYpS7dfPZ5ODB1UvvVQVVEeNUs3KKnZYRY8vRCw+/1h8/rH4ig9YrT4+UwM6iklEIoF3gWmqOstLkz1Ao1zfNwT25rM/9E4/HUaMgGnTfC4pFxsLc+bAzTfDk0/CtdcWuAaRMcaUOoEcxSTAq8BmVX3GR7P3ges8o5naA6mq+gOwCjhNRJqISBRwtadt6TBqFDRt6mZYHznitUlEhBsdO2YMTJ/ulprwMo3CGGNKrUBeQXTA3RrqLCLrPNslIjJERIZ42nwEbAe2Af8G/g9AVTOBYcB8XOf2f1TVe0GkUKhUCV58EbZscbWafBBxFxtvveWGw3boADt3Bi9MY4zxR0Sgnlhdx7MU0EaBoT6OfYRLIKVT9+7Qu7cb/nr11dC4sc+m11wDJ50EvXq5Sdkffgjx8UGL1BhjisVmUvvjuefcBIj+/V1nQz7TqDt1ghUrICYGOnZ0ScIYY0ozSxD+aNQIBgyA5cvhgQcKrLVx5pmwciWccQZcfjm88krwQjXGmKKyBOGvE090X7Oz3VAlHyObcjdfutTdoRoyxPV3Z2cHIU5jjCkiSxD+6tLFdVqD+6RftcqVd81H7mGwY8ZAt25u4Tor9GeMKU0C1kldYeTU2li82I1qmjrVXR688w6ccILP03KGweYUi1240HVjLFrkntIYY0LNEkRJSEg49qnepQvcdJMbrjR3Lpx2ms/TRFw3hohbsO7QIZg3zxKEMaZ0sFtMJe366+HTT+G336BdO/c4H4mJbmRTTjXYmTNtQp0xpnSwBBEIF1wA//0v1K/vplBPnOizae5qsGPGwLZt0Lkz/PprEOM1xhgv7BZToDRt6iY+XH21643evBnGjYPw8L80zX2HqnVruOIKd2XxySfHBkkZY0yw2RVEIFWvDh98AMOHu0l1l18OBw7ke0q3bm4S3c6dbnLdnj1BidQYY/7CEkSgRUTA88+7oUrz5xeqIFPnzq7pDz+4WddWv8kYEwqWIIJlyBA3RGnPHjjvPPj883ybd+jg+ib274cLL4Q9eyoFJ05jjPGwBBFMF13kam1Ur+4uE6ZOzbf5uee66RWHD8Ntt8Xx9ddBitMYY7AEEXzNm7skcf75cN11cN99+dbaaN3aleYQcX0S69YFL1RjTMVmCSIUatVynQw33uimTyclwUMP+ay10aIFPPfcOipVck2/+CK44RpjKiZLEKESFeXmRwwfDsuWwcMPu0uE+fO9Nm/Y8BDLlkHNmu5O1fLlQY7XGFPhWIIIJRE30SFnGnVGBlx2Gdx5J+ze/ZfmjRu7XJIz/66ASdrGGOMXSxChlpgI0dFuAl10tOu8fuEFN9Hu+uth48bjmjdo4JJE06Zw6aXw8cehCdsYU/5Zggi1nFobjz7qhizNmwfffQdDh7rCTC1bQo8eVF+/3lX0A+rVc03PPBN69nQlOgpY0M4YY4osYAlCRCaLyM8istHH8XtEZJ1n2ygiWSJS03Nsp4hs8BxbHagYS42EBLdyUE69jVNOcTOvd+1ya17/97+cc/vt7vjs2ZCdTe3a7hbT6ae7U++/v8AF7YwxpkgCeQUxBejm66CqjlXVOFWNA0YBS1X1t1xNkjzH2wYwxtKtVi0YPRr+9z++ve02+Pln6N3bXTpMmkSNSun06eOa5pQLHzkS9u4NbdjGmPIhYAlCVZcBvxXY0LkGmB6oWMq8ypXZ26sXfPstzJgBVaq4NScaN6brz1OpFJ1FuGQTHqZ89pnrzB44EDZtCnXgxpiyTNRzXzsgTy7SGJirqmfn06YysAdolnMFISI7gN8BBV5RVZ/1skVkMDAYoF69evEzZswoVqxpaWnExsYW69xgOC4+VU5Yu5ZGM2ZQc/VqVtCeJSTSKXw5v40axGubkvn44/ocPhxOu3b76Nt3N3Fx+xEJUnylkMXnH4vPP6U5vqSkpDU+79SoasA2oDGwsYA2fYEP8uw7yfO1LrAe6FiY14uPj9fiWrx4cbHPDQaf8Q0bpuruMLktOlr173/XX197Xx8dna5167rd8fGqM2aoZmQEOb5SwuLzj8Xnn9IcH7BafXymFuoWk4jcJiLVxHlVRNaKyMV+Jq4cV5Pn9pKq7vV8/RmYDZxXQq9V/vz971CpkhsmGxXlZtHNn0+tgZfzwNjq/O/cPrwyYAUH92dx9dVuBdQXXoC0tFAHbowp7QrbBzFIVQ8AFwN1gIHAGH9fXESqA52A93LtqyIiVXMee17T60gow/HDZJcscetg//ijGwd7003ErP8vg6d0YPOOGOa0HE2DsL3cdhucfDI88IBrmpJiw2SNMX9V2BXlcu5eXwK8pqrrRfK/oy0i04FEoLaI7AH+AUQCqOoET7MrgAWq+keuU+sBsz1PHwG8parzChlnxZR7STpwa1AkJrrt+edhzRrCZs2i5+yZ9Nz+GCm0ZyxP8MQTifzzKSU7W1BVoqOURYvDj3sqY0zFVdgEsUZEFgBNgFGev/B9lyAFVPWagp5UVafghsPm3rcdaF3IuExBRKBtW7c98QRs2ULC7NnMmnUv365OpX/mG3xBOyCMw+nZzPrnNhJmNwt11MaYUqCwt5huAEYC56rqn7grgYEBi8oEzhlnuJl1q1Zx+q5FPNdhJjEcRshGEZ6d05jBsW+x67Kh7urjiy/gyJFQR22MCYHCJogE4BtV3S8i1wIPAKmBC8sERaNGJIz9G59GdedxGc17EX9jSKsUXj90JafNfYZht4fzfbsr3AJHF14I994Lc+bATz+FOnJjTBAUNkG8DPwpIq2Be4H/AW8ELCoTPAkJJCx5klGPx3L5snt4cf2FbN0RyYDB0bwSMZRTI3dxx5nz+OnPqu6K4oorXAXapk3h2mvhpZdgyhROnjrVermNKWcK2weRqaoqIj2B51X1VRG5PpCBmSDK08l98snwyiswYoTw2GPhjH+jExOjOzFsWCb3dFlL7c2fwYoVrhjUtGmA65xi2jQ3esp6uY0pFwp7BXFQREYB/YEPRSQcz4gkU341bQqTJ8Pmze7CYeyzETTpex4P/H4Xv096F77/Hu65B0TcMLf0dBgxAv78M9ShG2NKQGETRF8gHTcf4kegATA2YFGZUuW00+DNN93SFN27w+OPu3pPDz8ipCb3gZgYssPC3GS9zz6DVq3cnAxjTJlWqAThSQrTgOoi0gM4rKrWB1HBtGgB//kPrF/v1jV66CFo0vc8bun6HXfEzSblX18eW+YuKQluvhlSbSyDMWVVYUttXAV8AVwJXAX8V0T6BDIwU3q1auWWpVi92lUenzCnPi+svYxOw1qymCT46iu4+26YNMlllfffD3XIxphiKOwtpvtxcyCuV9XrcLWRRgcuLFMWxMdDjx45S2oLGRlw+eXwwqTKHH50LKxc6da06NkTrr7arWdhjCkzCpsgwjyF83LsK8K5phzLWVI7LCyb6Gho1gxuu831W0xYcy5HVqx2daJmz3aXG1OnHl061RhTuhX2Q36eiMwXkQEiMgD4EPgocGGZsiKnVuCgQTtZvBjWroVPPoFGjeCWW6B5yygmn/QAmau+hObN4brr4JJL3HKqxphSrbCd1PcAE4FWuDpJE1V1RCADM2VHQgL067eLhARX+qlLF/j8c/j4Y6hdG264Ac78WwveHLKcrOfGu5FOZ53lJtll51vSyxgTQoW+TaSq76rqnap6h6rODmRQpuwTgW7dXCmn995zq6T2vz6MsycM4z9jtpOd0AGGDYOOHWH6dKs3bkwplG+CEJGDInLAy3ZQRA4EK0hTdom4juu1a+Gdd1yHdt9b6xL348fMvvVTdP1XbtGj++93Y2ctSRhTauSbIFS1qqpW87JVVdVqwQrSlH1hYdCnjxsBO20aHD4s9B6fRNvYzYzjTp7QEaQcjoNbb4Wvvw51uMYYbCSSCbLwcHfB8PXXMGUK/JBZm3t4mvt5nM58Ssr6yq5/okcPWLrURjwZE0KWIExIRETA9dfD/90WjYgCYRwmhpevWOCmaP/3v24Mbbt2bvp2ZmaIIzam4rEEYUKqSxeIiRHCw0FEmPpODMN++QeHvtkFEybA/v3Qty+cfjqMHw9paaEO2ZgKI2AJQkQmi8jPIrLRx/FEEUkVkXWe7cFcx7qJyDcisk1ERgYqRhN6OfMoHn3UVQq/8043+vW8TpXY2OFmV0p29myoXx+GD3e1yB94AH78MdShG1PuBfIKYgrQrYA2n6lqnGd7BMBTSvwloDvQArhGRFoEME4TYgkJbhXUTp3g6afd/Imff3bLaL80IRzt2ctNrPj8c3fb6Ykn4JRT4KabXAJJSbFhssYEQMAShKouA34rxqnnAdtUdbuqHgFmAD1LNDhTqnXr5kY7de7spkr07Am//gqcfz7MmgXffAODBrka5C1awAUXuKuKLl0sSRhTgkQDOEpERBoDc1X1bC/HEoF3gT3AXuBuVd3kqRLbTVVv9LTrD7RT1WE+XmMwMBigXr168TNmzChWrGlpacTGxhbr3GCoiPFlZ8OsWQ2YOPFUqlXLYNSozcTH7z96PHL/flo8+ig11q5FAAV+7NaNb+69103ACHB8Jcni84/FV3xJSUlrVLWt14OqGrANaAxs9HGsGhDreXwJsNXz+EpgUq52/YHxhXm9+Ph4La7FixcX+9xgqMjxrVunesYZqiKq996rmp6e6+CKFaqVKqmGhbkGoNq2reqsWapZWUGJryRYfP6x+IoPWK0+PlNDNopJVQ+oaprn8UdApIjUxl1RNMrVtCHuCsNUUK1bw5o1MHgw/POf0KEDbN3qOZjTy/3YY66X+9//ht9/h9693cIV06bZEFljiilkCUJEThRx9wFE5DxPLPuAVcBpItJERKKAqwFbcaaCq1zZjXp991347js45xx4/XXPPLrcvdw33ghbtrjEAHDttXDGGdSfO9etmW2MKbRADnOdDqQAzUVkj4jcICJDRGSIp0kfYKOIrAdeAK72XPFkAsOA+cBm4D+quilQcZqypXdv14Hdti0MGOBmZS9YkGcQU0SEO/DVV26I7Akn0Pzpp+HUU+H55+HPP0P5IxhTZkQE6olV9ZoCjr8IvOjj2EfYehPGh4YN3V2lp56C0aPh7bddn3R0tNufkOBpGBYGvXpBz56sHzeO1nPnwu23w+OPwx13wP/9H1SvHsKfxJjSzWZSmzIpPBzuuw9uvtndZsrOdneQFi/20liE388919V2+uwzt1bqffe5uRSjR7uJFzaPwpi/sARhyrT+/aFSJfc4O9utZncgv0L0F1zgEsKaNXDRRa5z+5JLXLnxpCSXQIwxgCUIU8blDGJ6/HEYOhSWLYNzz4UNGwo4sU0bmDnT3XICdxmSnu5m6d10E8yfDxkZgQ7fmFLNEoQp8xIS3B2jF1+ETz91VxDt2sHUqYU4+aqr3CVIeDhERbkxtG+/7RJFvXowcCB8+KGNgDIVkiUIU6507AhffgnnnQfXXef6KA4fzueE3NUClyxxQ6J+/hnef9+tSTF7tvtar557wvffL+AJjSk/LEGYcufEE11fxIgRMHGiuyj44YcY3yfkzKPIGf4UEwOXXQZvvAE//eSuIHr3hrlzXWGoOnXcMNpZs9yQWSsWaMqpgA1zNSaUIiJgzBhX3++662Dw4HiqVnUXA0USHe06sS+5BF55xQ2TmjnTXVlMn+6SSUaG6yGPiHB9Gmee6W5XRUcf+5r7cd59X33Fye+8474/OkbXmNCzBGHKtcsvdwOWunU7zGWXRTJqFDzyiPssL7LISLj4Yrf961+uR/y++9zqd+ASxdixxYqzCbgrlg8+gK5di/UcxpQ0SxCm3Dv1VHjxxS+ZObMjTz4JK1e6P/7r1fPjSSMiXD3yZ591ZcaPHHFXA2+/7WpApae77ciR47/m3ffee/D++4iqSzA9erhyIcOHuysRY0LIEoSpEKKjs/n3v11/xC23uFpOb78NF17o5xPndHIvWeIWMyrqLaIzzoAFC8hOTycsMhKSk+G111zhqa5d3S2riy92s8KNCTL7rTMVyoAB7gqiShU3L+7ppz0F//yRt5O7qOcuWsTOQYNc/8YHH8Du3W5U1fr10L27WxTp5Zfhjz/8DNSYorEEYSqc1q1h9Wo3IOnuu90f/v/4RwgHISUksKtfv2MJpk4dt0Le//7nVs2LjXV1oxo2dEOzdu0KUaCmorEEYSqk6tXdYKRbb3V9zY884q4oStVI1ago6NcPVq2C5ctdaZBx46BpUzfBb8WKErj8McY364MwFZYI1K/vbu/nFPsbOdLNlYuODnV0uYi4zpMOHdxVxUsvuYWR3nnH1T2/9FLXad6liw2TNSXKriBMhZaY6JJBeLjbli1zZTo2bgx1ZD6ccopbVm/3bpcofv4ZHn7YVaW98EJ45hk3OsqYEmAJwlRouSttfPaZG3X6ww+uIvgzz7gri1Ipp1/i5puPjXDKyoK77nLjdwcMsBpSxm92i8lUeAkJx9+Zad/eFXS96y43qOj11+Hkk0MXX76SktwlUM48jEcecaVs58xxgVev7mYL9unjhsvG5FNyxJg8LEEYk0fduu7z9bXX4LbboGVLVyn22mtdd0Cp4msexpEjbv8777gfZupUqFrV1Zjq08dVq81ZSMMYHwK5JvVkEflZRLzezRWRfiLylWdbISKtcx3bKSIbRGSdiKwOVIzG+CICgwa5qQgtW7p6TlddBfv2hToyL7zNw4iKcnMoJk92BQfnzYO+fd06F717u6G0V1/thnItXmzFBo1XgbyCmIJbc/oNH8d3AJ1U9XcR6Q5MBNrlOp6kqr8GMD5jCtS0qVupdOxYePBB+Pxz95nbrVuoIyuCyEg3K7trV1dDaulSlxhmzXLTyXNERLhVl5KT4bTToEkTd66psAJ2BaGqy4Df8jm+QlV/93y7EmgYqFiM8Ud4uBv++sUXULOm+8N86NAyOrE5MtLNp5gwAfbudXWfcu6bZWbC88+7elDNm7tbUM2aQffuNHvhBXjhBbdc67Ztrm0Of8udW7n0Uqu09EHcAHyc63sFFoiIAq+o6sTQhGXMMXFxbgb2/fe7EU4LF7pb++3aFXhq6RQR4e6jTZt2rJN75kyoUQO2bj1uO3HLFlfiPPe5TZpA7dpuIl9Wlsukffq4LJqe7hZWyvma+3HurwcOwO+evxPDwty9vB493JvdpInVoMqPqluPZP58Nz67b98SnwcjGsCZmCLSGJirqmfn0yYJ+Bdwgaru8+w7SVX3ikhdYCFwq+eKxNv5g4HBAPXq1YufMWNGsWJNS0sjNja2WOcGg8Xnn5KO78svazBmzBn8+ms0Xbv+SP36h2jTZj9nnXWgVMRXFNU2baLGunXsj4vjwFlneW2TdvAgNTMyqLRnD5W+//7o1+obNhD1228I7q+67IgIsitXJjsqym2RkX95rDn7IiOpvGsXVbdsOXo+Iq6yLZBZqRJ/nHoqac2aHd3+aNyYbC+zGP15/wrz8/srv/hyXj+1VSv+bNCAyNRUIlNTifJ8jUxNJXL//mOPc+0L98x5USA7Opr1Tz9d5J8hKSlpjaq29XYspAlCRFoBs4HuqvqtjzYPAWmqOq6g12vbtq2uXl28Pu0lS5aQmJhYrHODweLzTyDi278frrnG9f+Cu3szf74beVpUZfb9S0k5vtz5okVF+ys27/kffeTmeKxb57b169128KBrHxbmKuDGxbmiWnFxkJHB9jlzaDpwIJx7riubnpHhnjP3V2+P16+He+91t8yioty45osu8vv9ymvJkiUkduoEP/547Mps2zZXOXLp0oJLplSr5q7W6tRxX3Meb9jgpv6ruiu4Rx91AxaKQER8JoiQ3WISkZOBWUD/3MlBRKoAYap60PP4YuCREIVpjE81arg1sBcscBPqcpZzuOMO10dRv36oIwwCf8ud+zq/ba7Pq+xs2LHjWMJYt87NanzrraNNmgBMmuTHD4K77ZWc7BJUw4bQoMHxW+59deu6D2RwSS4n/vbt3aix3Elg61bafvmlSw65O64iItwvUU5yEHG/QP36/TUZREV5jzklxd1eykmwJfxHRsAShIhMBxKB2iKyB/gHEAmgqhOAB4FawL/EdZJlerJYPWC2Z18E8JaqzgtUnMb4I6dUx5Ej7v9727bwxBOuGsY117hkERcX6igDLO9Mw5I+PyzMrfp06qnwt78d2//bb6667auvuttSIu5qJDnZXc5FRroPzbyPc+/79ls32SUjw/0D3nST+/r997BnjxsC/MMPx3fKg0sO9eu7v+y/+cb1wYi4iYiHDh1rFxEBTZuSXrs2sT16uNFhzZq5ryef7Ppvcl9BFbVsvL8JugABSxCqek0Bx28EbvSyfzvQ+q9nGFP6ePv/uW2bGww0ebJbRbRzZ5coLrnE+lxLVM2aRzvZs9PTCYuOdjPJi/IhmZTkVgDM7wM2O9vVvPr++2OJI+fx8uUuOYC7EjjnHPeXwWmnHUsCERFs8HWLriQ+4P1N0PkoLaOYjCmz8v7/bNYMxo93n1X//rcbHXrZZXD66W6BuOuvh8qVQxZu+ZKz4NLkyTQdNCgwH7BhYXDiiW6Ljz/+WN4+lHHjinebrZRW4bW/Z4wJkBNOcP2fO3a42+XVqrn6eo0auaGye/eGOsJyIu+CS0F+7aPVHovaQV8G2BWEMQEWGenuOlx9tZuJ/cwzbl7Y2LFuX+fO8PnnJxMdXe4+XyqGUnwF4C+7gjAmSETgggtchYutW+GWW1wtvYEDYdKkJnTqBO++G+oojTnGEoQxIXDqqa4j+557cipdCBkZbiJymzbw+OOweXOoozQVnSUIY0Koe3c3MjIsLJuYGBg2zH3/wAPQooXbRo+GL7+05adN8FmCMCaEcvo4Bw3ayaefutFPK1a4kZQvvugGzjzxhLuqaNbMXXGsXFmKV7oz5Yp1UhsTYgkJkJ6+i4SEpkf3NWjgZmMPHQq//ALvv+/6J55/3o2kbNAArrjCzRuLiHATiwMwT8pUcJYgjCnl6tSBG25w2/79MHeu6+ieNMldZYDrx4iOhk8/tSRhSo7dYjKmDKlRwy19OmsW/Por/P3vbr+qKyV0003uFpUxJcEShDFlVJUqrlO7UiVXGigiAnbtgg4d3FXEzJnHqkAYUxyWIIwpw3JP5F22zNWVGz/elQ668kpXDmj8eEhLC3WkpiyyBGFMGZeQcKwIaM5Vxbffuk7t+vVh+HBX3mPUKCvvYYrGEoQx5VB4OPTu7Up7pKS4NXD++U9o3NgVC/zqq1BHaMoCSxDGlHPt27uSHlu3wpAh7sqidWu3bMK8ea5T+8knXSIxJjcb5mpMBdG0qSs9/vDD8Morrm+ie/ecUh9uBnc5LEhq/GBXEMZUMCecACNHujLkffq4IbKqbiG0m26C995zyxsYYwnCmAoqKgruvPP4YbJ790KvXnDSSW4Wd0qK1YCqyCxBGFOB5R0m+9NP8OGHrn9i8mQ4/3y3Et7rr5/Cd9+FOloTbAFLECIyWUR+FpGNPo6LiLwgIttE5CsRaZPrWDcR+cZzbGSgYjTGHD9MNjLSrZ09fbpLFpMnuyGyr7/emGbN3CS8CRPgt99CHbUJhkBeQUwBuuVzvDtwmmcbDLwMICLhwEue4y2Aa0SkRQDjNMZ4Ua2aW8zo009hxoyVjBkDqaluoaMTT3TFAmfNgqVLbRRUeRWwUUyqukxEGufTpCfwhqoqsFJEaohIfaAxsE1VtwOIyAxP268DFasxJn9166Zz1VVuje1162DqVLfO9pw57riI69NYuBAuvDCUkZqSJBrAHihPgpirqmd7OTYXGKOqyz3fLwJG4BJEN1W90bO/P9BOVYf5eI3BuCsQ6tWrFz9jxoxixZqWlkZsbGyxzg0Gi88/Fp9/vMWXlSWMG3c68+adCLixstHRWVx00U906vQL55yzn4iI4PRwl8X3r7RISkpao6ptvR5U1YBtuA/7jT6OfQhckOv7RUA8cCUwKdf+/sD4wrxefHy8FtfixYuLfW4wWHz+sfj84yu+FStUK1VSDQ9XjYpSTU5WjY11A2dr1lS94QbVefNUjxwJTXylRWmOD1itPj5TQzlRbg/QKNf3DYG9QJSP/caYUiZnFNSSJccWLDp0CObPd9Vk//MfePVVqFnTDZ+98kro0sV1hpvSL5QJ4n1gmKePoR2Qqqo/iMgvwGki0gT4Hrga+HsI4zTG5CMh4fjZ15UquWTQq5dbo2LBAlfqY+ZMNyrqhBOOTxZr1hyfYEzpEbAEISLTgUSgtojsAf4BRAKo6gTgI+ASYBvwJzDQcyxTRIYB84FwYLKqbgpUnMaYwImJgcsvd1t6+rFk8e678NprEBvrrjhU3VXFzJlw6aXHyn+Y0ArkKKZrCjiuwFAfxz7CJRBjTDkRHQ2XXea29HQ34unBB+HLL93x9HR3LCYGTjkFmjRx1WcbNz7+cZ06xyeQlBSYNu1koqPtCqSkWbE+Y0zQRUdDjx5Qq5a7zXTkiCv3MWwYhIXBzp2uVtSqVbBv3/HnVq58LFnExMAHH0BmZhOmTbNigyXNEoQxJmS8dXLndfCgSxg5SSP34y1bICMDQDh0CK66yq3TnZgIF1wAVasG7UcplyxBGGNCKm8nd15Vq0LLlm7LKyXFXYEcPqyEhws1a8Kzz7rFkcLDoW1blyySklyZkFI6FaHUsmJ9xpgyK+cK5IYbdrBsGaxfD/v3u/6NkSNdknj6aejWzY2eSkiA++5zneV//OGeIyXFSoX4YlcQxpgyLSEB0tN3kZDQFHB9FBdd5DZwiWDFCli82N3KGjvWJYSICDjzTNi8GbKzXb+I9WEcz64gjDHlWpUqrnz5E0+4RPH7726p1bvuco8zM12COHQIhg93x2zBJMcShDGmQomNha5dYcwYN9O7UiU3cio8HDZtcsuw1qsH113nVtc7dCjUEYeOJQhjTIWV04fx2GPw2WdunYv334eePd3w2V693LyLvn1dMklLC3XEwWV9EMaYCi3vKKqcyXwZGa7f4t13YfZslyBiYtzVx9/+5trUqBGysIPCEoQxxngRGQkXX+y2f/0Lli93yWLWLHfrKTLSDbGNi3O3qHr0KH8d3JYgjDGmAOHh0KmT2557Dr74wiWLadNcpza4kVHJya7uVPv20KpV2a9aawnCGGOKICzMJYD27d3citGj3SgoVTeXYsEC165SJTj3XNeuatXanHmm6/wuSyxBGGNMMSUlufkTR464JVfnzYMGDWDlSpcsUlLczO6MjLMZPdrVj8rp82jfHlq3Lt3lzi1BGGNMMfmqJXXKKW7kE7g1MSZNWkt6ehtWroRly2D6dHcsKsrNw1B1jz/5xNWQKi0sQRhjjB8KqiUVEwNnn32AxMRj+3bvdlcZzz8Pn3/u9qWnuxFSvXu7EVJdu0L16gENvUCWIIwxJsgaNXJbw4bHlzvv2BE+/hjefNOVArnwQjc6qkcPOP304MdpE+WMMSZEcm5RPfqou0318cfw00/uquLuu+GXX1xJkObNXYK46y43N8OVOA88u4IwxpgQynuLKjwczj/fbU8+6da++PBDmDsXXnwRnnkGqlVzFWp79IDatWHdusB0cgc0QYhIN+B53NrSk1R1TJ7j9wD9csVyJlBHVX8TkZ3AQSALyFTVtoGM1RhjSqPGjWHoULelpbmO7LlzXdL4z3+OtatUqeSr0QbsFpOIhAMvAd2BFsA1ItIidxtVHauqcaoaB4wClqrqb7maJHmOW3IwxlR4sbGuPtSkSfD99/B//3dsfe4jR9xtqpIUyD6I84BtqrpdVY8AM4Ce+bS/BpgewHiMMabcCAuDa691o6TCw90w2dwjpUqCqGrJPmPOE4v0Abqp6o2e7/sD7VR1mJe2lYE9QLOcKwgR2QH8DijwiqpO9PE6g4HBAPXq1YufMWNGseJNS0sjthSvR2jx+cfi84/F559AxrdpUzXWratBXNx+zjrrQJHPT0pKWuPzLo2qBmQDrsT1O+R83x8Y76NtX+CDPPtO8nytC6wHOhb0mvHx8VpcixcvLva5wWDx+cfi84/F55/SHB+wWn18pgbyFtMeoFGu7xsCe320vZo8t5dUda/n68/AbNwtK2OMMUESyASxCjhNRJqISBQuCbyft5GIVAc6Ae/l2ldFRKrmPAYuBjYGMFZjjDF5BGyYq6pmisgwYD5umOtkVd0kIkM8xyd4ml4BLFDVP3KdXg+YLa57PgJ4S1XnBSpWY4wxfxXQeRCq+hHwUZ59E/J8PwWYkmffdqB1IGMzxhiTPyu1YYwxxitLEMYYY7wK2DyIUBCRX4D/FfP02sCvJRhOSbP4/GPx+cfi809pju8UVa3j7UC5ShD+EJHVWopLelh8/rH4/GPx+ae0x+eL3WIyxhjjlSUIY4wxXlmCOMZrradSxOLzj8XnH4vPP6U9Pq+sD8IYY4xXdgVhjDHGK0sQxhhjvKpQCUJEuonINyKyTURGejkuIvKC5/hXItImyPE1EpHFIrJZRDaJyG1e2iSKSKqIrPNsDwY5xp0issHz2qu9HA/ZeygizXO9L+tE5ICI3J6nTVDfPxGZLCI/i8jGXPtqishCEdnq+XqCj3Pz/X0NYHxjRWSL599vtojU8HFuvr8LAYzvIRH5Pte/4SU+zg3V+/d2rth2isg6H+cG/P3zm6864OVtwxUM/A5oCkTh1phokafNJcDHgADtgf8GOcb6QBvP46rAt15iTATmhvB93AnUzud4SN/DPP/eP+ImAYXs/QM6Am2Ajbn2/RMY6Xk8EnjKR/z5/r4GML6LgQjP46e8xVeY34UAxvcQcHch/v1D8v7lOf408GCo3j9/t4p0BVGYJVB7Am+osxKoISL1gxWgqv6gqms9jw8Cm4EGwXr9EhLS9zCXLsB3qlrcmfUlQlWXAb/l2d0TeN3z+HWgl5dTi7pkb4nFp6oLVDXT8+1K3FouIeHj/SuMkL1/OcSVo76KMryUckVKEA2A3bm+38NfP3wL0yYoRKQxcA7wXy+HE0RkvYh8LCJnBTcyFFggIms8y73mVVrew78sQpVLKN8/gHqq+gO4PwpwqybmVVrex0G4K0JvCvpdCKRhnltgk33coisN79+FwE+qutXH8VC+f4VSkRKEeNmXd4xvYdoEnIjEAu8Ct6tq3kVm1+Jum7QGxgNzghxeB1VtA3QHhopIxzzHQ/4eilug6nLgHS+HQ/3+FVZpeB/vBzKBaT6aFPS7ECgvA6cCccAPuNs4eYX8/QOuIf+rh1C9f4VWkRJEYZZALcoyqQEhIpG45DBNVWflPa6qB1Q1zfP4IyBSRGoHKz4teCnYkL+HuP9wa1X1p7wHQv3+efyUc9vN8/VnL21C+j6KyPVAD6Cfem6Y51WI34WAUNWfVDVLVbOBf/t43VC/fxFAb+BtX21C9f4VRUVKEIVZAvV94DrPSJz2QGrOrYBg8NyzfBXYrKrP+GhzoqcdInIe7t9wX5DiK8xSsCF9Dz18/uUWyvcvl/eB6z2PryfXcru5FGrJ3kAQkW7ACOByVf3TR5uQLQucp0/rCh+vG7L3z+MiYIuq7vF2MJTvX5GEupc8mBtuhM23uNEN93v2DQGGeB4L8JLn+AagbZDjuwB3GfwVsM6zXZInxmHAJtyojJXA+UGMr6nnddd7YiiN72Fl3Ad+9Vz7Qvb+4RLVD0AG7q/aG4BawCJgq+drTU/bk4CP8vt9DVJ823D373N+Byfkjc/X70KQ4pvq+d36CvehX780vX+e/VNyfudytQ36++fvZqU2jDHGeFWRbjEZY4wpAksQxhhjvLIEYYwxxitLEMYYY7yyBGGMMcYrSxDGlALiqszODXUcxuRmCcIYY4xXliCMKQIRuVZEvvDU8H9FRMJFJE1EnhaRtSKySETqeNrGicjKXOsqnODZ30xEPvEUDFwrIqd6nj5WRGaKW4thWs6Mb2NCxRKEMYUkImcCfXFF1uKALKAfUAVX+6kNsBT4h+eUN4ARqtoKN/M3Z/804CV1BQPPx83EBVe993agBW6mbYcA/0jG5Csi1AEYU4Z0AeKBVZ4/7ivhCu1lc6wo25vALBGpDtRQ1aWe/a8D73jq7zRQ1dkAqnoYwPN8X6indo9nFbLGwPKA/1TG+GAJwpjCE+B1VR113E6R0Xna5Ve/Jr/bRum5Hmdh/z9NiNktJmMKbxHQR0TqwtG1pU/B/T/q42nzd2C5qqYCv4vIhZ79/YGl6tb32CMivTzPES0ilYP5QxhTWPYXijGFpKpfi8gDuFXAwnAVPIcCfwBnicgaIBXXTwGulPcETwLYDgz07O8PvCIij3ie48og/hjGFJpVczXGTyKSpqqxoY7DmJJmt5iMMcZ4ZVcQxhhjvLIrCGOMMV5ZgjDGGOOVJQhjjDFeWYIwxhjjlSUIY4wxXv0/waKb15XfbHIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import numpy \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#seed 값 설정\n",
    "seed=0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "#불러온 데이터를 학습셋과 테스트 셋으로 나누기\n",
    "(X_train, Y_train), (X_test, Y_test) = reuters.load_data(num_words=1000, test_split=0.2)\n",
    "\n",
    "#데이터 확인하기\n",
    "category = numpy.max(Y_train)+1\n",
    "\n",
    "print(category, '카테고리')\n",
    "print(len(X_train), '학습용 뉴스 기사')\n",
    "print(len(X_test),'테스트용 뉴스 기사')\n",
    "print(X_train[0])\n",
    "\n",
    "#데이터 전처리\n",
    "x_train = sequence.pad_sequences(X_train, maxlen=100)\n",
    "x_test = sequence.pad_sequences(X_test, maxlen=100)\n",
    "y_train = np_utils.to_categorical(Y_train)\n",
    "y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "#모델의 설정\n",
    "model = Sequential()\n",
    "model.add(Embedding(1000,100))\n",
    "model.add(LSTM(100, activation='tanh'))\n",
    "model.add(Dense(46, activation='softmax'))\n",
    "\n",
    "#모델의 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#모델의 실행\n",
    "history = model.fit(x_train, y_train, batch_size=100, epochs=20, validation_data=(x_test, y_test))\n",
    "\n",
    "#테스트 정확도 출력\n",
    "print('test accuracy %.4f' % (model.evaluate(x_test, y_test)[1]))\n",
    "\n",
    "#테스트 셋의 오차\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "#학습셋의 오차\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "#그래프로 표현\n",
    "x_len = numpy.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label='Trainset_loss')\n",
    "\n",
    "#그래프에 그리드를 추가하고 레이블 표시\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91c42b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19.5\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(numpy.__version__)\n",
    "\n",
    "#numpy가 1.19버전대가 아니면 위의 코드 오류남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83e8a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
