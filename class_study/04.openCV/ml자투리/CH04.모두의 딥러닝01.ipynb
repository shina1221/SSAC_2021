{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90075ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhttps://thebook.io/080228/\\n\\nAI > ML > DL\\nAI는 지도학습 ML은 지도학습과 비지도 학습을 포함\\n\\n학습: 데이터가 입력되고 패턴이 분석되는 과정\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "https://thebook.io/080228/\n",
    "\n",
    "AI > ML > DL\n",
    "AI는 지도학습 ML은 지도학습과 비지도 학습을 포함\n",
    "\n",
    "학습: 데이터가 입력되고 패턴이 분석되는 과정\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b866aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install keras\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78bcda7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "#필요한 라이브러리\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "676ecb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#실행할 때마다 같은 결과 출력을 위한설정\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "#준비된 수술환자 데이터 불러오기\n",
    "Data_set = np.loadtxt('./data/ThoraricSurgery.csv', delimiter=',')\n",
    "#환자의 기록과 수술 결과를 X와 Y로 구분해 저장\n",
    "X = Data_set[:, 0:17]\n",
    "Y = Data_set[:,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4811f38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[293.  ,   1.  ,   3.8 , ...,   0.  ,  62.  ,   0.  ],\n",
       "       [  1.  ,   2.  ,   2.88, ...,   0.  ,  60.  ,   0.  ],\n",
       "       [  8.  ,   2.  ,   3.19, ...,   0.  ,  66.  ,   1.  ],\n",
       "       ...,\n",
       "       [406.  ,   6.  ,   5.36, ...,   0.  ,  62.  ,   0.  ],\n",
       "       [ 25.  ,   8.  ,   4.32, ...,   0.  ,  58.  ,   1.  ],\n",
       "       [447.  ,   8.  ,   5.2 , ...,   0.  ,  49.  ,   0.  ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0ebe5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 1s 2ms/step - loss: 0.8508 - accuracy: 0.1489\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.8112 - accuracy: 0.1809\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.7332 - accuracy: 0.2638\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6685 - accuracy: 0.3255\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.2779 - accuracy: 0.7128\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511 ETA: 0s - loss: 0.1437 - accuracy: 0.8562  \n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 1000us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511: 0s - loss: 0.1500 - accuracy: 0.85\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 1000us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 957us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 935us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 913us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 935us/step - loss: 0.1489 - accuracy: 0.8511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21f7c9fff70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#딥러닝 구조를 결정(모델을 설정하고 실행)\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=17, activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "#딥러닝 실행\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X,Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b06c25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sequential 함수는 딥러닝의 구조를 한층한층 쉽게 쌓아올릴수 있게 해줌\n",
    "레이어가 무조건 많다고 좋은건 아님\n",
    "\n",
    "=======================================================================\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=17, activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "부분에서는  \n",
    "model.add()함수를 이용해 두 개의 층을 쌓아 올림\n",
    "\n",
    "층을 몇개 쌓을지는 데이터에 따라 그때그때 결정\n",
    "케라스를 통해 필요한 만큼의 층을 빠르고 쉽게 쌓아올릴 수 있음\n",
    "\n",
    "=======================================================================\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X,Y, epochs=100, batch_size=10)\n",
    "\n",
    "model.add()함수안에는 Dense함수가 포함되어 있음\n",
    "dense는 조밀하게 모여있는 집합이란 뜻으로 여기서는 각 층이 제각각 어떤 특성을\n",
    "가질지 옵션을 설정하는 역할을 함\n",
    "\n",
    "딥러닝의 구조와 층별 옵션을 정하고 나면 compile함수를 이용해 이를 실행\n",
    "\"\"\"\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "441b424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#수학적인 기초지식 읽어볼것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2f89102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#딥러닝의 동작원리\n",
    "import numpy as np\n",
    "x=[2,4,6,8]\n",
    "y=[81,93,91,97]\n",
    "\n",
    "#최소 제곱근 공식으로 기울기y와 b절편 a의 값을 구하기\n",
    "mx=np.mean(x)\n",
    "my=np.mean(y)\n",
    "\n",
    "#최소 제곱근 공식중 분모의 값 \n",
    "#x의 각 원소와 x의 평균값들의 차를 제곱하는 부분\n",
    "divisor = sum([(i-mx)**2 for i in x])\n",
    "\n",
    "#분자에 해당하는 부분구하기\n",
    "#x와 y의 편차를 곱해서 합한 값\n",
    "def top(x, mx, y, my):\n",
    "    d=0\n",
    "    for i in range(len(x)):\n",
    "        d += (x[i] -mx) * (y[i] -my)\n",
    "    return d\n",
    "dividend = top(x, mx, y, my)\n",
    "\n",
    "\"\"\"\n",
    "임의의 변수 d의 초깃값을 0으로 설정한 뒤 x의 개수만큼 실행함\n",
    "d에 x의 각 원소와 평균의 차, y의 각 원소와 평균의 차를 곱해서 \n",
    "차례로 더하는 최소 제곱법을 그대로 구현함\n",
    "\"\"\"\n",
    "\n",
    "#기울기 a 구하기\n",
    "a = dividend - divisor\n",
    "\n",
    "#y절편을 구하는 공식을 이용해 b구하기\n",
    "b= my - (mx*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3da15a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x의 평균값: 5.0\n",
      "y의 평균값: 90.5\n",
      "분모: 20.0\n",
      "분자: 46.0\n",
      "기울기 a= 2.3\n",
      "y 절편 b= 79.0\n"
     ]
    }
   ],
   "source": [
    "#선형회귀 실습\n",
    "import numpy as np\n",
    "\n",
    "#x값과 y값\n",
    "x = [2,4,6,8]\n",
    "y = [81,93,91,97]\n",
    "\n",
    "#x와 y의 평균값\n",
    "mx=np.mean(x)\n",
    "my=np.mean(y)\n",
    "print('x의 평균값:', mx)\n",
    "print('y의 평균값:', my)\n",
    "\n",
    "#기울기 공식의 분모\n",
    "divisor = sum([(mx-i)**2 for i in x])\n",
    "\n",
    "#기울기 공식의 분자\n",
    "def top(x, mx, y, my):\n",
    "    d = 0\n",
    "    for i in range(len(x)):\n",
    "        d += (x[i] - mx) * (y[i] - my)\n",
    "    return d\n",
    "dividend = top(x,mx,y,my)\n",
    "\n",
    "print('분모:',divisor)\n",
    "print('분자:',dividend)\n",
    "\n",
    "#기울기와 y절편 구하기\n",
    "a= dividend / divisor\n",
    "b= my - (mx*a)\n",
    "\n",
    "print(\"기울기 a=\", a)\n",
    "print('y 절편 b=', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d24685e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공부시간=2, 실제점수=81 예측점수=.82.000000\n",
      "공부시간=4, 실제점수=93 예측점수=.88.000000\n",
      "공부시간=6, 실제점수=91 예측점수=.94.000000\n",
      "공부시간=8, 실제점수=97 예측점수=.100.000000\n"
     ]
    }
   ],
   "source": [
    "#fake_a_b는 맨 처음 시작할때 초기화한 기울기임\n",
    "fake_a_b= [3,76]\n",
    "data = [[2,81], [4,93], [6,91], [8,97]]\n",
    "x = [i[0] for i in data]\n",
    "y = [i[1] for i in data]\n",
    "\n",
    "#predict()함수 사용해 일차방정식 y = ax+b 구현\n",
    "def predict(x):\n",
    "    return fake_a_b[0]*x + fake_a_b[1]\n",
    "\n",
    "#평균제곱근\n",
    "def mse(y_hat, y):\n",
    "    return ((y_hat-y)**2).mean()\n",
    "\n",
    "#mse함수에 데이터를 대입하여 최종값을 구하는 함수\n",
    "def mse_val(predict_result, y):\n",
    "    return mse(np.array(predict_result), np.array(y))\n",
    "\n",
    "#모든 x값을 predict 함수에 대입하여 예측값을 구함\n",
    "#예측 값이 들어갈 빈 리스트\n",
    "predict_result = []\n",
    "\n",
    "#모든 x값을 한 번씩 대입하여\n",
    "for i in range(len(x)):\n",
    "    #그 결과에 해당하는 predict_result 리스트 완성\n",
    "    predict_result.append(predict(x[i]))\n",
    "    print('공부시간=%.f, 실제점수=%.f 예측점수=.%f'% (x[i], y[i], predict(x[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fa9b737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공부한 시간=2, 실제점수=81 예측점수=.82.000000\n",
      "공부한 시간=4, 실제점수=93 예측점수=.88.000000\n",
      "공부한 시간=6, 실제점수=91 예측점수=.94.000000\n",
      "공부한 시간=8, 실제점수=97 예측점수=.100.000000\n",
      "mse 최종값: 11.0\n"
     ]
    }
   ],
   "source": [
    "#선형회귀 실습2\n",
    "import numpy as np\n",
    "\n",
    "#기울기 a와 y절편 b\n",
    "fake_a_b =[3,76]\n",
    "\n",
    "#x,y의 데이터 값\n",
    "data = [[2,81], [4,93], [6,91], [8,97]]\n",
    "x= [i[0] for i in data]\n",
    "y= [i[1] for i in data]\n",
    "\n",
    "#y=ax+b에 a와 b값을 대입하여 결과를 출력하는 함수\n",
    "def predict(x):\n",
    "    return fake_a_b[0]*x + fake_a_b[1]\n",
    "\n",
    "#MSE함수\n",
    "def mse(y_hat, y):\n",
    "    return ((y_hat - y)**2).mean()\n",
    "\n",
    "#MSE함수를 각 y값에 대입하여 최종 값을 구하는 함수\n",
    "def mse_val(predict_result, y):\n",
    "    return mse(np.array(predict_result), np.array(y))\n",
    "\n",
    "#예측값이 들어갈 빈 리스트\n",
    "predict_result = []\n",
    "\n",
    "#모든 x값을 한 번씩 대입하여\n",
    "for i in range(len(x)):\n",
    "    #predict_result 리스트 완성\n",
    "    predict_result.append(predict(x[i]))\n",
    "    print('공부한 시간=%.f, 실제점수=%.f 예측점수=.%f'% (x[i], y[i], predict(x[i])))\n",
    "\n",
    "#최종 MSE 출력\n",
    "print(\"mse 최종값: \" + str(mse_val(predict_result,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa01585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#오차 수정하기: 경사하강법\n",
    "\"\"\"\n",
    "경사하강법 : 오차의 변화에 따라 이차 함수 그래프를 만들고 적절한 학습률을 설정해 미분 값이 0인 지점을 구하는 것\n",
    "\n",
    "b값이 너무 크면 오차도 함께 커지고, 너무 작아도 오차가 커짐\n",
    "최적의 b값을 구할 때 역시 경사 하강법을 사용함\n",
    "\n",
    "그래프에서 오차를 비교하여 가장 작은 방향으로 이동시키는 방법이 있는데\n",
    "바로 미분 기울기 이용. 순간 기울기가 0이되는 점이 최소 기울기가 될것임\n",
    "즉 반복적으로 기울기 a를 변화시켜서 m의 값을 찾아내는 방법\n",
    "\n",
    "#학습률: 어느만큼 이동시킬지를 신중히 결정시켜야 하는데 이 때 이동거리를 정해주는 것\n",
    "기울기 변화를 얼마씩 줄것인가를 의미\n",
    "기울기가 작다면 시간이 매우 오래걸릴것임\n",
    "\"\"\"\n",
    "#파이썬 코드\n",
    "y_pred = a* x_data + b #오차함수인 y= ax+b를 정의한 부분 \n",
    "error = y_data - y_pred #실제값-예측값, 즉 오차를 구하는 식\n",
    "\n",
    "#평균제곱오차를 a로 미분한 결과\n",
    "a_diff = -(2 /len(x_data) *sum(x_data*error))\n",
    "\n",
    "#평균제곱오차를 b로 미분한 결과\n",
    "b_diff = -(1 / len(x_data)) * sum(y_data - y_pred)\n",
    "\n",
    "#학습률을 곱해 기존의 a값과 b값 업데이트\n",
    "a= a-lr*a_diff #미분결과에 학습률을 곱한 후 기존의 a값을 업데이트\n",
    "b= b-lr*a_diff #미분결과에 학습률을 곱한 후 기존의 b값을 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9bfdbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, 기울기=23.2000, 절편=4.5250\n",
      "epoch=100, 기울기=7.9316, 절편=45.3932\n",
      "epoch=200, 기울기=4.7953, 절편=64.1094\n",
      "epoch=300, 기울기=3.4056, 절편=72.4022\n",
      "epoch=400, 기울기=2.7899, 절편=76.0766\n",
      "epoch=500, 기울기=2.5171, 절편=77.7047\n",
      "epoch=600, 기울기=2.3962, 절편=78.4261\n",
      "epoch=700, 기울기=2.3426, 절편=78.7457\n",
      "epoch=800, 기울기=2.3189, 절편=78.8873\n",
      "epoch=900, 기울기=2.3084, 절편=78.9501\n",
      "epoch=1000, 기울기=2.3037, 절편=78.9779\n",
      "epoch=1100, 기울기=2.3016, 절편=78.9902\n",
      "epoch=1200, 기울기=2.3007, 절편=78.9957\n",
      "epoch=1300, 기울기=2.3003, 절편=78.9981\n",
      "epoch=1400, 기울기=2.3001, 절편=78.9991\n",
      "epoch=1500, 기울기=2.3001, 절편=78.9996\n",
      "epoch=1600, 기울기=2.3000, 절편=78.9998\n",
      "epoch=1700, 기울기=2.3000, 절편=78.9999\n",
      "epoch=1800, 기울기=2.3000, 절편=79.0000\n",
      "epoch=1900, 기울기=2.3000, 절편=79.0000\n",
      "epoch=2000, 기울기=2.3000, 절편=79.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlmUlEQVR4nO3deXjV9Z328feHhCUJ+yoBAmELKMgWUaHigrJZK1rrVrXqKNOnbm0dxurM9cwz7Qyru9YFUNtaa7UqTlshLCpuLUoQFTQJhBAgCUtYAgFCyPJ5/sixg5jASXLgl5zcr+vySnJ+y7l/mNwcvudzcszdERGR6NUs6AAiInJyqehFRKKcil5EJMqp6EVEopyKXkQkysUGHaA6nTt39j59+gQdQ0Sk0Vi9evUud+9S3bYGWfR9+vQhPT096BgiIo2GmW2uaZuWbkREopyKXkQkyqnoRUSinIpeRCTKhfVkrJndA9wOGDDf3R81s1eAlNAu7YEidx9ezbG5QDFQAZS7e2r9Y4uISLhOWPRmNoSqkh8NHAHSzOwtd7/mqH0eAvYd5zQXuvuu+oYVEZHaC2fpZjCw0t0PuXs58B5wxdcbzcyAq4GXT05EERGpj3CKfh0wzsw6mVk8MAXoddT284Ad7r6hhuMdWGpmq81sWk13YmbTzCzdzNILCwvDzS8iEhX+tnEXz7y38aSc+4RLN+6eYWazgWXAAeBzoPyoXa7j+I/mx7p7gZl1BZaZWaa7v1/N/cwD5gGkpqbql+SLSJOQtb2YWYszeDerkF4d4/jRuX2IaxET0fsI68lYd38OeA7AzGYAeaHPY4ErgVHHObYg9HGnmS2kaq3/W0UvItKUbNtXwiPL1vPa6jwSWsZy/+RB/GhMH1o1j2zJQ/hTN11DRZ1EVbGfG9p0MZDp7nk1HJcANHP34tDnE4BfRiC3iEijtP9wGc++t5HnPtxEZSXcOjaZ5M4JPLViI7MWZ5LYPo7pE1OYOqJHxO4z3N9187qZdQLKgDvcfW/o9ms5ZtnGzBKBBe4+BegGLKx6vpZY4A/unhaR5CIijciR8kpe+ngzj7+9gb2Hypg6PJF7J6SwevNe7n9jLSVlFQDkF5Vw/xtrASJW9uEu3ZxXw+03V3NbAVVP2OLuOcCweuQTEWnU3J231m5jTloWW/YcYky/Ttw/eTBDe7YD4Np5K/9R8l8rKatg7pKsU1v0IiJSex/n7GbG4kw+31rEoNPa8JtbzuL8gV0IrXIAUFBUUu2xNd1eFyp6EZEI27CjmNlpmSzP2MlpbVsx96ozuXJkT2Ka2bf2TWwfR341pZ7YPi5ieVT0IiIRsmP/YR5dvp5XVm0loUUs/zophVvHJh93kmb6xJRvrNEDxDWPYfrElBqPqS0VvYhIPRUfLmPe+zks+GAT5ZWV3DwmmTsv6k/HhBYnPPbrdfi5S7IoKCoJdOpGRESOUVZRycufbOGx5RvYffAIlw1LZPqEFJI6xdfqPFNH9IhosR9LRS8iUkvuTtq67cxZksWmXQc5O7kjz08ZzLBe7YOOVi0VvYhILazK3cOMRRms2VLEgK6tef7mVC5M6fqNSZqGRkUvIhKG7J0HmJOWydKvdtCtbUtmf38o3x/Zk9iYhv/+TSp6EZHj2Fl8mMeWb+CPq7YS1zyGf5kwkFu/k0x8i8ZTn40nqYjIKXSwtJz5H+Qw7/0cjpRXcuM5vbnrov50at0y6Gi1pqIXETlKWUUlr6zayqPLN7DrQCmXDu3O9Ikp9OmcEHS0OlPRi4hQNUmz9KsdzE7LJKfwIKP7dGTeTaMYmdQh6Gj1pqIXkSZv9ea9zFyUQfrmvfTrksD8m1K5eHDDnqSpDRW9iDRZOYUHmLski8XrttOlTUtmXDGUq1MbxyRNbajoRaTJKSwu5fG3N/DyJ1toGduMn108kNvOSyahZXRWYnRelYhINQ4dKWfBB5t49r2NHC6v5PrRSdw9fgBd2jS+SZraUNGLSNQrr6jkT6vzeGTZenYWlzLpjNOYPimFfl1aBx3tlFDRi0jUcnfeztjJrLRMsnceYFTvDjx9w0hG9e4YdLRTSkUvIlHps61FzFiUwSeb9tC3cwLP3DCKiWd0i5pJmtpQ0YtIVNm8+yBzlmTx1hfb6Ny6Bb+aOoRrz+pF8yibpKkNFb2IRIXdB0p54p1sXvp4M7HNmnH3+AFMG9eX1lE6SVMbYf0JmNk9wO2AAfPd/VEz+3+h2wpDuz3g7ouqOXYS8BgQAyxw91mRCC4iAlBypILnP9rE0ys2UlJWwTVn9eKn4wfQtW2roKM1GCcsejMbQlWhjwaOAGlm9lZo8yPu/uBxjo0Bfg1cAuQBq8zsz+7+Vb2Ti0iTVlHpvL46j4eWZbFjfymXnN6N+yal0L9rm6CjNTjhPKIfDKx090MAZvYecEWY5x8NZLt7TujYPwKXAyp6EakTd2dFViGzFmeStaOY4b3a88R1Ixmd3LQmaWojnKJfB/y3mXUCSoApQDqwG7jTzG4KfX2vu+895tgewNajvs4Dzq7uTsxsGjANICkpqTbXICJNxBd5RcxclMnfc3bTp1M8T/1wJJOHnNYkJ2lq44RF7+4ZZjYbWAYcAD4HyoGngV8BHvr4EHDrMYdX96fvNdzPPGAeQGpqarX7iEjTtHXPIeYuyeLPnxfQKaEF//m9M7hudBItYpvuJE1thPVkrLs/BzwHYGYzgDx33/H1djObD/y1mkPzgF5Hfd0TKKhzWhFpUvYePMIT72Tz4spcYpoZd13Un2nj+tKmVfOgozUq4U7ddHX3nWaWBFwJnGtm3d19W2iXK6ha4jnWKmCAmSUD+cC1wPURyC0iUexwWQUvfJTLUyuyOVhaztWpvfjpxQM5rZ0maeoi3AHT10Nr9GXAHe6+18xeNLPhVC3F5AL/DGBmiVSNUU5x93IzuxNYQtV45fPu/mWkL0JEokNFpbNwTT4PLc1i277DjB/UlfsmD2JgN03S1Ie5N7zl8NTUVE9PTw86hoicIu7O+xt2MXNRBpnbizmzZzvunzyYc/t1Cjpao2Fmq909tbptesmYiARqXf4+Zi3O5MPsXfTqGMcT143g0qHdadZMkzSRoqIXkUDk7T3Eg0uyePOzAjrEN+f/fvd0fnhOEi1jY4KOFnVU9CJyShUdOsKv383mt3/bjBn85IJ+/PiCfrTVJM1Jo6IXkVPicFkFv/t7Lk++k01xaTlXjezJzycMpHu7uKCjRT0VvYicVJWVzv98ns+DS9aTX1TCBSlduG/SIAZ3bxt0tCZDRS8iJ82HG3Yxc3EGXxbsZ0iPtsy56kzG9u8cdKwmR0UvIhH3VcF+ZqVl8v76Qnq0j+Oxa4dz2ZmJmqQJiIpeRCImv6iEh5ZmsXBNPm1bNeffLx3Mjef21iRNwFT0IlJv+0rKeGpFNi98lAvAtHF9+cn5/WkXr0mahkBFLyJ1VlpewYt/38yT72azr6SMK0b04N4JKfRor0mahkRFLyK1Vlnp/OWLAuYuySJvbwnnDejMLyYP4ozEdkFHk2qo6EWkVv62cRczF2WyNn8fg7u35Xe3DmXcwC5Bx5LjUNGLSFgyt+9n9uJM3s0qJLFdKx6+ehhTh/fQJE0joKIXkePatq+Eh5eu57VP82jdMpb7Jw/iR2P60Kq5JmkaCxW9iFRr/+Eynlmxkec+3IQ73PadZO64sD/t41sEHU1qSUUvJ82ba/KZuySLgqISEtvHMX1iClNH9Ag6lpzAkfJKXvp4M4+/vYG9h8qYOjyReyek0KtjfNDRpI5U9HJSvLkmn/vfWEtJWQVQ9UKa+99YC6Cyb6DcnbfWbmNOWhZb9hxiTL9O3D95MEN7apKmsVPRy0kxd0nWP0r+ayVlFcxdkqWib4BW5uxm5qIMPs/bx6DT2vCbW87i/IFdMNMTrdFARS8nRUFRSa1ul2Cs31HM7MWZvJ25k+7tWjH3qjO5cmRPYjRJE1VU9HJSJLaPI7+aUk/UKyYbhB37D/PIsvW8mr6VhBax3DdpELeM1SRNtFLRy0kxfWLKN9boAeKaxzB9YkqAqaT4cBnz3s9h/gc5VFQ6N49J5s6L+tMxQZM00Sysojeze4DbAQPmu/ujZjYXuAw4AmwEbnH3omqOzQWKgQqgvKZ3KZfo8vU6vKZuGoayikpe/mQLjy3fwO6DR7hsWCLTJ6SQ1EmTNE2BufvxdzAbAvwRGE1VqacB/wdIBt5x93Izmw3g7vdVc3wukOruu8INlZqa6unp6eHuLiI1cHfS1m1nzpIsNu06yNnJHXlgymCG9WofdDSJMDNbXdMD6XAe0Q8GVrr7odDJ3gOucPc5R+2zEriq3klFJGJW5e5hxqIM1mwpYmC31jx/cyoXpnTVJE0TFE7RrwP+28w6ASXAFODYh9u3Aq/UcLwDS83MgWfdfV51O5nZNGAaQFJSUhixRKQ62TsPMDstk2Vf7aBb25bM/v5QrhrVS5M0TdgJi97dM0JLM8uAA8DnQPnX283s30Jfv1TDKca6e4GZdQWWmVmmu79fzf3MA+ZB1dJNra9EpInbWXyYR5dv4JVVW//xxPetY5OJa6FJmqYurCdj3f054DkAM5sB5IU+/xHwXWC817DY7+4FoY87zWwhVWv93yp6Eambg6Xl/5ikOVJeyY3n9Oaui/rTqXXLoKNJAxHu1E3XUFEnAVcC55rZJOA+4Pyv1++rOS4BaObuxaHPJwC/jFB2kSatrKKSV1Zt5dHlG9h1oJRLh3Zn+sQU+nROCDqaNDDhztG/HlqjLwPucPe9ZvYk0JKq5RioesL2x2aWCCxw9ylAN2BhaHss8Ad3T4v4VYg0Ie7O0q92MDstk5zCg4zu05F5N41iZFKHoKNJAxXu0s151dzWv4Z9C6h6whZ3zwGG1SegiPyv1Zv3MnNRBumb99KvSwLzb0rl4sGapJHj0ytjRRqBnMIDzEnLIu3L7XRp05IZVwzl6tSexMY0CzqaNAIqepEGrLC4lMff3sAfPtlCq9hm/PySgdx2XjLxLfSjK+HTd4tIA3ToSDkLPtjEs+9t5HB5JdePTuLu8QPo0kaTNFJ7KnqRBqS8opI/rc7j4WXrKSwuZdIZpzF9Ugr9urQOOpo0Yip6kQbA3VmesZPZaZlk7zzAqN4deOaGkYzq3THoaBIFVPQiAVuzZS8zF2XySe4e+nZO4JkbRjHxjG6apJGIUdGLBCR310HmLsnirbXb6Ny6Bb+aOoRrz+pFc03SSISp6EVOsd0HSnninWx+v3IzzWOacc/4Adw+ri+tW+rHUU4OfWeJnCIlRyp4/qNNPL1iIyVlFVxzVi9+On4AXdu2CjqaRDkVvchJVlHpvL46j4eWZbFjfymXnN6N+yal0L9rm0DyvLkmX+/81cSo6EVOEndnRVYhMxdnsH7HAYb3as8T141kdHJwkzRvrsn/xnv55heVcP8bawFU9lFMRS9yEnyRV8SMRRmszNlDn07xPPXDkUweclrgkzRzl2R94w3bAUrKKpi7JEtFH8VU9CIRtGX3IeYuzeIvnxfQKaEFv7z8DK4bndRgJmkKikpqdbtEBxW9SATsPXiEJ97J5sWVucQ0M+66qD/TxvWlTavmQUf7hsT2ceRXU+qJ7eMCSCOniopepB4Ol1Xwwke5PLUim4Ol5Vyd2oufXjyQ09o1zEma6RNTvrFGD/zjbQcleqnoReqgotJZuCafh5ZmsW3fYcYP6sp9kwcxsFswkzTh+nodXlM3TYuKXqQW3J331hcya3EmmduLGdazHQ9fPZxz+3UKOlrYpo7ooWJvYlT0ImFal7+PmYsz+Ch7N0kd43ny+hFcOrR74JM0Iieiohc5ga17DvHQ0ize/KyADvHN+Y/LTueHZ/emRWzDmKQROREVvUgNig4d4dfvZvPbv23GDH5yQT9+fEE/2jawSRqRE1HRixzjcFkFv/t7Lk++k01xaTlXjezJzycMpHs7jSBK4xRW0ZvZPcDtgAHz3f1RM+sIvAL0AXKBq919bzXHTgIeA2KABe4+KzLRRSKrstL5n8/zeXDJevKLSrggpQv3TRrE4O5tg44mUi8nLHozG0JVyY8GjgBpZvZW6La33X2Wmf0C+AVw3zHHxgC/Bi4B8oBVZvZnd/8qspchUj8fbtjFjEUZfLVtP0N6tGXOVWcytn/noGOJREQ4j+gHAyvd/RCAmb0HXAFcDlwQ2ue3wAqOKXqq/nLIdvec0LF/DB2nopcG4auC/cxcnMEHG3bRs0Mcj107nMvOTKRZM03SSPQIp+jXAf9tZp2AEmAKkA50c/dtAO6+zcy6VnNsD2DrUV/nAWdXdydmNg2YBpCUlBT2BYjURX5RCQ8tzWLhmnzatmrOv186mBvP7U3L2Jigo4lE3AmL3t0zzGw2sAw4AHwOlId5/uoeFnkN9zMPmAeQmppa7T4i9bWvpIynVmTzwke5AEwb15efnN+fdvGapJHoFdaTse7+HPAcgJnNoOqR+Q4z6x56NN8d2FnNoXlAr6O+7gkU1C+ySO2Vllfw4t838+S72ewrKeOKET24d0IKPfTLvKQJCHfqpqu77zSzJOBK4FwgGfgRMCv08X+qOXQVMMDMkoF84Frg+kgEFwlHZaXzly8KmLski7y9JZw3oDO/mDyIMxLbBR1N5JQJd47+9dAafRlwh7vvNbNZwKtm9k/AFuAHAGaWSNUY5RR3LzezO4ElVI1XPu/uX0b+MkS+7W/Zu5ixOIN1+fsZ3L0tv7t1KOMGdgk6lsgpZ+4Nbzk8NTXV09PTg44hjVTm9v3MWpzJiqxCEtu14l8mpjB1eA9N0khUM7PV7p5a3Ta9MlaixrZ9JTy8dD2vfZpHm5axPDBlEDed24dWzTVJI02bil4avf2Hy3hmxUae+3AT7nDbd5K548L+tI9vEXQ0kQZBRS+N1pHySl76eDOPv72BvYfKmDo8kXsnpNCrY3zQ0UQaFBW9NDruzltrtzEnLYstew4xpl8nHpgymCE9NEkjUh0VvTQqK3N2M3NRBp/n7WPQaW34zS1ncf7ALnrzD5HjUNFLo7B+RzGzF2fyduZOurdrxdyrzuTKkT2J0SSNyAmp6KVB27H/MI8sW8+r6VtJaBHLfZMGcctYTdKI1IaKXhqk4sNlzHs/h/kf5FBR6dw8Jpk7L+pPxwRN0ojUlopeGpQj5ZW8/MkWHn97A7sPHuGyYYlMn5BCUidN0ojUlYpeGgR3Z/G67cxJyyR39yHO6duR5ycPZliv9kFHE2n0VPQSuFW5e5ixKIM1W4oY2K01L9x8FhekaJJGJFJU9BKY7J0HmJ2WybKvdtCtbUvmfP9Mvj9KkzQikaail1NuZ/FhHl2+gVdWbSWueQzTJ6Zw69hk4lpokkbkZFDRyylzoLSc+aFJmiPlldx4Tm/uuqg/nVq3DDqaSFRT0ctJV1ZRySurtvLo8g3sOlDKpUO7M31iCn06JwQdTaRJUNHLSePuLPlyB3PSMsnZdZDRfToy/6ZRjEjqEHQ0kSZFRS8nxerNe5ixKJPVm/fSv2tr5t+UysWDu2qSRiQAKnqJqJzCA8xJyyLty+10adOSmVcO5QejehIb0yzoaCJNlopeIqKwuJTH397AHz7ZQqvYZvz8koHcdl4y8S30LSYSNP0USr0cOlLOgg828ex7GzlcXsn1o5O4e/wAurTRJI1IQ6Gilzopr6jk1fQ8Hlm+nsLiUiadcRrTJ6XQr0vroKOJyDHCKnoz+xlwG+DAWuAW4LdASmiX9kCRuw+v5thcoBioAMprepdyaRzcneUZO5m1OIONhQcZ1bsDz9wwklG9OwYdTURqcMKiN7MewN3A6e5eYmavAte6+zVH7fMQsO84p7nQ3XfVO60Eas2WvcxclMknuXvo2zmBZ28cxYTTu2mSRqSBC3fpJhaIM7MyIB4o+HqDVf2UXw1cFPl40hDk7jrI3CVZvLV2G51bt+C/pg7hmrN60VyTNCKNwgmL3t3zzexBYAtQAix196VH7XIesMPdN9R0CmCpmTnwrLvPq29oOTV2HyjliXey+f3KzTSPacY94wdw+7i+tG6pp3ZEGpNwlm46AJcDyUAR8Cczu8Hdfx/a5Trg5eOcYqy7F5hZV2CZmWW6+/vV3M80YBpAUlJS7a5CIqrkSAXPf7SJp1dspKSsgmvO6sVPxw+ga9tWQUcTkToI56HZxcAmdy8EMLM3gDHA780sFrgSGFXTwe5eEPq408wWAqOBbxV96JH+PIDU1FSv5XVIBFRUOq+vzuOhZVns2F/KJad3475JKfTv2iboaCJSD+EU/RbgHDOLp2rpZjyQHtp2MZDp7nnVHWhmCUAzdy8OfT4B+GX9Y0skuTvvZu1k1uJM1u84wPBe7XniupGMTtYkjUg0CGeN/mMzew34FCgH1hB65A1cyzHLNmaWCCxw9ylAN2BhaCojFviDu6dFLr7U1xd5RcxYlMHKnD306RTPUz8cyeQhp2mSRiSKmHvDWyVJTU319PT0E+8odbZl9yHmLs3iL58X0CmhBfdcPIDrRidpkkakkTKz1TW9TknjE03M3oNHeOKdbF5cmUtMM+Oui/ozbVxf2rRqHnQ0ETlJVPRNxOGy/52kOVhaztWpvfjZJQPppkkakainoo9yFZXOG5/m8fCy9Wzbd5jxg7py3+RBDOymSRqRpkJFH6XcnffWFzJrcSaZ24sZ1rMdj1wznHP6dgo6moicYir6KLQufx8zF2fwUfZukjrG8+T1I7h0aHdN0og0USr6KLJ1zyEeWprFm58V0CG+Of9x2en88OzetIjVJI1IU6aijwJFh47w63ez+e3fNmMGP7mgHz++oB9tNUkjIqjoG7XDZRX87u+5PPlONsWl5Vw1sic/nzCQ7u3igo4mIg2Iir4Rqqx03vwsn4eWrie/qIQLUrrwi8mDGHRa26CjiUgDpKJvZD7YUMjMRZl8tW0/Q3q0Ze5VZzKmf+egY4lIA6aibyS+LNjHrMWZfLBhFz07xPHYtcO57MxEmjXTJI2IHJ+KvoHLLyrhoaVZLFyTT9tWzfn3Swdz47m9aRkbE3Q0EWkkVPQN1L6SMp5akc0LH+UCMG1cX35yfn/axWuSRkRqR0XfwJSWV/Di3zfz5LvZ7Csp44oRPbh3Qgo92muSRkTqRkXfQFRWOn/5ooC5S7LI21vCeQM684vJgzgjsV3Q0USkkVPRNwB/y97FjMUZrMvfz+nd2/LiPw3lvAFdgo4lIlFCRR+gzO37mbU4kxVZhfRoH8cj1wzj8mE9NEkjIhGlog/Atn0lPLx0Pa99mkeblrE8MGUQN53bh1bNNUkjIpGnoj+F9h8u4+kVG3n+w024w23fSeaOC/vTPr5F0NFEJIqp6E+BI+WV/H7lZp54ZwN7D5UxdXgi905IoVfH+KCjiUgToKI/idydv36xjblLstiy5xBj+nXigSmDGdJDkzQicuqo6E+SlTm7mbkog8/z9jHotDb85pazOH9gF735h4iccmEVvZn9DLgNcGAtcAvwC+B2oDC02wPuvqiaYycBjwExwAJ3nxWB3A3W+h3FzF6cyduZO+nerhUP/mAYV4zoQYwmaUQkICcsejPrAdwNnO7uJWb2KnBtaPMj7v7gcY6NAX4NXALkAavM7M/u/lX9ozcsO/Yf5pFl63k1fSsJLWK5b9IgbhmrSRoRCV64SzexQJyZlQHxQAHQJ4zjRgPZ7p4DYGZ/BC4Hoqboiw+X8ex7OSz4MIeKSufmMcnceVF/OiZokkZEGoYTFr2755vZg8AWoARY6u5LzWwMcKeZ3QSkA/e6+95jDu8BbD3q6zzg7Orux8ymAdMAkpKSan0hp9qR8kpe/mQLj729gT0Hj3DZsESmT0ghqZMmaUSkYQln6aYDVY/Ck4Ei4E9mdgPwNPArqtbtfwU8BNx67OHVnNKrux93nwfMA0hNTa12n4bA3Vm8bjtz0jLJ3X2Ic/p25IEpgzmzZ/ugo4mIVCucpZuLgU3uXghgZm8AY9z991/vYGbzgb9Wc2we0Ouor3tStezTKH2yaQ8zFmXw2dYiBnZrzQs3n8UFKZqkEZGGLZyi3wKcY2bxVC3djAfSzay7u28L7XMFsK6aY1cBA8wsGcin6knc6+sf+9TK3nmA2WmZLPtqB93atmTO98/k+6N6apJGRBqFcNboPzaz14BPgXJgDVVLLAvMbDhVSzG5wD8DmFkiVWOUU9y93MzuBJZQNV75vLt/eTIu5GTYuf8wj769gVdWbSWueQzTJ6Zw69hk4lpokkZEGg9zb3jL4ampqZ6enh7Y/R8oLWfe+znMfz+HsopKbjinN3dd1J9OrVsGlklE5HjMbLW7p1a3Ta+MPUpZRSV/XLWVx5avZ9eBI1w6tDvTJ6bQp3NC0NFEROpMRU/VJM2SL3cwJy2TnF0HGd2nI/NvGsSIpA5BRxMRqbcmX/SrN+9hxqJMVm/eS/+urVlwUyrjB3fVJI2IRI0mW/Q5hQeYk5ZF2pfb6dKmJTOvHMoPRvUkNqZZ0NFERCKqyRV9YXEpj729npc/2Uqr2Gb8/JKB3HZeMvEtmtwfhYg0EU2m3Q6WlrPgg03Me38jh8sruX50EnePH0CXNpqkEZHoFvVFX15RyavpeTyyfD2FxaVMOuM0pk9KoV+X1kFHExE5JaK26N2d5Rk7mbU4g42FBxnVuwPP3DCSUb07Bh1NROSUisqiX7NlLzMXZfJJ7h76dk7g2RtHMeH0bpqkEZEmKaqKPnfXQeYuyeKttdvo3LoF/zV1CNec1YvmmqQRkSYsaop+X0kZUx7/AIB7xg/g9nF9ad0yai5PRKTOoqYJ28U1Z+5VwzirTwe6tm0VdBwRkQYjaooe4NIzuwcdQUSkwdHitYhIlFPRi4hEORW9iEiUU9GLiEQ5Fb2ISJRT0YuIRDkVvYhIlFPRi4hEubCK3sx+ZmZfmtk6M3vZzFqZ2VwzyzSzL8xsoZm1r+HYXDNba2afmVl6RNOLiMgJnbDozawHcDeQ6u5DgBjgWmAZMMTdzwTWA/cf5zQXuvtwd0+NQGYREamFcJduYoE4M4sF4oECd1/q7uWh7SuBnicjoIiI1M8Ji97d84EHgS3ANmCfuy89ZrdbgcU1nQJYamarzWxaTfdjZtPMLN3M0gsLC8NLLyIiJxTO0k0H4HIgGUgEEszshqO2/xtQDrxUwynGuvtIYDJwh5mNq24nd5/n7qnuntqlS5daXoaIiNQknKWbi4FN7l7o7mXAG8AYADP7EfBd4Ifu7tUd7O4FoY87gYXA6EgEFxGR8IRT9FuAc8ws3qrei288kGFmk4D7gO+5+6HqDjSzBDNr8/XnwARgXWSii4hIOE74++jd/WMzew34lKolmjXAPOBLoCWwLPRerCvd/cdmlggscPcpQDdgYWh7LPAHd087KVciIiLVshpWXAKVmprq6ekauRcRCZeZra5phF2vjBURiXIqehGRKKeiFxGJcip6EZEop6IXEYlyKnoRkSinohcRiXIqehGRKKeiFxGJcif8FQiNxZtr8pm7JIuCohIS28cxfWIKU0f0CDqWiEjgoqLo31yTz/1vrKWkrAKA/KIS7n9jLYDKXkSavKhYupm7JOsfJf+1krIK5i7JCiiRiEjDERVFX1BUUqvbRUSakqgo+sT2cbW6XUSkKYmKop8+MYW45jHfuC2ueQzTJ6YElEhEpOGIiidjv37CVVM3IiLfFhVFD1Vlr2IXEfm2qFi6ERGRmqnoRUSinIpeRCTKqehFRKKcil5EJMqZuwed4VvMrBDYXMfDOwO7IhgnSNFyLdFyHaBraYii5TqgftfS2927VLehQRZ9fZhZurunBp0jEqLlWqLlOkDX0hBFy3XAybsWLd2IiEQ5Fb2ISJSLxqKfF3SACIqWa4mW6wBdS0MULdcBJ+laom6NXkREvikaH9GLiMhRVPQiIlEuKorezHqZ2btmlmFmX5rZPUFnqisza2Vmn5jZ56Fr+c+gM9WHmcWY2Roz+2vQWerLzHLNbK2ZfWZm6UHnqSsza29mr5lZZuhn5tygM9WFmaWE/l98/d9+M/tp0Lnqysx+FvqZX2dmL5tZq4idOxrW6M2sO9Dd3T81szbAamCqu38VcLRaMzMDEtz9gJk1Bz4E7nH3lQFHqxMz+zmQCrR19+8Gnac+zCwXSHX3Rv3iHDP7LfCBuy8wsxZAvLsXBRyrXswsBsgHznb3ur7YMjBm1oOqn/XT3b3EzF4FFrn7byJx/qh4RO/u29z909DnxUAG0Ch/Ob1XORD6snnov0b5t7GZ9QQuBRYEnUWqmFlbYBzwHIC7H2nsJR8yHtjYGEv+KLFAnJnFAvFAQaROHBVFfzQz6wOMAD4OOEqdhZY7PgN2AsvcvbFey6PAvwKVAeeIFAeWmtlqM5sWdJg66gsUAi+EltQWmFlC0KEi4Frg5aBD1JW75wMPAluAbcA+d18aqfNHVdGbWWvgdeCn7r4/6Dx15e4V7j4c6AmMNrMhAUeqNTP7LrDT3VcHnSWCxrr7SGAycIeZjQs6UB3EAiOBp919BHAQ+EWwkeontPz0PeBPQWepKzPrAFwOJAOJQIKZ3RCp80dN0YfWs18HXnL3N4LOEwmhf1KvACYFm6ROxgLfC61r/xG4yMx+H2yk+nH3gtDHncBCYHSwieokD8g76l+Jr1FV/I3ZZOBTd98RdJB6uBjY5O6F7l4GvAGMidTJo6LoQ09gPgdkuPvDQeepDzPrYmbtQ5/HUfUNkBloqDpw9/vdvae796Hqn9XvuHvEHqGcamaWEHqin9BSxwRgXbCpas/dtwNbzSwldNN4oNENLRzjOhrxsk3IFuAcM4sP9dl4qp5rjIhoeXPwscCNwNrQ2jbAA+6+KLhIddYd+G1oiqAZ8Kq7N/rRxCjQDVhY9TNILPAHd08LNlKd3QW8FFryyAFuCThPnZlZPHAJ8M9BZ6kPd//YzF4DPgXKgTVE8NchRMV4pYiI1Cwqlm5ERKRmKnoRkSinohcRiXIqehGRKKeiFxGJcip6EZEop6IXEYly/x8L6tpuVrfDkgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#경사하강법 실습\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#공부시간 x와 성적 y의 리스트 만들기\n",
    "data = [[2,81], [4,93], [6,91], [8,97]]\n",
    "x = [i[0] for i in data]\n",
    "y = [i[1] for i in data]\n",
    "\n",
    "#그래프로 나타내기\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(x,y)\n",
    "plt.show()\n",
    "\n",
    "#리스트로 되어 있는 x와 y값을 넘파이 배열로 바꾸기(인덱스를 주어 하나씩 불러와 계산이 가능하게 하기 위함)\n",
    "x_data = np.array(x)\n",
    "y_data = np.array(y)\n",
    "\n",
    "#기울기 a와 절편 b의 값 초기화\n",
    "a=0\n",
    "b=0\n",
    "\n",
    "#학습률 정하기\n",
    "lr = 0.05\n",
    "#몇번 반복될지 설정(0부터 세므로 원하는 반복 횟수에 +1)\n",
    "epochs = 2001\n",
    "\n",
    "#경사하강법 시작\n",
    "for i in range(epochs): #에포크 수만큼 반복\n",
    "    y_pred = a * x_data + b #y를 구하는 식 세우기\n",
    "    error = y_data - y_pred #오차를 구하는 식\n",
    "    #오차함수를 a로 미분한 값\n",
    "    a_diff = -(1/len(x_data)) * sum(x_data*(error))\n",
    "    #오차함수를 b로 미분한 값\n",
    "    b_diff = -(1/len(x_data)) * sum(y_data - y_pred)\n",
    "    a= a-lr*a_diff #학습률을 곱해 기존의 a값 업데이트\n",
    "    b= b-lr*b_diff #학습률을 곱해 기존의 b값 업데이트\n",
    "    \n",
    "    if i %100 ==0: #100번 반복될 때마다 현재의 a,b값 출력\n",
    "        print('epoch=%.f, 기울기=%.04f, 절편=%.04f'%(i,a,b))\n",
    "\n",
    "#앞서구한 기울기와 절편을 이용해 그래프를 다시 그리기\n",
    "y_pred = a*x_data +b\n",
    "plt.scatter(x,y)\n",
    "plt.plot([min(x_data), max(x_data)], [min(y_pred), max(y_pred)])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
