{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6917c3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#선형회귀 적용하기\n",
    "#선형 회귀 데이터는 마지막에 참과 거짓을 구분할 필요가 없음\n",
    "#출력층에 활성화 함수를 지정할 필요도 없음\n",
    "model = Sequeltial()\n",
    "model.add(Dense(30, input_dim=13, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77900df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델의 학습이 어느 정도 되었는지 확인하기 위해 예측 값과 실제 값을 비교하는 부분을 추가함\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "for i in range(10):\n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2425809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten( ) 함수\n",
    "\"\"\"\n",
    "데이터 배열이 몇 차원이든 모두 1차원으로 바꿔 읽기 쉽게 해 주는 함수\n",
    "range('숫자')는 0부터 ‘숫자-1’만큼 차례대로 증가하며 반복되는 값을 만듦\n",
    "즉, range(10)은 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]를 말함\n",
    "for in 구문을 사용해서 10번 반복하게 함\n",
    "\"\"\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac3eb79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       506 non-null    float64\n",
      " 1   1       506 non-null    float64\n",
      " 2   2       506 non-null    float64\n",
      " 3   3       506 non-null    int64  \n",
      " 4   4       506 non-null    float64\n",
      " 5   5       506 non-null    float64\n",
      " 6   6       506 non-null    float64\n",
      " 7   7       506 non-null    float64\n",
      " 8   8       506 non-null    int64  \n",
      " 9   9       506 non-null    float64\n",
      " 10  10      506 non-null    float64\n",
      " 11  11      506 non-null    float64\n",
      " 12  12      506 non-null    float64\n",
      " 13  13      506 non-null    float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/housing.csv', delim_whitespace=True, header=None)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eafa967b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "36/36 [==============================] - 1s 2ms/step - loss: 12851.5596\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1367.1437\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 703.8331\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 632.8430\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 606.3589\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 600.6735\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 599.0093\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 597.8168\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 596.5664\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 595.3091\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 594.0577\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 592.8288\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - ETA: 0s - loss: 603.573 - 0s 2ms/step - loss: 591.7297\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 590.6288\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 589.5336\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 588.4547\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 587.3574\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 586.2466\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 585.1137\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 583.9634\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 582.7973\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 581.6094\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 580.4107\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 579.1919\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 577.9699\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 576.7314\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 575.4822\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 574.2310\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 572.9552\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 571.6836\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 570.4036\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 569.1078\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 567.8051\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 566.5029\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 565.1920\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 563.8735A: 0s - loss: 563.770\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 562.5490\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 561.2170\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 559.8840\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 558.5427\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 557.2033\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 555.8546\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 554.4990\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 553.1412\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 551.7845\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 550.4164\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 549.0586\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 547.6896\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 546.3195\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 544.9507\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 543.5781\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 542.2065\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 540.8322\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 539.4503\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 538.0706\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 536.6855\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 535.3097\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 533.9280\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 532.5583\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 531.1771\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 529.8013\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 528.4276\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 527.0428\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 525.6669\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 524.2919\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 522.8954\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 521.5151\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 520.1326\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 518.7517\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 517.3672\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 515.9805\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 514.6069\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 513.2316\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 511.8508\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 510.4682\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 509.0892\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 507.7146\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 506.3460\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 504.9715\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 503.5910\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 502.2381\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 500.8639\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 499.4935\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 498.1364\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 496.7715\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 495.4071\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 494.0510\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 492.6925\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 491.3445\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 489.9879\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 488.6365\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 487.2870\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 485.9398\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 484.5990\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 483.2574\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 481.9106\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 480.5728\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 479.2287\n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 477.8863\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 476.5485\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 475.2158\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 473.8769\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 472.5539\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 471.2159\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 469.8925\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 468.5744\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 467.2504\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 465.9236\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 464.6040\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 463.2846\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 461.9827\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 460.6646\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 459.3480\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 458.0378\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 456.7432\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 455.4420\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 454.1426\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 452.8442\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 451.5457\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 450.2564\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 448.9638\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 447.6761\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 446.3845\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 445.1117\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 443.8192\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 442.5441\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 441.2662\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 439.9868\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 438.7145\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 437.4392\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 436.1744\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 434.9164\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 433.6449\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 432.3926\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 431.1305\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 429.8663\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 428.6212\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 427.3548\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 426.1119\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 424.8553\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 423.6131\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 422.3658\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 421.1334\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 419.8969\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 418.6628\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 417.4339\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 416.2048\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 414.9771\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 413.7473\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 412.5187\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 411.2999\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 410.0837\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 408.8654\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 407.6427\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 406.4359\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 405.2324\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 404.0320\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 402.8243\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 401.6175\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 400.4134\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 399.2195\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 398.0281\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 396.8281\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 395.6427\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 394.4474\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 393.2583\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 392.0764\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 390.8918\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 389.7256\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 388.5482\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 387.3829\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 386.2122\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 385.0489\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 383.8831\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 382.7233\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 381.5621\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 380.3992\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 379.2476\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 378.0868\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 376.9323\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 375.7831\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 374.6511\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 373.5032\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 372.3703\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 371.2253\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 370.0949\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 368.9595\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 367.8267\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 366.7049\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 365.5777\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 364.4524\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 363.3317\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 362.2110\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 361.0874\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 359.9727\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 358.8559\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 357.7484\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 356.6429\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 355.5373\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 354.4305\n",
      "실제가격: 22.600, 예상가격: 6.342\n",
      "실제가격: 50.000, 예상가격: 6.342\n",
      "실제가격: 23.000, 예상가격: 6.342\n",
      "실제가격: 8.300, 예상가격: 6.342\n",
      "실제가격: 21.200, 예상가격: 6.342\n",
      "실제가격: 19.900, 예상가격: 6.342\n",
      "실제가격: 20.600, 예상가격: 6.342\n",
      "실제가격: 18.700, 예상가격: 6.342\n",
      "실제가격: 16.100, 예상가격: 6.342\n",
      "실제가격: 18.600, 예상가격: 6.342\n"
     ]
    }
   ],
   "source": [
    "#보스턴 집값 예측하기\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#Seed값 설정\n",
    "seed=0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df = pd.read_csv('./data/housing.csv', delim_whitespace=True, header=None)\n",
    "\n",
    "dataset = df.values\n",
    "X=dataset[:,0:13]\n",
    "Y=dataset[:,13]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X,Y, test_size=0.3, random_state=seed) \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=13, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, Y_train, epochs=200, batch_size=10)\n",
    "\n",
    "#예측값과 실제 값의 비교\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "for i in range(10):\n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label, prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f90cfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 39s 3us/step\n",
      "11501568/11490434 [==============================] - 39s 3us/step\n",
      "학습셋 이미지 수:60000 개\n",
      "테스트셋 이미지 수:10000 개\n"
     ]
    }
   ],
   "source": [
    "#데이터 전처리\n",
    "#mnist.load_data()함수로 사용할 데이터 불러올 수 있음\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\"\"\"\n",
    "학습에 사용될 부분: X_train, Y_class_train\n",
    "테스트에 사용될 부분: X_test, Y_class_test\n",
    "\"\"\"\n",
    "(X_train, Y_class_train), (X_test, Y_class_test) = mnist.load_data()\n",
    "\n",
    "print('학습셋 이미지 수:%d 개'%(X_train.shape[0]))\n",
    "print('테스트셋 이미지 수:%d 개'%(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77ab5e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#불러온 이미지 중 한개만 다시 불러와 봄\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0], cmap='Greys')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "이 이미지는 가로 28 × 세로 28 = 총 784개의 픽셀로 이루어져 있음\n",
    "각 픽셀은 밝기 정도에 따라 0부터 255까지의 등급을 매김\n",
    "흰색 배경이 0이라면 글씨가 들어간 곳은 1~255까지 숫자 중 하나로 채워져 \n",
    "긴 행렬로 이루어진 하나의 집합으로 변환됨\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "666c359c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t3\t18\t18\t18\t126\t136\t175\t26\t166\t255\t247\t127\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t30\t36\t94\t154\t170\t253\t253\t253\t253\t253\t225\t172\t253\t242\t195\t64\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t49\t238\t253\t253\t253\t253\t253\t253\t253\t253\t251\t93\t82\t82\t56\t39\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t18\t219\t253\t253\t253\t253\t253\t198\t182\t247\t241\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t80\t156\t107\t253\t253\t205\t11\t0\t43\t154\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t14\t1\t154\t253\t90\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t139\t253\t190\t2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t11\t190\t253\t70\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t35\t241\t225\t160\t108\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t81\t240\t253\t253\t119\t25\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t45\t186\t253\t253\t150\t27\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t16\t93\t252\t253\t187\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t249\t253\t249\t64\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t46\t130\t183\t253\t253\t207\t2\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t39\t148\t229\t253\t253\t253\t250\t182\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t24\t114\t221\t253\t253\t253\t253\t201\t78\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t23\t66\t213\t253\t253\t253\t253\t198\t81\t2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t18\t171\t219\t253\t253\t253\t253\t195\t80\t9\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t55\t172\t226\t253\t253\t253\t253\t244\t133\t11\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t136\t253\t253\t253\t212\t135\t132\t16\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "for x in X_train[0]:\n",
    "    for i in x:\n",
    "        sys.stdout.write('%d\\t' % i)\n",
    "    sys.stdout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38687f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "이미지는 다시 숫자의 집합으로 바뀌어 학습셋으로 사용됨\n",
    "이제 주어진 가로 28, 세로 28의 2차원 배열을 784개의 1차원 배열로 \n",
    "바꿔 주어야 하는데 이를 위해 reshape( ) 함수를 사용함\n",
    "\"\"\"\n",
    "X_train= X_train.reshape(X_train.shape[0], 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8aa7834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class : 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "정규화(normalization) :\n",
    "데이터의 폭이 클 때 적절한 값으로 분산의 정도를 바꾸는 과정\n",
    "현재 주어진 데이터의 값은 0부터 255까지의 정수로, 정규화를 위해 \n",
    "\"\"\"\n",
    "X_train = X_train.astype('float64')\n",
    "X_train = X_train/255\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 784).astype('float64') / 255\n",
    "\n",
    "#실제로 이 숫자의 레이블이 어떤지 불러오고자 Y_class_train[0] 출력\n",
    "print('class : %d'%(Y_class_train[0]))\n",
    "\"\"\"\n",
    "아이리스 품종을 예측할 때 딥러닝의 분류 문제를 해결하려면\n",
    "원-핫 인코딩 방식을 적용해야 함\n",
    "\n",
    "즉, 0~9까지의 정수형 값을 갖는 현재 형태에서 0 또는 1로만 \n",
    "이루어진 벡터로 값을 수정해야 함\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3186836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "지금 우리가 열어본 이미지의 class는 [5]였음\n",
    "이를 [0,0,0,0,0,1,0,0,0,0]로 바꿔야 함\n",
    "이를 가능하게 해 주는 함수가 바로 np_utils.to_categorical( ) 함수\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4da18891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "Y_train = np_utils.to_categorical(Y_class_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_class_test, 10)\n",
    "\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23f45e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습셋 이미지 수:60000 개\n",
      "테스트셋 이미지 수:10000 개\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t3\t18\t18\t18\t126\t136\t175\t26\t166\t255\t247\t127\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t30\t36\t94\t154\t170\t253\t253\t253\t253\t253\t225\t172\t253\t242\t195\t64\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t49\t238\t253\t253\t253\t253\t253\t253\t253\t253\t251\t93\t82\t82\t56\t39\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t18\t219\t253\t253\t253\t253\t253\t198\t182\t247\t241\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t80\t156\t107\t253\t253\t205\t11\t0\t43\t154\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t14\t1\t154\t253\t90\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t139\t253\t190\t2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t11\t190\t253\t70\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t35\t241\t225\t160\t108\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t81\t240\t253\t253\t119\t25\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t45\t186\t253\t253\t150\t27\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t16\t93\t252\t253\t187\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t249\t253\t249\t64\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t46\t130\t183\t253\t253\t207\t2\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t39\t148\t229\t253\t253\t253\t250\t182\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t24\t114\t221\t253\t253\t253\t253\t201\t78\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t23\t66\t213\t253\t253\t253\t253\t198\t81\t2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t18\t171\t219\t253\t253\t253\t253\t195\t80\t9\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t55\t172\t226\t253\t253\t253\t253\t244\t133\t11\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t136\t253\t253\t253\t212\t135\t132\t16\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "class : 5\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#MNIST 손글씨 인식하기: 데이터 전처리\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import numpy\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "#Seed값 설정\n",
    "seed=0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "#MNIST 데이터 셋 불러오기\n",
    "(X_train, Y_class_train), (X_test, Y_class_test) = mnist.load_data()\n",
    "\n",
    "print('학습셋 이미지 수:%d 개'%(X_train.shape[0]))\n",
    "print('테스트셋 이미지 수:%d 개'%(X_test.shape[0]))\n",
    "\n",
    "#그래프로 확인\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0], cmap='Greys')\n",
    "plt.show()\n",
    "\n",
    "#코드로 확인\n",
    "for x in X_train[0]:\n",
    "    for i in x:\n",
    "        sys.stdout.write('%d\\t' % i)\n",
    "    sys.stdout.write('\\n')\n",
    "\n",
    "#차원변환 과정\n",
    "X_train = X_train.reshape(X_train.shape[0], 784)\n",
    "X_train = X_train.astype('float64')\n",
    "X_train = X_train/255\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 784).astype('float64') / 255\n",
    "\n",
    "    #이어서\n",
    "dataset = df.values\n",
    "X=dataset[:,0:13]\n",
    "Y=dataset[:,13]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X,Y, test_size=0.3, random_state=seed) \n",
    "\n",
    "#클래스 값 확인\n",
    "print('class : %d'%(Y_class_train[0]))\n",
    "\n",
    "#바이너리화 과정\n",
    "Y_train = np_utils.to_categorical(Y_class_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_class_test, 10)\n",
    "\n",
    "print(Y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "974d1561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MNIST는 이미지의 크기가 같아야함 (28x28)\n",
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187677a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#딥러닝 기본 프레임 만들기\n",
    "\n",
    "\"\"\"\n",
    "총 60,000개의 학습셋과 10,000개의 테스트셋을 불러와\n",
    "속성 값을 지닌 X, 클래스 값을 지닌 Y로 구분하는 작업\n",
    "\"\"\"\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 784).astype('float32')/255\n",
    "X_test = X_test.reshape(X_test.shape[0], 784).astype('float32')/255\n",
    "\n",
    "Y_train = np_utils.to_categorical(Y_train,10)\n",
    "Y_test = np_utils.to_categorical(Y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ea78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#딥러닝을 실행하고자 프레임 설정\n",
    "#활성화 함수로 은닉층에서는 relu를, 출력층에서는 softmax를 사용함\n",
    "\n",
    "model = Sequential()\n",
    "#28*28\n",
    "model.add(Dense(512, input=784, activation='relu'))\n",
    "#0-9까지의 클래스\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b1dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#딥러닝 실행환경을 위해 오차 함수로 categorical_crossentropy, \n",
    "#최적화 함수로 adam을 사용함\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece78126",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "모델의 실행에 앞서 모델의 성과를 저장하고 \n",
    "모델의 최적화 단계에서 학습을 자동 중단하게끔 설정함\n",
    "10회 이상 모델의 성과 향상이 없으면 자동으로 학습을 중단함\n",
    "\"\"\"\n",
    "import os\n",
    "import keras.callbacks import ModelCheckpoint, Earlystopping\n",
    "\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEK_DIR)\n",
    "    \n",
    "modelpath='./model/{epoch:02d}-{val_loss: 4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d99ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "샘플 200개를 모두 30번 실행하게끔 설정함\n",
    "테스트셋으로 최종 모델의 성과를 측정하여 그 값을 출력함\n",
    "\"\"\"\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30,\n",
    "                   batch_size = 200, verbose=0, callbacks=[early_stopping_callback, checkpointer])\n",
    "\n",
    "print('\\n Test Accuracy: %.4f'%(model.evaluate(X_test,Y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bae57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습셋의 오차는 1에서 학습셋의 정확도를 뺀 값임\n",
    "\"\"\"\n",
    "좀 더 세밀한 변화를 볼 수 있게 학습셋의 오차와 테스트셋의 오차를 \n",
    "그래프 하나로 나타냄\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "#학습셋의 오차\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "#그래프로 표현\n",
    "x_len = numpy.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label='Testset_loss')\n",
    "plt.plot(x_len, y_vloss, marker='.', c='blue', label='Trainset_loss')\n",
    "\n",
    "#그래프에 그리드를 주고 레이블 표시\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d8dfddf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\engine\\training.py:788 train_step\n        loss = self.compiled_loss(\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\engine\\compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\losses.py:1665 categorical_crossentropy\n        return backend.categorical_crossentropy(\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\backend.py:4839 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (200, 10, 10, 10) and (200, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22052/4149761081.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m#모델의 실행\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30,\n\u001b[0m\u001b[0;32m     48\u001b[0m                    batch_size = 200, verbose=0, callbacks=[early_stopping_callback, checkpointer])\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 759\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    760\u001b[0m             *args, **kwds))\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\engine\\training.py:788 train_step\n        loss = self.compiled_loss(\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\engine\\compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\losses.py:1665 categorical_crossentropy\n        return backend.categorical_crossentropy(\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\keras\\backend.py:4839 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\admin\\Anaconda3\\envs\\SSAC\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (200, 10, 10, 10) and (200, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "#MNIST 손글씨 인식하기: 기본 프레임\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy \n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "#Seed값 설정\n",
    "seed=0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "#MNIST 데이터 셋 불러오기\n",
    "(X_train, Y_class_train), (X_test, Y_class_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 784).astype('float32')/255\n",
    "X_test = X_test.reshape(X_test.shape[0], 784).astype('float32')/255\n",
    "\n",
    "Y_train = np_utils.to_categorical(Y_train,10)\n",
    "Y_test = np_utils.to_categorical(Y_test, 10)\n",
    "\n",
    "#모델 프레임 설정\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=784, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#모델 실행 환경 설정\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#모델 최적화 설정\n",
    "\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEK_DIR)\n",
    "    \n",
    "modelpath='./model/{epoch:02d}-{val_loss: 4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "#모델의 실행\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30,\n",
    "                   batch_size = 200, verbose=0, callbacks=[early_stopping_callback, checkpointer])\n",
    "\n",
    "#테스트 정확도 출력\n",
    "print('\\n Test Accuracy: %.4f'%(model.evaluate(X_test,Y_test)[1]))\n",
    "\n",
    "#테스트셋의 오차\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "#학습셋의 오차\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "#그래프로 표현\n",
    "x_len = numpy.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label='Testset_loss')\n",
    "plt.plot(x_len, y_vloss, marker='.', c='blue', label='Trainset_loss')\n",
    "\n",
    "#그래프에 그리드를 주고 레이블 표시\n",
    "plt.legend(loc='upper right')\n",
    "#plt.axis([0,20,0,0.35])\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41f9f4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14746, saving model to ./model\\01-0.1475.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14746 to 0.10213, saving model to ./model\\02-0.1021.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.10213 to 0.08911, saving model to ./model\\03-0.0891.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08911 to 0.07862, saving model to ./model\\04-0.0786.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.07862 to 0.07386, saving model to ./model\\05-0.0739.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.07386 to 0.06701, saving model to ./model\\06-0.0670.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.06701 to 0.06458, saving model to ./model\\07-0.0646.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.06458 to 0.06275, saving model to ./model\\08-0.0627.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06275\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06275\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.06275\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.06275\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.06275 to 0.05881, saving model to ./model\\13-0.0588.hdf5\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.05881\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.05881\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.05881\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.05881\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.05881\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.05881\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.05881\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.05881\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.05881\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.05881\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0675 - accuracy: 0.9831\n",
      "\n",
      " Test Accuracy: 0.9831\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import os\n",
    "import tensorflow as tf\n",
    "  \n",
    "# seed 값 설정\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "  \n",
    "# MNIST 데이터 불러오기\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    " \n",
    "X_train = X_train.reshape(X_train.shape[0], 784).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 784).astype('float32') / 255\n",
    " \n",
    "Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_test, 10)\n",
    "  \n",
    "# 모델 프레임 설정\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=784, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "  \n",
    "# 모델 실행 환경 설정\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  \n",
    "# 모델 최적화 설정\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "  \n",
    "# 모델의 실행\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30, batch_size=200, verbose=0, callbacks=[early_stopping_callback,checkpointer])\n",
    "  \n",
    "# 테스트 정확도 출력\n",
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))\n",
    "  \n",
    "# 테스트셋의 오차\n",
    "y_vloss = history.history['val_loss']\n",
    "  \n",
    "# 학습셋의 오차\n",
    "y_loss = history.history['loss']\n",
    "  \n",
    "# 그래프로 표현\n",
    "x_len = numpy.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "  \n",
    "# 그래프에 그리드를 주고 레이블을 표시\n",
    "plt.legend(loc='upper right')\n",
    "# plt.axis([0, 20, 0, 0.35])\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb8bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#딥러닝의 활용\n",
    "\"\"\"\n",
    "앞서 한 것들은 하나의 은닉층을 둔 아주 단순한 모델로\n",
    "딥러닝 알고리즘은 프로젝트에 맞춰서 어떤 옵션을 더하고 \n",
    "어떤 층을 추가하느냐에 따라 성능이 좋아질 수 있음\n",
    "\n",
    "컨볼루션 신경망 : 입력된 이미지에서 다시 한번 특징을 추출하기 위해\n",
    "마스크(필터, 윈도 또는 커널이라고도 함)를 도입하는 기법\n",
    "\n",
    "새롭게 만들어진 층을 컨볼루션(합성곱)이라고 부름\n",
    "컨볼루션을 만들면 입력 데이터로부터 더욱 정교한 특징을 추출할 수 있음\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#케라스에서 컨볼루션 층을 추가하는 함수는 Conv2D( )임\n",
    "model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n",
    "\n",
    "#인자\n",
    "\"\"\"\n",
    "1 | 첫 번째 인자: 마스크를 몇 개 적용할지 정함\n",
    "    여러개의 마스크를 적용하면 서로 다른 컨볼루션이 여러개 나옴\n",
    "    여기서는 32개의 마스크를 적용함\n",
    "2 | kernel_size: 마스크(커널)의 크기를 정함 kernel_size=(행, 열) 형식으로 정하며, 여기서는 3×3 크기의 마스크를 사용하게끔 정함\n",
    "3 | input_shape: Dense 층과 마찬가지로 맨 처음 층에는 입력되는 값을 알려주어야함\n",
    "    input_shape=(행, 열, 색상 또는 흑백) 형식으로 정함\n",
    "    만약 입력 이미지가 색상이면 3, 흑백이면 1을 지정함\n",
    "4 | activation: 활성화 함수를 정의함\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f730114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#컨볼루션 층을 하나 더 추가함\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab743432",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "풀링(pooling) 또는 서브 샘플링(sub sampling) :\n",
    "     앞서 구현한 컨볼루션 층을 통해 이미지 특징을 도출함\n",
    "     그 결과가 여전히 크고 복잡하면 이를 다시 한번 축소해야 함\n",
    "\n",
    "맥스 풀링(max pooling) :\n",
    "     풀링 기법에는 정해진 구역 안에서 최댓값을 뽑아내는 것\n",
    "\n",
    "평균 풀링(average pooling) :\n",
    "     평균값을 뽑아내는 것\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584d9107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#여기서 pool_size는 풀링 창의 크기를 정하는 것\n",
    "#2로 정하면 전체 크기가 절반으로 줄어듦\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ba8cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#드롭아웃, 플래튼\n",
    "\"\"\"\n",
    "드롭아웃은 은닉층에 배치된 노드 중 일부를 임의로 꺼주는 것\n",
    "랜덤하게 노드를 끔으로써 학습 데이터에 지나치게 치우쳐서 \n",
    "학습되는 과적합을 방지할 수 있음\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03e4222",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea3edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dense( ) 함수를 이용해 만들었던 기본 층에 연결\n",
    "\"\"\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "컨볼루션 층이나 맥스 풀링은 주어진 이미지를 2차원 배열인 채로 다루기 때문에\n",
    "이를 1차원 배열로 바꿔주어야 활성화 함수가 있는 층에서 사용할 수 있음\n",
    "Flatten( ) 함수를 사용해 2차원 배열을 1차원으로 바꿔줌\n",
    "\"\"\"\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b29dfe89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05379, saving model to ./model\\01-0.0538.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05379 to 0.03983, saving model to ./model\\02-0.0398.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03983 to 0.03709, saving model to ./model\\03-0.0371.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03709 to 0.03111, saving model to ./model\\04-0.0311.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.03111 to 0.03091, saving model to ./model\\05-0.0309.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.03091 to 0.03050, saving model to ./model\\06-0.0305.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.03050 to 0.02943, saving model to ./model\\07-0.0294.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02943\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02943\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02943\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.02943\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.02943\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.02943 to 0.02702, saving model to ./model\\13-0.0270.hdf5\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.02702\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.02702\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.02702 to 0.02635, saving model to ./model\\16-0.0264.hdf5\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.02635\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.02635\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.02635\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.02635\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.02635\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.02635\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.02635\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.02635\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.02635\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.02635\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0296 - accuracy: 0.9930\n",
      "\n",
      " Test Accuracy: 0.9930\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAw70lEQVR4nO3de3xUxf3/8dcnmxuCQAQSEVCwxQsIolAxRSV4AVFbL63SFqlKLbVfraJfqqg/xar1Xr9WqyIq9Yb3FuWhVFBLRCVWwIKIgCCiRJSbEAhCrvP7YzZkEzbJbshhQ/b9fDzOY2/n7JnZs3s+OzNnZsw5h4iISG0piU6AiIg0TwoQIiISlQKEiIhEpQAhIiJRKUCIiEhUqYlOQFPq2LGj6969e6O23bZtG61bt27aBDVzynPLl2z5BeU5XvPnz9/gnOsU7bUWFSC6d+/OvHnzGrVtfn4+eXl5TZugZk55bvmSLb+gPMfLzL6s6zVVMYmISFQKECIiEpUChIiIRNWi2iBEpPkpKyujsLCQHTt27JH9tWvXjiVLluyRfTUXseQ5MzOTrl27kpaWFvP7KkCISKAKCwvZd9996d69O2YW+P62bt3KvvvuG/h+mpOG8uycY+PGjRQWFtKjR4+Y31dVTCISqB07dtChQ4c9EhwkOjOjQ4cOcZfiFCCAggKYMuVACgoSnRKRlknBIfEacwySvoppzhwYPBgqKnowZQq8/Tbk5iY6VSIiiZf0JYh33oHycnDOKC2F/PxEp0hEpHlI+gCRlwe+5OVIT/ePRaTl2LhxI/369aNfv37sv//+dOnSZefj0tLSBrfPz89nzpw5jdr3qlWrePbZZxt8/zPOOKNR7x+0pA8QublwxBHQufMOVS+JNBcFBXD77TRFw2CHDh1YsGABCxYs4JJLLuHKK6/c+Tg9Pb3B7YMOEM1Z0rdBAPTsCVu2VCo4iARt7FhYsKD+dYqK4OOPobISUlKgb19o167u9fv1g/vuiysZ8+fP56qrrqK4uJiOHTvyxBNP0LlzZ+6//34mTpxIamoqvXr14o477mDixImEQiGeeeYZHnjgAb799lv+9Kc/EQqFaNeuHbNnz6aiooLx48eTn59PSUkJl156Kb/73e8YP348S5YsoV+/flxwwQVceeWV9abru+++Y/To0axcuZJ99tmHSZMm0bdvX9555x2uuOIKwDc2z549m+LiYkaMGMGWLVsoLS3lkUce4fjjj4/rc2iIAgSQnQ2bNjX8T0JE9oCiIh8cwN8WFdUfIOLknOMPf/gDr776Kp06deKFF17g+uuvZ/Lkydxxxx188cUXZGRksHnzZtq3b88ll1xCmzZtGDduHAB9+vRhxowZdOnShc2bNwPw+OOP065dO+bOnUtJSQmDBg1i6NCh3HHHHdxzzz289tprMaVtwoQJHHXUUbzyyiv8+9//5te//jULFizgnnvu4cEHH2TQoEEUFxeTmZnJpEmTGDZsGNdffz2bN28mFAo12WdURQECyMmBLVvSKC+HVH0iIsGJ5Z9+QQGcdBKUlkJ6OkyZ0qR1vyUlJXzyySeccsopAFRUVNC5c2cA+vbty8iRIznrrLM466yzom4/aNAgLrzwQs477zzOOeccAGbOnMnHH3/Myy+/DEBRURHLly+PqQor0nvvvcc//vEPAE488UQ2btxIUVERgwYN4qqrrmLkyJGcc845dO3alR/96EeMHj2asrIyTjnlFAYNGtSYj6NeSd8GAb4EAbB+fWLTISL4YPD223DLLYFcd+6co3fv3jvbIRYtWsTMmTMBeP3117n00kuZP38+/fv3p7y8fJftJ06cyK233srq1avp168fGzduxDnHAw88sPM9v/jiC4YOHdqotNVmZowfP57HHnuM7du3c+yxx7J06VJOOOEEZs+eTZcuXRgzZgxPPfVU/B9GAxQg8CUIgHXrEpsOEQnLzYVrrw3kqpGMjAzWr19PQbgBvKysjMWLF1NZWcnq1asZMmQId911F5s3b6a4uJh9992XrVu37tz+888/Z+DAgdx888107NiR1atXM2zYMB5++GHKysoA+Oyzz9i2bdsu2zbkhBNOYMqUKYBvHO/YsSNt27bl888/p0+fPlxzzTUMGDCApUuX8uWXX5Kdnc1vf/tbRo0axUcffdSEn5KnChWqSxBr1yY2HSISvJSUFF5++WUuv/xyioqKKC8vZ+zYsRxyyCGcf/75FBUV4ZzjyiuvpH379vzkJz/h5z//Oa+++ioPPPAA//d//8fy5ctxznHSSSdx5JFH0rdvX1atWsXRRx+Nc45OnTrxyiuv0LdvX1JTUznyyCO58MILG2ykvummm7jooovo27cv++yzD08++SQA9913H7NmzSIUCtGrVy+GDx/O888/z913301aWhqtWrXaGViakkUr0uytBgwY4Bozo9xnn8Ghh8LTT8P55weQsGZKM2+1fM0hv0uWLOHwww/fY/vTYH11i3YszGy+c25AtPVVxYRKECIi0aiKCX8FXVpaJevWKV6KSDBmzJjBNddcU+O5Hj16MHXq1ASlqGEKEPihNtq3L2Xt2sxEJ0VEWqhhw4YxbNiwRCcjLvrLHJaVVaarmEREIgQaIMzsVDNbZmYrzGx8lNdHmtnH4WWOmR0Z8doqM1tkZgvMLP6W5zhlZZWqDUJEJEJgVUxmFgIeBE4BCoG5ZjbNOfdpxGpfAIOdc5vMbDgwCRgY8foQ59yGoNIYKSurlE8+2RN7EhHZOwRZgjgGWOGcW+mcKwWeB86MXME5N8c5tyn88AOga4DpqVf79r6KqQVd9SsisluCbKTuAqyOeFxIzdJBbb8B/hXx2AEzzcwBjzjnJkXbyMzGAGMAcnJyyG/kjD+tW3eitBRef/092rTZtXt9S1RcXNzoz2tvlWx5bg75bdeuXVy9iXdXRUVFjf1t3LiRn/70pwCsXbuWUChEx44dAZg1a1a94yV99NFHPPfcc9x9991Nlr4pU6Zw4okn7hz/KZrTTjuNW2+9laOPPjqm96yd57rs2LEjvu+Dcy6QBTgXeCzi8SjggTrWHQIsATpEPHdA+DYbWAic0NA++/fv7xrruus+deDc0qWNfou9zqxZsxKdhD0u2fLcHPL76aefxr3NnDnO3Xabv43Xli1b6nxtwoQJ7u67767xXFlZWfw72Q2DBw92c+fO3e11ItWX50jRjgUwz9VxTg2yBFEIdIt43BVYU3slM+sLPAYMd85trHreObcmfLvOzKbiq6xmB5XYrCw/s9S6db5XtYg0vWYyHQQXXngh++23H//97385+uijGTFiBGPHjmX79u20atWKv//97xx66KHk5+fvHK77pptu4quvvmLlypV89dVXjB07lssvv5xt27Zx3nnnUVhYSEVFBTfccAMjRoyIOufE+++/z7x58xg5ciStWrWioKCAVq1a1ZvW5557jttuuw3nHKeffjp33nknFRUV/OY3v2HevHmYGb/61a+49tprd5nP4vnnn4/vg6klyAAxF+hpZj2Ar4FfAL+KXMHMDgT+CYxyzn0W8XxrIMU5tzV8fyhwc4BppX17HyB0JZNIYgU8HcROn332GW+99RahUIgtW7Ywe/ZsUlNTeeutt7juuut2DrsdaenSpcyaNYutW7dy6KGH8vvf/5433niDAw44gNdffz2c/iLKysrqnHPib3/7G/fccw8DBkQd3aKGNWvWcM011zB//nyysrIYOnQor7zyCt26dePrr7/mk/CVNatX+9r82vNZ7K7AAoRzrtzMLgNmACFgsnNusZldEn59InAj0AF4yPzE0OXOjwmSA0wNP5cKPOuceyOotALst58fhVF9IUSC0wymg9jp3HPP3TnJTlFRERdccAHLly/HzHaOylrb6aefTkZGBhkZGWRnZ7N27Vr69OnDuHHjuOaaazjjjDM4/vjj+eSTT+qccyIec+fOJS8vj06dOgEwcuRIZs+ezQ033MDKlSv5wx/+wOmnn05u+AOKZT6LeATak9o5Nx2YXuu5iRH3LwYujrLdSuDI2s8HqV27MsxUghBJtKrpIPLzIS8vuHniW7duvfP+DTfcwJAhQ5g6dSqrVq2qc4DDjIyMnfdDoRDl5eUccsghzJ8/n+nTp3PttdcydOhQzj77bHr37r1zSPHGcnVcVpmVlcXChQuZMWMGDz74IFOmTOHpp5/m9ddfZ/bs2UybNo1bbrmFxYsXk7obs6CpJ3VYKOTo0EElCJHmIMDpIKIqKiqiS5cuADzxxBNxbbtmzRr22Wcfzj//fMaNG8dHH33EoYceGnXOCSCuOSIGDhzIO++8w4YNG6ioqOC5555j8ODBbNiwgcrKSn72s59xyy23sHDhwjrns9gdGospQna2ShAiyejqq6/mggsu4N577+XEE0+Ma9tFixbxxz/+kZSUFNLS0nj44YdJT0+POudE7969ufDCC7nkkktiaqTu3Lkzt99+O0OGDME5x2mnncaZZ57JwoULueiii6gMN9ZMmDCBioqKqPNZ7A7NBxGWn5/PzTfnUVoK773XxAlrpprDXAF7WrLluTnkV/NBBE/zQewBKkGIiFRTFVOEnBy1QYjInnP22WfzxRdf1HjuzjvvbDbDgitARMjOhi1bYMcOyNTUECJNxjlH+LJ1ibAnJwtqTHOCqpgi5OT4W5UiRJpOZmYmGzdubNQJSpqGc46NGzeSGec/X5UgIkTOTX3ggYlNi0hL0bVrVwoLC1m/fv0e2d+OHTviPhHu7WLJc2ZmJl27xjdgtgJEBJUgRJpeWloaPXr02GP7y8/P56ijjtpj+2sOgsqzqpgiRJYgRESSnQJEhKoAoRKEiIgCRA2tW/tFJQgREQWIXagvhIiIpwBRi3pTi4h4ChC1qAQhIuIpQNSiEoSIiKcAUUtODmzYABUViU6JiEhiKUDUkp3t58HduDHRKRERSSwFiFrUm1pExFOAqEW9qUVEPAWIWqpKEAoQIpLsFCBq0XAbIiKeAkQtWVmQmqoShIiIAkQtKSnQqZNKECIiChBR5OSoBCEiogARRXa2ShAiIgoQUagEISKiABFVVQlCc6yLSDJTgIgiJwd27ICtWxOdEhGRxAk0QJjZqWa2zMxWmNn4KK+PNLOPw8scMzsy1m2DpL4QIiIBBggzCwEPAsOBXsAvzaxXrdW+AAY75/oCtwCT4tg2MOpNLSISbAniGGCFc26lc64UeB44M3IF59wc59ym8MMPgK6xbhsklSBERCA1wPfuAqyOeFwIDKxn/d8A/4p3WzMbA4wByMnJIT8/v1GJLS4u3rnt+vXpwI95993PyMpa06j32xtE5jlZJFueky2/oDw3pSADhEV5Lup1QWY2BB8gjot3W+fcJMJVUwMGDHB5eXlxJxQgPz+fqm1LS/1z7dsfQl7eIY16v71BZJ6TRbLlOdnyC8pzUwoyQBQC3SIedwV2+TtuZn2Bx4DhzrmN8WwblPR0PyaT2iBEJJkF2QYxF+hpZj3MLB34BTAtcgUzOxD4JzDKOfdZPNsGTb2pRSTZBVaCcM6Vm9llwAwgBEx2zi02s0vCr08EbgQ6AA+ZGUC5c25AXdsGldZo1JtaRJJdkFVMOOemA9NrPTcx4v7FwMWxbrsnZWfDokWJ2ruISOKpJ3UdVIIQkWSnAFGH7GzYvLn6iiYRkWSjAFGHqt7UaqgWkWSlAFEH9aYWkWSnAFEHjcckIslOAaIOKkGISLJTgKiDShAikuwUIOrQpg1kZqoEISLJSwGiDmbqCyEiyU0Boh4aj0lEkpkCRD1UghCRZKYAUQ+VIEQkmSlA1CMnxweIyspEp0REZM9TgKhHdjZUVMCmTQ2vKyLS0ihA1EN9IUQkmSlA1EO9qUUkmSlA1EMlCBFJZgoQ9VAJQkSSmQJEPTp0gJQUlSBEJDkpQNQjFIKOHVWCEJHkpADRAPWmFpFkpQDRAPWmFpFkpQDRAJUgRCRZKUA0QCUIEUlWChANyMmBbdv8IiKSTBQgGqC+ECKSrBQgGqDe1CKSrBQgGqAShIgkq0ADhJmdambLzGyFmY2P8vphZlZgZiVmNq7Wa6vMbJGZLTCzeUGmsz4qQYhIskoN6o3NLAQ8CJwCFAJzzWyac+7TiNW+Ay4HzqrjbYY45zYElcZYqAQhIskqyBLEMcAK59xK51wp8DxwZuQKzrl1zrm5QFmA6dgtmZnQtq1KECKSfIIMEF2A1RGPC8PPxcoBM81svpmNadKUxUl9IUQkGcVUxWRmVwB/B7YCjwFHAeOdczPr2yzKcy6OtA1yzq0xs2zgTTNb6pybHSVtY4AxADk5OeTn58exi2rFxcV1bpuZeRTLllWSn7+wUe/dXNWX55Yq2fKcbPkF5bkpxdoGMdo591czGwZ0Ai7CB4z6AkQh0C3icVdgTawJc86tCd+uM7Op+CqrXQKEc24SMAlgwIABLi8vL9Zd1JCfn09d2/bsCcuWUefre6v68txSJVueky2/oDw3pVirmKpKA6cBf3fOLSR6CSHSXKCnmfUws3TgF8C0mHZm1trM9q26DwwFPokxrU1O4zGJSDKKtQQx38xmAj2Aa8Mn78r6NnDOlZvZZcAMIARMds4tNrNLwq9PNLP9gXlAW6DSzMYCvYCOwFQzq0rjs865N+LOXRPJzoaNG6G8HFIDu+5LRKR5ifV09xugH7DSOfe9me2Hr2aql3NuOjC91nMTI+5/i696qm0LcGSMaQtcVV+I9euhc+fEpkVEZE+JtYopF1jmnNtsZucD/w8oCi5ZzYv6QohIMoo1QDwMfG9mRwJXA18CTwWWqmZGvalFJBnFGiDKnXMO39Htr865vwL7Bpes5kUlCBFJRrG2QWw1s2uBUcDx4WE00oJLVvOiEoSIJKNYSxAjgBJ8f4hv8T2i7w4sVc1Mu3aQnq4ShIgkl5gCRDgoTAHamdkZwA7nXNK0QZj5aiaVIEQkmcQUIMzsPOBD4FzgPOA/ZvbzIBPW3Gg8JhFJNrG2QVwP/Mg5tw7AzDoBbwEvB5Ww5ka9qUUk2cTaBpFSFRzCNsaxbYugEoSIJJtYSxBvmNkM4Lnw4xHU6iHd0uXk+ADhnG+TEBFp6WIKEM65P5rZz4BB+EH6JjnnpgaasmYmOxtKS6GoCNq3T3RqRESCF/PQc865fwD/CDAtzVpkXwgFCBFJBvUGCDPbSvRJfgxwzrm2gaSqGYrsTX3ooYlNi4jInlBvgHDOJc1wGg1Rb2oRSTZJdSXS7tB4TCKSbBQgYtSpk79VCUJEkoUCRIxSU6FDB5UgRCR5KEDEQb2pRSSZKEDEQb2pRSSZKEDEQSUIEUkmChBxUAlCRJKJAkQccnJgyxbYsSPRKRERCZ4CRBzUF0JEkokCRBzUm1pEkokCRBxUghCRZKIAEQeVIEQkmShAxEElCBFJJgoQcWjd2i8qQYhIMlCAiJP6QohIsgg0QJjZqWa2zMxWmNn4KK8fZmYFZlZiZuPi2TZR1JtaRJJFYAHCzELAg8BwoBfwSzPrVWu174DLgXsasW1CqAQhIskiyBLEMcAK59xK51wp8DxwZuQKzrl1zrm5QFm82yaKShAikiyCDBBdgNURjwvDzwW9baCys2HDBqioSHRKRESCVe+c1LvJojznmnpbMxsDjAHIyckhPz8/xl3UVFxcHNO2W7Z0obKyJ9OmvU9WVu2Cz94l1jy3JMmW52TLLyjPTSnIAFEIdIt43BVY09TbOucmAZMABgwY4PLy8uJOKEB+fj6xbLt2LTzwAPTsOYgjjmjUrpqNWPPckiRbnpMtv6A8N6Ugq5jmAj3NrIeZpQO/AKbtgW0Dpd7UIpIsAitBOOfKzewyYAYQAiY75xab2SXh1yea2f7APKAtUGlmY4Fezrkt0bYNKq3xUG9qEUkWQVYx4ZybDkyv9dzEiPvf4quPYtq2OVAJQkSShXpSxykrC0IhlSBEpOVTgIhTSgq0bw8zZ0JBQaJTIyISHAWIOBUUwHffwfz5cNJJChIi0nIpQMQp8lLjkpKaj0VEWhIFiDjl5UFmpr9fWQkHH5zQ5IiIBEYBIk65ufD22zB+POy7L9x7L5SXJzpVIiJNTwGiEXJz4fbb4dFH4cMP/X0RkZZGAWI3jBgBv/oV/OlPMG9eolMjItK0FCB209/+BvvvD6NGwfbtiU6NiEjTUYDYTVlZ8MQTsHSpb5cQEWkpFCCawMknw+WXw/33w5tvJjo1IiJNQwGiidxxBxx2GFx0EWzalOjUiIjsPgWIJtKqFTzzjB/E77LLEp0aEZHdpwDRhPr3hwkT4Nln4YUXEp0aEZHdowDRxMaPh2OPhd//Hr7+OtGpERFpPAWIJpaaCk895cdpGj0aXKyzcIuINDMKEAHo2RP+8hc/JPhDDyU6NSIijaMAEZDf/Q6GD4c//hGWLUt0akRE4qcAERAzePxx2GcfOPtsuPVWzR0hInsXBYgAde4MV10FS5bAjTdqgiER2bsoQATMzC/O+bGaXnop0SkSEYmNAkTAqiYYSgl/0g884PtK7NiR0GSJiDRIASJgVRMM3XorvPaaHyL85puhTx+N2yQizZsCxB6QmwvXXgunn+6H43jrLV/tNHSon0/i228TnUIRkV0pQCTASSfBxx/DTTfBP/7hB/l76CGoqEh0ykREqilAJEhmpm+LWLQIBgyASy+FH/8Y/vvfRKdMRMRTgEiwQw7xbRFTpsCqVT5YjBjhSxe6JFZEEkkBohkw820RS5fCT38KL77o57nOy1OQEJHEUYAAePxxDnryyYSfjbOy4Jhjqi+JLS2F3/wGVq9OaLJEJEkFGiDM7FQzW2ZmK8xslxmbzbs//PrHZnZ0xGurzGyRmS0ws3mBJfKNN+Dii+n+xBNw4okJDxJ5eZCRAaEQpKXB55/D4YfDffdBeXlCkyYiSSawAGFmIeBBYDjQC/ilmfWqtdpwoGd4GQM8XOv1Ic65fs65AUGlk//+F1JSMPC9115+ObBdxaKq38Qtt8A77/iB/gYPhiuvhIEDYf78hCZPRJJIkCWIY4AVzrmVzrlS4HngzFrrnAk85bwPgPZm1jnANO0q/JfdVdXrPPYYvP/+Hk1CbVX9JnJzoXt338HuxRdhzRpfBTV2LGzdmtAkikgSMBfQjDZm9nPgVOfcxeHHo4CBzrnLItZ5DbjDOfde+PHbwDXOuXlm9gWwCXDAI865SXXsZwy+9EFOTk7/559/Pu60tl28mFYffkhFjx4c/PjjZK5dy5Jrr2X9kCFxv1eQiotDPPbYwUybdgAdO5Zw+eUrOO64DbvxfsW0adOmCVPY/CVbnpMtv6A8x2vIkCHz66ylcc4FsgDnAo9FPB4FPFBrndeB4yIevw30D98/IHybDSwETmhon/3793eNNWvWLH9nwwbnjjvOOXDuzjudq6xs9HsGpaDAuT59fBLPPNO5qVOdu+025+bMie99duY5iSRbnpMtv84pz/EC5rk6zqlBVjEVAt0iHncF1sS6jnOu6nYdMBVfZRW8Dh18x4QRI+Caa+B//qfZtQ4fe6xvi7jzTvjXv/x8E9dfr+HERaRpBRkg5gI9zayHmaUDvwCm1VpnGvDr8NVMxwJFzrlvzKy1me0LYGatgaHAJwGmtabMTHj2WR8gJk6EM8+E4uI9tvtYpKXB1VfD5Zf7x1XDiV90kZ+oaP36xKZPRPZ+gQUI51w5cBkwA1gCvOicW2xml5jZJeHVpgMrgRXAo8D/hJ/PAd4zs4XAh8Drzrk3gkprVCkpcMcdPkDMmAEnnOBbiZuZc86BVq18clNToagILr4Y9t/ft7/ffz989VWiUykie6PUIN/cOTcdHwQin5sYcd8Bl0bZbiVwZJBpi9nvfgcHHgjnnuvrdqZPhyOOSHSqdqq6LDY/3weEY4+FhQvhn/+EqVPhiiv8MmCAr4o65xw/OGBBAUyZciAZGf49RERqU0/qWAwfDu++69siBg3ys/7cfnuzqfCPvCzWDPr183NOLFrk+1HccYfveHf99b7TXffuvkD0+OM91G4hInVSgIjVUUfBf/4DHTv6iv/rr/d/2Z95xo+J0UwdcohvSvngAygshL/9zQeL8nJwzti+HX7/e9/ksnFjolMrIs2JAkQ8unWD88/3953zgWHUKGjd2lc7/eIXvgv01KmwfHn1BA8FBc2ixNGlix9W/JlnfLuFmSMUgi+/hJEjoVMnXwq55RZ/lVRlZUKTKyIJFmgbRIt06qlw990+OKSm+rqdkhJYvBjmzoUXXqheNzPTt198/rk/22ZkwL//nfBK/6p2i8mTv2D06IN3DuExfbpfJkyAG2+EnBxfu3baadCunV8nLy/hyReRPUQBIl61W4Vrny23bYMlS+CTT/wybVp1SWLHDj886223+bNuevqeTv1OublQUvIVubkHA/CjH/llwgRYt85fuDV9Orz6KjzxRPV2oZBvtz/jDD+vdpcuvt1DRFoeBYjGyM2t+29069b+kqEB4Z7rP/uZ78FWWurPpN9+6y8n6tjRTwJxwQW+faMZnWWzs33N2ahRvq3isstg0iRfq1ZR4adHfeghv25Wlq9d69OnejniCPj007pjqIjsHRQggla7xPGjH8HMmf5v+cSJvqNCnz4+UIwc6TswNCOpqT5pTz3lY1x6um9iadXKXyVVtTz9dM0BBM18QElP96WRvLwGdlRQEHxEKSjgwClT0LW9LZiOcZNSgNgTapc4TjvNL99959ssnnwSxo3zlxsNH+47M1RWwsknx/Ylb8zJNY4fUl21aiecUL2Oc75D3qJF8MBfK5n5lgFGaSkMG1rBiBPWMmJQIaccXkh65Q4fbUpK/O2yZb6IUl7uu4g/8ogvZbVrF1te6lNa6mdcmj4dxo2jR1mZj2aTJ/vPd7/9fBSs4zNqVsWg5pae5qagAE48kR4lJf4Yv/SSbzNMS2v6/cRzHPbi4xbYaK6JMGDAADdvXuPmFsrPzyevwb+5AVq61AeKxx6DDREjtLZq5f+Gh0L+RBYK1VxKS+Hrr/0Z2gx69fLVV+np/uSfkVF9v+p2wwZ46SVcRQWWmuobHo491tcXVS1t21ZPbQc1v+T9+vlLn+pYClZ35STeopQ0UqngZN7kfY5jM1lk8R3n8E9G8AJDmEUqFXV/Jh06wMEH++UHP6i+f/DB/qT/7ru+X0qXLn5C72hL1WdTn/bt/b46dqy+LSnxvQ0rKvznlqiLC7Zu9ZdXv/CCD2qVlf57cN99MGZMgye/uL7Xzvni4dy5MGxYDMU+En+y/P57mD3bl8qnTPENaLV16ODrTaMtmzfDypX+O33YYf5PSkWFX6LdX7YM7rqr+s/M1Vf7a8lTUvzvLyWlejHzVzNOmODXz8jw/7Sa+ntUUMDKyZM5ePToRr23mdU5mqsCRFjCA0SVP//ZX0JUWem/YD/+MfTvX/1Frf2FXbQIPv64evsf/tCfMKv+nUe7LS6GsrL605GS4v/BZ2X5E+Rnn9V93WsoBF27wkEH+aWwkIJZO8hnMHk2m9zRh1N6/mhm/rcTL7zdkVfz27J1W4hOHSr42U/KGHHEYlKv+yPvluWSl/oeuX861Z8EV670y+ef++ATMWhiAceSTx555JPLBzXT3a2b7w0YuXz/Pfzv/+JKS7G0NN+PZb/9fLDcuHHX2zVran5G7dr5Escxx/iZm/r3h6YeUto5n885c/ycJHPm+GNb1+e+775wyim+NHrqqf6411Lv93r7dh8Mqvb1zjs16wnT0vzJNfKPQ9XSvr0f12XiRP85pab6CzA6dPAXakRb1q3zx9M5/50ZPdoHosMO89/bjIyGP6PKSv+ZzJzpl3ff9d/rjAxfVbtwIa683B/jyy/3x2jduprL2rWwaVPD+wpCp04wZAj07euXPn38bybWNsjvvoMVK/yyfLkPuG++iausxFq1alQAUoCIQbMJEAUF1Y3a6ekNH/B414/YprKkhJT0dHj0UX857qZN1ct331XfnzfPBwjwX+STT4Zf/7o6IBxwQM1qmgbStH27H4X2hRf8ZEjffw9+2g8IpcBJJxsdO/rzSGWlv3WVlbht23HF29iwZC3vbTicClJIo5y7+j7DqJsPocORXf1Jsq5/1fH806rKQ0mJP5kNHlwdsMAHot69qwPGMcfAli3w3nt1/zuuqPAn0/JyfztnDrz+uk/vmjX+cdV4X23a+FLdj3/sS0lmftDIqs/0xht9Wv71L98DEuDII32wGD7c73/u3Jr5/eab6uDz/vvw0UfVQfeww/w+58+vLo0edxwceqj/DmzeXPP7UVQUvWSWkuIv1Ki9tGnjS3Offhr98w6FfMnwsMP8cvjh/nbLFh+4qv4wvPlmdSnhiCNg6FC/HH887LNP7Me4tNT/s7/rLv8lS0nxAe6CC3YtrUfeX7jQ94UqK/PH7emn/UUmlZXVS9UXt7ISFizwJb2yMr+P3Fx/vL74ojotbdtWX+HRt69fb+FCH0zMqoPBihX+d1nFzG9bVFT9Gd5yi7/0Pg4KEDFoNgEC9kyxvTEny3iDUAxp2rbNDy4YOc9TVpb/c28Wfdn4bSnrNqUBNf91HXSQ/2Pfvz8cfbS/7dSpZpImT17J6NEHx/YxRcvD+vX+X/d//gMffuiXyB9tlbZtfWLLyqqDQn2/tf3393OiDxrkg0KfPv4H31B6nPOXU0+f7oPFe+/5QNSmDWzf7v9ZpqT46pRvvvHbZGb6gFYVfHJz/T//eI5zRQW89RacdVb1yfJf//KBtK5/w7Xf/7XXfElk6VK/LFnibz/7LProBO3b+wA4dKgvOR1wQNTdxPxbbsz3umq73f19bt3qj9vHH/ulqiag6mQf6aCDfAmrZ8+atwcf7KdMrvqz18gqrPoCRGATBiViaZIJg5JIXHmeM6dxsxLF+NatWjkXCvnbhnYxZ45zrTLKXcjKXauMcnf//X5up/POc+6HP/QTKVUt3bo5d9ZZzv32t86lpzuXklIZ0z5iVlnp3PLlfudmfqdmzg0c6NwVVzg3bpxz48c7d8MNzt18s/8M777budNPr14/FPLPN4VNm5x76SXn+vev+UH07u3cvfc698EHzpWU1L19vMc5iPXLyvxn+utf1/yM/vznmHbRXL7XcausdO7qq51LSanO8803N7zdnDnu84svbnQeqGfCoISf1JtyUYCIT3PKc1OeZzZtcu7f//bn4V/+0rlDDql5rgTnunTx55/bb3fu1Vf9+ai8fDfSNGeOm5M+2N1m17k56YNjjHJxRMV4hd+/IiUlmPffExr5GTWn73XcEpDn+gKELnOVZqG+vofxrt++vW8HjJxS/K23fO/v0lJHKGQccIAvjT/1VPU6GRm+yv3ww33771NP+Zqh1FR/BXK3br5JYscOf1u17NgBX36Zy2vls6h0kFbpeOjTFEb0qacdu6Ee+bsr/P6rduPqloQL+jNqjppZnhUgJCmcfDLMmlU9/lTV766oyFd7f/qpX5Ys8c0KkW2IpaW+7S+azEwfWMrLoaLS172XlhsXX+zbVg480Ldl9+rlb3v3rg5ABeSSTy55QCCngdxcviop4eC9+cQa7z+HlqAZ5VkBQpJG7fGnwF+9OnCgXyLNmuUvBqq63P2pp/z2GRnVQSEtrbo9NrK9My3NXyBTUeGDzuLFvhtFSUn1++fk+PZu53wJZdw4316ck+Pbq7Ozdx2qay/ubyV7KQUIkSiGDPFBItYTckM1AxUV/irNqoDx4ov+cnzwFwHdfvuu79mhQ3XACIV8eioqfEC58UYf1CK7JrRrV/PCp4ZmDays9JccFxf7q8mKi33padEin4cTT/Qlncj+krUpaLVsChAidWjKdpFQyF+d2LOn784wZEjNKyyfecZ34Vi71o/nWLVUPV6ypLrLQlkZ3HBD9P20bVvdt9GPMt+DyZN9tVZKSnUwqFrqcv/9/tbMB4l27XZdtm/3V6pWVia2s7kERwFCJAHibYusXYX16KP+8vhofdg2bfJdNXwHbKOy0jek9+lT3Wct2u3Mmb4/SlW/sWHD/KDERUU1l2+/9SNOfPNNddDasQN+8hM/53lenu8OEaVjt+xlFCBEEiSeEkpjA0pJSSUZGSk8/XTD2xxyiB+KqapUc8MNsXfiT0nxHZ9ffNEHL/ClpcGDfXrz8nzACLoPaO1qtcrK6lFpot1++KHf5rjjfBtQ1fBlqan19/dLlmo1BQiRvURjAsrkyati7jkebxCKtn5FhR8lIj/fLy+95MefBB8gvv3Wn7RDIV/V1ratr+r6/vvqperx5s0150mvGrOyLhUVVR2we+zcZ6zuvrvmY7PqixEil4oKf4WbCw8ndc45fnSMjh13XTp08KW9ujrAl5b6arrt230JrOr+3Lm+k/Xpp/shthI5VYwChEgLFe2qrVi22Z12l1DID3Ny9NFw1VU1A8ajj/rhmMD/e58+3Z9I99nHL61b+4Cx//7+8fLlfhQTFx4aauBAPzxVXT74wI804pxhVl1yiRxOKfJ25kw/Y6JzvgR02ml+CPvI/i21+7ssWlQ9YkpFhZ8w8qWX6k5TmzY+4FXloU0bv9327Q0PMvzggz4odu/uL5euWrp1q3l/wYL6L0bYHQoQIhKYyICRm7t741DeeWds61dVq/35z/Wv36+fn8yq6v2vu65xw5L17+9LOuvX+8GAI5c33vDbVOnd21dltWq165KZ6cdunDKluh3omGOgc2c/18obb/h2n+iBpQdTpjT9aOIKECKyRzRFFVYs68dardaYTst1bdO5s19qO+WUmgHl3nvr38+BB8LLL1evf9ddNdevmv7lq6/8lChPP+0HuHXOT86Vn68AISJ7qaa8dLiu9eOpVmtMp+UgLy5oaP30dOjRwy/g59F6911fakpPT4lpjqd4KECIiAQoyKDYmIsR4qEAISKyF2vMxQixqqcTvYiIJLNAA4SZnWpmy8xshZmNj/K6mdn94dc/NrOjY91WRESCFViAMLMQ8CAwHOgF/NLMetVabTjQM7yMAR6OY1sREQlQkCWIY4AVzrmVzrlS4HngzFrrnAk8FZ7Y6AOgvZl1jnFbEREJUJCN1F2A1RGPC4GBMazTJcZtATCzMfjSBzk5OeTn5zcqscXFxY3edm+lPLd8yZZfUJ6bUpABItoIIrX7ANa1Tizb+iedmwRMAhgwYIDLa+SFwPn5+TR2272V8tzyJVt+QXluSkEGiEKgW8TjrsCaGNdJj2HbXcyfP3+DmX3ZqNRCR2BDI7fdWynPLV+y5ReU53gdVNcLQQaIuUBPM+sBfA38AvhVrXWmAZeZ2fP4KqQi59w3ZrY+hm134Zzr1NjEmtk859yAxm6/N1KeW75kyy8oz00psADhnCs3s8uAGUAImOycW2xml4RfnwhMB04DVgDfAxfVt21QaRURkV0F2pPaOTcdHwQin5sYcd8Bl8a6rYiI7DnqSV1tUqITkADKc8uXbPkF5bnJmGto1goREUlKKkGIiEhUChAiIhJV0geIZBwU0MxWmdkiM1tgZvMSnZ4gmNlkM1tnZp9EPLefmb1pZsvDt1mJTGNTqyPPN5nZ1+FjvcDMTktkGpuamXUzs1lmtsTMFpvZFeHnW+yxrifPTX6sk7oNIjwo4GfAKfhOe3OBXzrnPk1owgJmZquAAc65FtuZyMxOAIrxY30dEX7uLuA759wd4T8DWc65axKZzqZUR55vAoqdc/ckMm1BCY/d1tk595GZ7QvMB84CLqSFHut68nweTXysk70EoUEBWyjn3Gzgu1pPnwk8Gb7/JP5H1WLUkecWzTn3jXPuo/D9rcAS/FhuLfZY15PnJpfsAaKuwQJbOgfMNLP54cEOk0WOc+4b8D8yIDvB6dlTLgvPtzK5JVW11GZm3YGjgP+QJMe6Vp6hiY91sgeImAcFbGEGOeeOxs+3cWm4akJapoeBHwD9gG+AvyQ0NQExszbAP4CxzrktiU7PnhAlz01+rJM9QMQyoGCL45xbE75dB0zFV7Ulg7Xh+tuqetx1CU5P4Jxza51zFc65SuBRWuCxNrM0/IlyinPun+GnW/SxjpbnII51sgeInQMKmlk6flDAaQlOU6DMrHW4YQszaw0MBT6pf6sWYxpwQfj+BcCrCUzLHlF1kgw7mxZ2rM3MgMeBJc65eyNearHHuq48B3Gsk/oqJoDwpWD3UT0o4J8Tm6JgmdnB+FID+LG4nm2JeTaz54A8/DDIa4EJwCvAi8CBwFfAuc65FtOoW0ee8/BVDg5YBfyuqm6+JTCz44B3gUVAZfjp6/B18i3yWNeT51/SxMc66QOEiIhEl+xVTCIiUgcFCBERiUoBQkREolKAEBGRqBQgREQkKgUIkWbAzPLM7LVEp0MkkgKEiIhEpQAhEgczO9/MPgyPt/+ImYXMrNjM/mJmH5nZ22bWKbxuPzP7IDx42tSqwdPM7Idm9paZLQxv84Pw27cxs5fNbKmZTQn3mBVJGAUIkRiZ2eHACPxgh/2ACmAk0Br4KDwA4jv4HswATwHXOOf64nu9Vj0/BXjQOXck8GP8wGrgR+UcC/QCDgYGBZwlkXqlJjoBInuRk4D+wNzwn/tW+EHgKoEXwus8A/zTzNoB7Z1z74SffxJ4KTwOVhfn3FQA59wOgPD7feicKww/XgB0B94LPFcidVCAEImdAU86566t8aTZDbXWq2/8mvqqjUoi7leg36ckmKqYRGL3NvBzM8uGnfMeH4T/Hf08vM6vgPecc0XAJjM7Pvz8KOCd8Lj9hWZ2Vvg9Msxsnz2ZCZFY6R+KSIycc5+a2f/Dz8aXApQBlwLbgN5mNh8owrdTgB9memI4AKwELgo/Pwp4xMxuDr/HuXswGyIx02iuIrvJzIqdc20SnQ6RpqYqJhERiUolCBERiUolCBERiUoBQkREolKAEBGRqBQgREQkKgUIERGJ6v8DEIXxLEcYFnYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#MNIST 손글씨 인식하기: 컨볼루션 신경망 적용\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import os\n",
    "import tensorflow as tf\n",
    "  \n",
    "# seed 값 설정\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "  \n",
    "# MNIST 데이터 불러오기\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    " \n",
    "X_train = X_train.reshape(X_train.shape[0], 28,28,1).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 28,28,1).astype('float32') / 255\n",
    " \n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "  \n",
    "# 모델 프레임 설정\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# 모델 실행 환경 설정\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  \n",
    "# 모델 최적화 설정\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "  \n",
    "# 모델의 실행\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30, batch_size=200, verbose=0, callbacks=[early_stopping_callback,checkpointer])\n",
    "  \n",
    "# 테스트 정확도 출력\n",
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))\n",
    "  \n",
    "# 테스트셋의 오차\n",
    "y_vloss = history.history['val_loss']\n",
    "  \n",
    "# 학습셋의 오차\n",
    "y_loss = history.history['loss']\n",
    "  \n",
    "# 그래프로 표현\n",
    "x_len = numpy.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "  \n",
    "# 그래프에 그리드를 주고 레이블을 표시\n",
    "plt.legend(loc='upper right')\n",
    "# plt.axis([0, 20, 0, 0.35])\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "#100% 다 맞히지 못한 이유는 데이터 안에 확인할 수 없는 글씨가 있었기 때문임\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb9782f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a454b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a283277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75df653f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09828d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d7719a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1805e922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69581863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c52a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa2ea07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
