#타임아웃 문제해결
elasticsearch.requestTimeout: 90000를 elasticsearch yml파일 아니고 kibana yml파일 맨 아래에 추가

엘라스틱서치 / 관계형 데이터베이스
인덱스            데이터베이스
샤드               파티션
타입               테이블
문서               행
필드               열
매핑               스키마
query DSL       SQL

#자동 매핑 방식을 사용한다고 할 경우 반드시 스키마가 숫자형으로 매핑되었을 경우
 뒤에 TX100같은 데이터가 들어오면 숫자형으로만 이루어진 것이 아니라 오류가 뜨게 됨

PUT movie_search_first
{
  "settings": {
    "number_of_shards": 5,
    "number_of_replicas": 1
  },
  "mappings": {
    "_doc": {
      "properties": {
        "movieCd": {
          "type": "keyword"
        },
        "movieNm": {
          "type": "text",
          "analyzer": "standard"
        },
        "movieNmEn": {
          "type": "text",
          "analyzer": "standard"
        },
        "prdtYear": {
          "type": "integer"
        },
        "openDt": {
          "type": "integer"
        },
        "typeNm": {
          "type": "keyword"
        },
        "prdtStatNm": {
          "type": "keyword"
        },
        "nationAlt": {
          "type" : "keyword"
        },
        "genreAlt": {
          "type": "keyword"
        },
        "repNationNm": {
          "type" : "keyword"
        },
        "repGenreNm" : {
          "type" : "keyword"
        },
        "companies": {
          "properties": {
            "companyCd": {
              "type" : "keyword" 
            }
          }
        },
        "directors" : {
          "properties" : {
            "peopleNm" : {
              "type" : "keyword"
            }
          }
        }
      }
    }
  }
}

GET movie_search_1/_mapping


#아래코드에서 buckets[] 부분이 비어있으면 안됨
POST movie_search/_search
{
  "size":0,
  "aggs": {
    "indices": {
      "terms": {
        "field": "_index",
        "size": 10
      }
    }
  }
}

#이전 엘라스틱서치에선 fielddata라고 하여 힙공간에 메모리 캐시를 생성해서 사용했었으나 
반복적인 메모리 부족 현상과 잦은 GC로 현재는 사용되지 않음.
#현재는 doc_value라는 기본 캐시를 사용
text타입을 제외한 모든 타입에서 기본적으로 해당 캐시를 사용하며 이 캐시는 루씬을 기반으로 함.
과거에는 캐시를 모두 메모리에 올려 사용했으나 현재는 doc_values를 사용함으로써 
힙 사용에 대한 부담을 없애고 운영체제의 파일 시스템 캐시를 통해 디스크에 있는 데이터에 빠르게 접근가능
이로인해 GC의 비용이 들지 않으면서도 메모리 연산과 비슷한 성능을 보임.


POST movie_search/_search
{
  "size":0,
  "aggs": {
    "indices": {
      "terms": {
        "field": "_type",
        "size": 10
      }
    }
  }
}


POST movie_search/_search
{
  "size":0,
  "aggs": {
    "indices": {
      "terms": {
        "field": "_id",
        "size": 10
      }
    }
  }
}


#uid
POST movie_search/_search
{
  "size":0,
  "aggs": {
    "indices": {
      "terms": {
        "field": "_uid",
        "size": 10
      }
    }
  }
}

PUT /reindex_movie

#재색인
POST /_reindex
{
  "source": {
    "index": "movie_search",
    "query": {
      "match": {
        "movieCd": "20173732"
      }
    }
  },
  "dest": {
    "index": "reindex_movie"
  },
  "script": {
    "source": "ctx._source.prdtYear++"
  }
} 
  
POST movie_search/_search
{
  "query": {
    "term": {
      "movieCd": "20173732"
    }
  }
}  

POST reindex_movie/_search
{
  "query": {
    "term": {
      "movieCd": "20173732"
    }
  }
}
#재색인을 한 결과 prdtYear값 sting에 1이 붙여진 것을 확인11


#_routing 메타필드
#_routing 메타필드는 특정 문서를 특정 샤드에 저장하기 위해 사용자가 지정하는 메타필드
#기본적으로 색인을 하면 해당문서는 수식에 따라 문서 id를 이용해 문서가 색인될 샤드 결정
#HASH (document_id) % num_of_shards

#특정문서들을 하나의 샤드에 저장하고 싶을 때
#HASH (_routing) % num_of_shards

PUT movie_routing/_doc/1?routing=ko
{
  "repGenreNm": "한국어",
  "movieNm": "살아남은 아이"
}

POST movie_routing/_doc/_search?routing=ko

#나중에 geo 데이터를 사용할 거라면 long, lat으로 사용하면 안됨 geo_point, geo_shape으로 써야함


#keyword 데이터 타입
PUT movie_search_datatype/_mapping/_doc
{
  "properties": {
    "multiMovieYn": {
      "type": "keyword"
    }
  }
}

#다음의 경우에는 반드시 keyword 데이터 타입사용
#검색시 필터링되는 항목, 정렬이 필요한 항목, 집계해야 하는 항목

#text 데이터 타입
PUT movie_text/_mapping/_doc
{
  "properties": {
    "movieComment": {
      "type": "text"
    }
  }
}

#색인시 지정된 분석기가 칼럼의 데이터를 문자열 데이터로 인식하고 이를 분석
#text 데이터 타입은 전문 검색이 가능함. TEXT 타입으로 데이터를 색인하면 전체 텍스트가 토큰화되어 생성되며 특정 단어를 검색하는것이 가능해짐
#필드에 검색뿐 아니라 정렬이나 집계 연산을 사용해야할 때 text 타입과 keyword 타입을 동시에 갖도록 멀티 필드로 설정할 수 있음

PUT movie_search/_mapping/_doc
{
  "properties": {
    "movieComment": {
      "type": "text",
      "fields": {
        "movieComment_keyword": {
          "type": "keyword"
        }
      }
    }
  }
}

#Array 데이터 타입
# 데이터는 1차원으로 표현되나 2차원으로 존재하는 경우도 있음.이 때 사용 문자열이나 숫자처럼 일반적인 값을 지정할 수도 있지만 객체 형태로도 정의할 수 있음. 한가지 주의할 점은 Array 타입에 PUT 저장되는 값은 모두 같은 타입으로 구성해야 함. 엘라스틱서치에서는 매핑 설정시 Array 타입을 명시적으로 정의하지 않음.
PUT movie_search_datatype/_doc/1
{
  "title": "해리포터와 마법사의 돌",
  "subtitleLang": ["ko", "en"]
}

#엘라스틱 서치는 다양한 숫자 타입 제공
#integer 데이터 타입
PUT movie_text/_mapping/_doc
{
  "properties": {
    "year": {
      "type": "integer"
    }
  }
}  
 
#Date 데이터 타입
#JSON 포맷에서 문자열로 처리됨. 
PUT movie_text/_mapping/_doc
{
  "properties": {
    "date": {
      "type": "date", "format": "yyyy-MM-dd HH:mm:ss"
    }
  }
}

#Range 데이터 타입
#범위가 있는 데이터를 저장할 때 사용
#Ip에 대한 범위도 Range 타입으로 정의 가능
PUT movie_search/datatype/_mapping/_doc
{
  "properties": {
    "showRange": {
      "type": "date_range"
    }
  }
}

#데이터 입력시 showRange에 시작값과 종료값의 범위 지정 가능
PUT movie_search_datatype/_doc/2
{
  "showRange": {
    "gte": "2001-01-01",
    "1te": "2001-12-31"
  }
}

#Boolean 데이터 타입 
PUT movie_text/_mapping/_doc
{
  "properties": {
    "check": {
      "type": "boolean"
    }
  }
}

#Geo_Point 데이터 타입
PUT movie_search_datatype/_mapping/_doc
{
  "properties": {
    "filmLocation": {
      "type": "geo_point"
    }
  }
}

##
PUT movie_search_datatype/_doc/3
{
  "title": "해리포터와 마법사의 돌",
  "filmLocation": {
    "lat": 55.4155828,
    "lon": -1.7081091
  }
}

#IP데이터 타입
#IPv4나 Ipv6지정 가능
PUT movie_search_datatype/_mapping/_doc
{
  "properties": {
    "ipAddr": {
      "type": "ip"
    }
  }
}

##
PUT movie_search_datatype/_doc/4
{
  "ipAddr": "127.0.0.1"
}

#Object 데이터 타입
#문서를 가지는 필드의 데이터타입

PUT movie_search_datatype/_mapping/_doc
{
  "properties": {
    "companies": {
      "properties": {
        "companyName": {
          "type": "text"
        }
      }
    }
  }
}

##데이터 입력시 문서의 계츨 구조에 따라 데이터 입력
PUT movie_search_datatype/_doc/5
{
  "title":"해리포터와 마법사의 돌",
  "companies": {
    "companyName": "워너브라더스"
  }
}

#Nested 데이터 타입
#Object 형식으로 특정 필드 내에 JSON포맷 표현 가능
#필드에서 객체가 배열 형태로도 저장될 수 있음
PUT movie_search_datatype/_doc/6
{
  "title": "해리포터와 마법사의 돌",
  "companies": [
    {
      "companyName": "워너브라더스"
    },{
      "companyName": "Heyday Films"
    }
  ]
}

#데이터가 배열 형태로 저장되면 한 필드 내의 검색은 기본적으로 OR 조건으로 검색됨 이러한 특성 탓에 저장되는 데이터의 구조가 조금만 복잡해지면 결과가 모호해질 수 있음 

##예시
PUT movie_search_datatype/_doc/7
{
  "title": "해리포터와 마법사의 돌",
  "companies": [
    {
      "companyCd": "1",
      "companyName": "워너브라더스"
    },{
      "companyCd": "2",
      "companyName": "Heyday Films"
    }
  ]
}

#검색시 워너브라더스가 회사명이고 Cd가 1일 때는 문서가 잘 검색됨. 회사명이 워너브라더스이고 Cd가 2일 때는 검색결과가 나오지 않을 것이라 예상하지만 실제로 출력됨. 이는 companies 필드의 데이터 타입이 Array이기 때문임. Array 데이터 타입 내부에서의 검색은 모든 데이터를 기준으로 OR 연산이 이뤄짐 

#위의 문제를 해결하기 위해 nested 데이터 타입 고안
#Nested 데이터 타입
PUT movie_search_datatype/_mapping/_doc
{
  "properties": {
    "companies_nested": {
      "type": "nested"
    }
  }
}

#생성된 인덱스에 데이터 색인
PUT movie_search_datatype/_doc/8
{
  "title": "해리포터와 마법사의 돌",
  "companies_nested": [
    {
      "companyCd": "1",
      "companyName": "워너브라더스"
    },{
      "companyCd": "2",
      "companyName": "Heyday Films"
    }
  ]
}

#이전의 문제되던 쿼리 실행
#must가 핵심
POST movie_search_datatype/_search
{
  "query": {
    "nested": {
      "path": "companies_nested",
      "query": {
        "bool": {
          "must": [
            {
              "match": { "companies_nested.companyName": "워너브라더스" }
            }, {
              "match": {"companies_nested.companyCd": "2"}
            }  
          ]
        }
      }
    }
  }
}

#다음과 같이 Nested 데이터 타입을 이용하면 검색할 때 일치하는 문서만 정확하게 출력 가능

#엘라스틱서치 분석기
#"우리나라가 좋은나라, 대한민국 화이팅"
POST _analyze
{
 "analyzer": "standard",
 "text": "우리나라가 좋은나라, 대한민국 화이팅"
}

#역색인 구조
#책을 읽을 때 어떤 단어가 등장하는 페이지를 알지 못할때 맨 마지막에 열거된 부분을 펼쳐 특정단어가 등장하는 페이지를 쉽게 찾아갈 수 있음

#-모든 문서가 가지는 단어의 고유 단어 목록
#-해당 단어가 어떤 문서에 속해있는지에 대한 정보
#-전체 문서에 각 단어가 몇 개 들어있는지에 대한 정보
#-하나의 문서에 단어가 몇번씩 출현했는지에 대한 빈도

#색인을 한다는 것은 역색인 파일을 만든다는것
#그렇다고 원문 자체를 변경한다는 것은 아니고 색인 파일에 들어갈 토큰만 변경되어 저장되고 실제 문서의 내용은 변함없이 저장됨.
#색인할 때 특정 규칙과 흐름에 의해 텍스트를 변경하는 과정을 분석이라고 하고 해당 처리는 분석기라는 모듈을 조합해서 이뤄짐

#분석기의 구조
#1.문장을 특정한 규칙에 의해 수정
#2.수정한 문장을 개별 토큰으로 분리
#3.개별 토큰을 특정한 규칙에 의해 변경

#CHARACTER FILTER
#문장을 분석하기 전에 입력 텍스트에 대해 특정한 단어를 변경하거나 HTML과 같은 태그를 제거하는 필터
#TOKENIZER FILTER
#분석기를 구성할 때 하나만 사용할 수 있으며 텍스트를 어떻게 나눌 것인가 정의.
#TOKEN FILTER
#토큰화된 단어를 하나씩 필터링해서 사용자가 원하는 토큰으로 변환


#<B>Elasticsearch</B> is cool 예시
#간단한 분석기 정의
#html_strip으로 HTML제거
#standard 토크나이저로 특수문자 혹은 공백 기준으로 텍스트 분할(여기서 standard 라는 것은 루씬의 standard analyzer 의미)
#lowercase로 모든 토큰을 소문자로 변환

PUT /movie_analyzer
{
  "settings": {
    "index": {
      "number_of_shards": 5,
      "number_of_replicas":1
    }
  },
  "analysis": {
    "analyzer": {
      "custom_movie_analyzer": {
        "type": "custom",
        "char_filter": [
          "html_strip"
        ],
        "tokenizer": "standard",
        "filter": [
          "lowercase"
        ]
      }
    }
  }
}

#분석기를 이용한 분석
POST _analyze
{
  "analyzer": "standard",
  "text": "캐리비안의 해적"
}

#필드를 이용한 분석
POST movie_analyzer/_analyze
{
  "field": "title",
  "text": "캐리비안의 해적"
}

#색인과 검색시 분석기를 각각 설정
#분석기는 색인할 때 사용되는 index Analyzer와 검색할 때 사용되는 Search Analyzer로 구분해서 구성가능

#
PUT movie_analyzer
{
  "settings": {
    "index": {
      "number_of_shards": 5,
      "number_of_replicas": 1
    },
    "analysis": {
      "analyzer": {
        "movie_lower_test_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase"
          ]
        },
        "movie_stop_test_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "english_stop"
          ]
        }
      },
      "filter": {
        "english_stop": {
          "type": "stop",
          "stopwords": "_english_"
        }
      }
    }
  },
  "mappings": {
    "_doc": {
      "properties": {
        "title": {
          "type": "text",
          "analyzer": "movie_stop_test_analyzer",
          "search_analyzer": "movie_lower_test_analyzer"
        }
      }
    }
  }
}


#문서 색인
PUT movie_analyzer/_doc/1
{
  "title": "Harry Potter and the Chamber of Secrets"
}

#검색
POST movie_analyzer/_search
{
  "query": {
    "query_string": {
      "default_operator": "AND", 
      "query": "Chamber of Secrets"
    }
  }
}

#
POST movie_analyzer/_analyze
{
  "analyzer": "standard",
  "text": "Harry Potter and the Chamber of Secrets"
}
#소문자로 출력

#whitespace 분석기
POST movie_analyzer/_analyze
{
  "analyzer": "whitespace",
  "text": "Harry Potter and the Chamber of Secrets"
}
#대문자로 출력

#keyword 분석기
POST movie_analyzer/_analyze
{
  "analyzer": "keyword",
  "text": "Harry Potter and the Chamber of Secrets"
}

#전처리 필터
PUT movie_html_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "html_strip_analyzer": {
          "tokenizer": "keyword",
          "char_filter": [
            "html_strip_char_filter"
          ]
        }
      },
      "char_filter": {
        "html_strip_char_filter": {
          "type": "html_strip",
          "escaped_tags": [
            "b"
          ]
        }
      }
    }
  }
} 

#확인
POST movie_html_analyzer/_analyze
{
  "analyzer": "html_strip_analyzer",
  "text": "<span>Harry Potter</span> and the <b>Chamber</b> of Secrets"
}

#토크나이저는 필터와 비슷한 또다른 방법임
#토크나이저 필터는 분석기를 구성하는 핵심 구성요소

#standard 토크나이저
POST movie_analyzer/_analyze
{
  "tokenizer": "standard",
  "text": "Harry Potter and the Chamber of Secrets"
}

#whitespace 토크나이저

POST movie_analyzer/_analyze
{
  "tokenizer": "whitespace",
  "text": "Harry Potter and the Chamber of Secrets"
}

#Ngram 토크나이저
PUT movie_ngram_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "ngram_analyzer": {
          "tokenizer": "ngram_tokenizer"
        }
      },
      "tokenizer": {
        "ngram_tokenizer": {
          "type": "ngram",
          "min_gram": 3,
          "max_gram": 3,
          "token_chars": [
            "letter"
          ]
        }
      }
    }
  }
}

##ngram을 이용한 문장분리
POST movie_ngram_analyzer/_analyze
{
  "tokenizer": "ngram_tokenizer",
  "text": "Harry Potter and the Chamber of Secrets"
}

#edge Ngram 토크나이저
#지정된 문자의 목록 중 하나를 만날 대마다 시작 부분을 고정시켜 단어를 자르는 방식으로 사용하는 토크나이저
PUT movie_engram_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "edge_ngram_analyzer": {
          "tokenizer": "edge_ngram_tokenizer"
        }
      },
      "tokenizer": {
        "edge_ngram_tokenizer": {
          "type": "edge_ngram",
          "min_gram": 2,
          "max_gram": 10,
          "token_chars": [
            "letter"
          ]
        }
      }
    }
  }
}


POST movie_engram_analyzer/_analyze
{
  "tokenizer": "edge_ngram_tokenizer",
  "text": "Harry Potter and the Chamber of Secrets"
}

#keyword 토크나이저
POST movie_analyzer/_analyze
{
  "tokenizer": "keyword",
  "text": "Harry Potter and the Chamber of Secrets"
}

#토큰 필터
#토크나이저에서 분리된 토큰들을 변형하거나 추가, 삭제할 대 사용하는 필터로 토크나이저에 의해 토큰이 모두 분리돼야 비로소 동작하기 때문에 독립적으로 사용 불가

#Ascii Folding 토큰 필터
PUT movie_af_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "asciifolding_analyzer": {
          "tokenizer": "standard",
          "filter": [
            "standard",
            "asciifolding"
          ]
        }
      }
    }
  }
}

#Lowercase 토큰필터
PUT movie_lower_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "lowercase_analyzer": {
          "tokenizer": "standard",
          "filter": [
            "lowercase"
          ]
        }
      }
    }
  }
}

POST movie_lower_analyzer/_analyze
{
  "analyzer": "lowercase_analyzer",
  "text": "Harry Potter and the Chamber of Secrets"
}

#Uppercase 토큰필터
PUT movie_upper_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "uppercase_analyzer": {
          "tokenizer": "standard",
          "filter": [
            "uppercase"
          ]
        }
      }
    }
  }
}

POST movie_upper_analyzer/_analyze
{
  "analyzer": "uppercase_analyzer",
  "text": "Harry Potter and the Chamber of Secrets"
}

#Stop 토큰필터
#불용어로 등록할 사전을 구축해서 사용하는 필터
#불용어 사전이 존재하는 경로로 필터사용 가능
PUT movie_stop_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stop_filter_analyzer": {
          "tokenizer": "standard",
          "filter": [
            "standard",
            "stop_filter"
          ]
        }
      },
      "filter": {
        "stop_filter": {
          "type": "stop",
          "stopwords": [
            "and",
            "is",
            "the"
          ]
        }
      }
    }
  }
}

POST movie_stop_analyzer/_analyze
{
  "analyzer": "stop_filter_analyzer",
  "text": "Harry Potter and the Chamber of Secrets"
}

#Stemmer 토큰필터
#stemming 알고리즘을 사용해 토큰을 변형하는 필터
#한글은 지원안함.
PUT movie_stam_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "stemmer_eng_analyzer": {
          "tokenizer": "standard",
          "filter": [
            "standard",
            "lowercase",
            "stemmer_eng_filter"
          ]
        }
      },
      "filter": {
        "stemmer_eng_filter": {
          "type": "stemmer",
          "name": "english"
        }
      }
    }
  }
}

POST movie_stam_analyzer/_analyze
{
  "analyzer": "stemmer_eng_analyzer",
  "text": "Harry Potter and the Chamber of Secrets"
}

#Synonym 토큰 필터
#동의어를 처리할 수 있는 필터
PUT movie_syno_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "synonym_analyzer": {
          "tokenizer" : "whitespace",
          "filter": [
            "synonym_filter"
          ]
        }
      },
      "filter": {
        "synonym_filter": {
          "type": "synonym",
          "synonyms": [
            "Harry => 해리"
          ]
        }
      }
    }
  }
}

POST movie_syno_analyzer/_analyze
{
  "analyzer": "synonym_analyzer",
  "text": "Harry Potter and the Chamber of Secrets"
}

#Trim 토큰 필터
#앞뒤 공백을 제거하는 토큰 필터
PUT movie_trim_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "trim_analyzer": {
          "tokenizer": "keyword",
          "filter": [
            "lowercase",
            "trim"
          ]
        }
      }
    }
  }
}

POST movie_trim_analyzer/_analyze
{
  "analyzer": "trim_analyzer",
  "text": "   Harry Potter and the Chamber of Secrets "
}

#동의어 사전
#등록방식
#1. 동의어를 매핑 설정 정보에 미리 파라미터로 등록하는 방식
#2. 특정파일을 별도로 생성해서 관리하는 방식

#동의어 사전 만들기
#elasticsearch/config/analysis/synonym.txt 파일 생성 및 수정

#"type": "resource_already_exists_exception" 일 경우 
#동의어 치환하기
PUT movie_analyzer_0
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "synonym_analyzer": {
            "tokenizer": "standard",
            "filter": [
              "lowercase",
              "synonym_filter"
            ]
          } 
        },
        "filter": {
          "synonym_filter": {
            "type": "synonym",
            "ignore_case": true,
            "synonyms_path": "C:/elasticsearch-6.4.3/config/analysis/synonym.txt"
          }
        }
      }
    }
  }
}


PUT movie_analyzer
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer"
      }
    }
  }
}


POST movie_analyzer/_analyze
{
  "analyzer": "synonym_analyzer",
  "text": "Elasticsearch Harry Potter"
}

#동의어 수정후 close 했다가 open해서 재시작 해줘야 함
POST movie_analyzer/_close
POST movie_analyzer/_open

