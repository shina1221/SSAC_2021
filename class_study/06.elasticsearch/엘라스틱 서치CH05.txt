#데이터 집계

GET /_cat/indices/apache*?v&pretty

#스냅숏 목록 확인
curl -XGET 'http://localhost:9200/_snapshot/apache-web-log/_all?pretty'
#기본 스냅숏 복구
curl -XPOST 'http://localhost:9200/_snapsho/apache-web-log/default/_restore'

#197p
GET /apache-web-log/_search?size=0
{
  "query": {
    "match_all": {}
  },
  "aggs": {
    "region_count": {
      "terms": {
        "field": "geoip.city_name.keyword",
        "size": 20
      }
    }
  }
}

#합산 집계
#합산 집계는 단일 숫자 메트릭 집계에 해당
GET /apache-web-log/_search?size=0
{
  "aggs": {
    "total_bytes": {
      "sum": {
        "field": "bytes"
      }
    }
  }
}

#필터기능 적용
GET /apache-web-log/_search?size=0
{
  "query": {
    "constant_score": {
      "filter": {
        "match": {"geoip.city_name": "paris"}
      }
    }
  },
  "aggs": {
    "total_bytes": {
      "sum": {
        "field": "bytes"
      }
    }
  }
}


#script 를 사용해 합 연산 수행
GET /apache-web-log/_search?size=0
{
  "query": {
    "constant_score": {
      "filter": {
        "match": {"geoip.city_name": "paris"}
      }
    }
  },
  "aggs": {
    "total_bytes": {
      "sum": {
        "script": {
          "lang": "painless",
          "source": "doc.bytes.value / params.divide_value",
          "params": {
            "divide_value": 1000
          }
        }
      }
    }
  }
}

#기존에는 결과가 428964였는데 422가 됨. 1000으로 나눴을 때 예상했던 값은 428이었는데 422가 됨. 그 이유는 1000으로 나누는 것은 모든 합산 값에 대한 나누기가 아니라 각 문서의 개별적인 값을 1000으로 나눈 것이기 때문에 1000보다 작은 수들은 전부 0이 되었기 때문
#위의 문제를 해결하기 위한 방법
GET /apache-web-log/_search?size=0
{
  "query": {
    "constant_score": {
      "filter": {
        "match": {"geoip.city_name": "paris"}
      }
    }
  },
  "aggs": {
    "total_bytes": {
      "sum": {
        "script": {
          "lang": "painless",
          "source": "doc.bytes.value / (double)params.divide_value",
          "params": {
            "divide_value": 1000
          }
        }
      }
    }
  }
}

#평균 집계
GET /apache-web-log/_search?size=0
{
  "aggs": {
    "avg_bytes": {
      "avg": {
        "field": "bytes"
      }
    }
  }
}

#filter 기능을 사용해 특정 지역에서 유입된 데이터의 합 계산
GET _search?size=0
{
  "query": {
    "constant_score": {
      "filter": {
        "match": {"geoip.city_name": "paris"}
      }
    }
  },
  "aggs": {
    "avg_bytes": {
      "avg": {
        "field": "bytes"
      }
    }
  }
}

#최솟값 집계
GET /apache-web-log/_search?size=0
{
  "aggs": {
    "min_bytes": {
      "min": {
        "field": "bytes"
      }
    }
  }
}

#filter를 사용해 특정 지역에서 유입된 데이터 중 가장 작은 값 추출

GET _search?size=0
{
  "query": {
    "constant_score": {
      "filter": {
        "match": {"geoip.city_name": "paris"}
      }
    }
  },
  "aggs": {
    "min_bytes": {
      "min": {
        "field": "bytes"
      }
    }
  }
}

#최댓값 집계
#단일 매트릭 집계
#서버에 유입된 데이터 중 가장 큰 값 구하기
GET /apache-web-log/_search?size=0
{
  "aggs": {
    "max_bytes": {
      "max": {
        "field": "bytes"
      }
    }
  }
}

#filter를 사용해 특정 지역에서 유입된 데이터 중 가장 큰 값 찾아보기
GET _search?size=0
{
  "query": {
    "constant_score": {
      "filter": {
        "match": {"geoip.city_name": "paris"}
      }
    }
  },
  "aggs": {
    "max_bytes": {
      "max": {
        "field": "bytes"
      }
    }
  }
}

#개수집계
GET /apache-web-log/_search?size=0
{
  "aggs": {
    "bytes_count": {
      "value_count": {
        "field": "bytes"
      }
    }
  }
}

#filter기능을 사용해 특정 지역에서 일어난 사용자요청 횟수 계산
GET _search?size=0
{
  "query": {
    "constant_score": {
      "filter": {
        "match": {"geoip.city_name": "paris"}
      }
    }
  },
  "aggs": {
    "bytes_count": {
      "value_count": {
        "field": "bytes"
      }
    }
  }
}

#통계 집계
GET /apache-web-log/_search?size=0
{
  "aggs": {
    "bytes_stats": {
      "stats": {
        "field": "bytes"
      }
    }
  }
}

#filter를 사용해 특정 지역에 대한 통계 집계
GET _search?size=0
{
  "query": {
    "constant_score": {
      "filter": {
        "match": {"geoip.city_name": "paris"}
      }
    }
  },
  "aggs": {
    "bytes_stats": {
      "stats": {
        "field": "bytes"
      }
    }
  }
}

#확장 통계 집계
GET /apache-web-log/_search?size=0
{
  "aggs": {
    "bytes_extended_stats": {
      "extended_stats": {
        "field": "bytes"
      }
    }
  }
}

#filter 적용
GET /apache-web-log/_search?size=0
{
  "query": {
    "constant_score": {
      "filter": {
        "match": {"geoip.city_name": "paris"}
      }
    }
  },
  "aggs": {
    "bytes_extended_stats": {
      "extended_stats": {
        "field": "bytes"
      }
    }
  }
}

#카디널리티 집계
#단일 숫자 메트릭 집계에 해당. 개수 집합과 유사하게 횟수를 계산하는데 중복된 값은 제외한 고유한 값에 대한 집계를 수행. 하지만 모든 문서에 대해 중복된 값을 집계하는 것은 성능에 큰 영향을 줄 수 있기 대문에 근사치를 통해 집계를 수행
GET /apache-web-log/_search?size=0
{
  "query": {
    "constant_score": {
      "filter": {
        "match": {"geoip.country_name": "United States"}
      }
    }
  },
  "aggs": {
    "us_city_naems": {
      "terms": {
        "field": "geoip.city_name.keyword"
      }
    }
  }
}

#집계된 결과를 살펴보면 미국내에서 요청 수가 가장 많은 도시 순으로 결과가 반환됨. 지금까지의 집계로는 동일한 필드값에 대해서도 집계 연산이 수행되기 때문에 미국내 몇개의 도시에서 유입이 있었는지 확인하기 위해선 다음의 카디널러티 집계 사용
#카디널리티는 근사치를 계산하는 메트릭 집계임/
#데이터가 적은 경우 거의 정확한 결과를 확인할 수 있지만 기본적으로 근사치 계산임.

GET /apache-web-log/_search?size=0
{
  "query": {
    "constant_score": {
      "filter": {
        "match": {"geoip.country_name": "United States"}
      }
    }
  },
  "aggs": {
    "us_cardinality": {
      "cardinality": {
        "field": "geoip.city_name.keyword"
      }
    }
  }
}

#백분위 수 집계
GET /apache-web-log/_search?size=0
{
  "aggs": {
    "bytes_percentiles": {
      "percentiles": {
        "field": "bytes"
      }
    }
  }
}

#
GET /apache-web-log/_search?size=0
{
  "aggs": {
    "bytes_percentiles": {
      "percentiles": {
        "field": "bytes",
        "percents": [
          1,
          5,
          25,
          50,
          75,
          95,
          99
        ]
      }
    }
  }
}

#백분위 수 랭크 집계
GET /apache-web-log/_search?size=0
{
  "aggs": {
    "bytes_percentile_ranks": {
      "percentile_ranks": {
        "field": "bytes",
        "values": [5000,10000]
      }
    }
  }
}

#지형집계
GET /_mapping

#스냅숏 복사
#curl -XPOST "http://localhost:9200/_snapshot/apache-web-log/applied-mapping/_restore" -u elastic:bigdata

#인덱스 정보 확인
GET /_cat/indices/apache*?v&pretty

#매핑 정보 확인
GET /apache-web-log-applied-mapping/_mapping/field/geoip.location

#??
GET /apache-web-log-applied-mapping/_search?size=0
{
  "aggs": {
    "viewport": {
      "geo_bounds": {
        "field": "geoip.location",
        "wrap_longitude": true
      }
    }
  }
}

GET /apache-web-log-applied-mapping/_search?size=0
{
  "query": {
    "constant_score": {
      "filter": {
        "match" : {"geoip.continent_code": "EU"}
      }
    }
  },
  "aggs" : {
    "viewport": {
      "geo_bounds": {
        "field": "geoip.location",
        "wrap_longitude": true
      }
    }
  }
}

#지형중심 집계
GET /apache-web-log-applied-mapping/_search?size=0
{
  "aggs": {
    "centroid": {
      "geo_centroid": {
        "field": "geoip.location"
      }
    }
  }
}

#기타사항
#타임아웃 에러 해결
#글로벌로 적용되는 타임아웃의 기본 정책은(-1) 무제한
PUT _cluster/settings
{
  "transient": {
    "search.default_search_timeout": "100s" #기존에 -1s 일때 계속 타임아웃되서 바꿈
  }
}



#버킷집계

#메트릭을 계산하지 않고 버킷을 생성
#버킷을 생성한다는 것은 집계된 결과 데이터 집합을 메모리에 저장한다는 의미이기 때문에 중첩되는 단계가 깊어질 수록 메모리 사용량은 점점 더 증가해서 성능에 악영향을 줄 수 있음. 버킷수는 search.max_buckets값을 변경해서 조정 가능
#집계 질의 요청시 버킷 크기를 -1(전체대상) 또는 10000 이상의 값을 지정할 경우에는 엘라스틱 서치에서 경고 반환

#범위 집계
#from과 to 속성 지정
#to에 지정한 값은 결과에서 제외

GET /apache-web-log/_search?size=0
{
  "aggs": {
    "bytes_range": {
      "range": {
        "field": "bytes",
        "ranges": [
          {
            "from": 1000,
            "to": 2000
          }
        ]
      }
    }
  }
}

#범위 여러개 지정
GET /apache-web-log/_search?size=0
{
  "aggs": {
    "bytes_range": {
      "range": {
        "field": "bytes",
        "ranges": [
          {
            "to": 1000
          },
          {
            "from": 1000,
            "to": 2000
          },
          {
            "from": 2000,
            "to": 3000
          }          
        ]
      }
    }
  }
}

#key값 지정 가능 
GET /apache-web-log/_search?size=0
{
  "aggs": {
    "bytes_range": {
      "range": {
        "field": "bytes",
        "ranges": [
          {
            "key": "small",
            "to": 1000
          },
          {
            "key": "medium",
            "from": 1000,
            "to": 2000
          },
          {
            "key": "large",
            "from": 2000,
            "to": 3000
          }          
        ]
      }
    }
  }
}

#날짜범위 집계
#범위 집계와 유사하지만 숫자 값을 범위로 사용했던 범위 집계와는 달리 날짜 값을 범위로 집계를 수행
#날짜 형식으로는 엘라스틱서치에서 지원하는 형식만 사용해야 함.
#특정기간 동안 서버로 전달된 요청수를 집계한 것
GET /apache-web-log/_search?size=0
{
  "aggs": {
    "request count with date range": {
      "date_range": {
        "field": "timestamp",
        "ranges": [
          {
            "from": "2015-01-04T05:14:00.000Z",
            "to": "2015-01-04T05:16:00.000Z"
          }
        ]
      }
    }
  }
}

#히스토그램 집계
#지정한 범위 내에서 집계를 수행하는 범위 집계와 달리 지정한 수치가 간격을 나타내고 이 간격의 범위 내에서 집계를 수행
#히스토그램 간격을 10000으로 지정
GET /apache-web-log/_search?size=0
{"aggs": {
  "bytes_histogram": {
    "histogram": {
      "field": "bytes",
      "interval": 10000
      }
    }
  }
}

#문서의 개수가 0인 것도 있으므로 최소문서 수를 설정해 해당 구간 제외 즉 일정 기준을 충족하지 못하면 반환하지 않음
GET /apache-web-log/_search?size=0
{
  "aggs": {
    "bytes_histogram": {
      "histogram": {
        "field": "bytes",
        "interval": 10000,
        "min_doc_count": 1
      }
    }
  }
}

#날짜 히스토그램 집계
#숫자 값을 간격으로 삼아 구간별 집계를 수행한 히스토그램 집계와 달리 분, 시간, 월, 연도를 구간으로 집계를 수행

#분 단위로 얼마만큼의 사용자 유입이 있었는지 확인해보기
GET /apache-web-log/_search?size=0
{
  "aggs": {
    "daily_request_count": {
      "date_histogram": {
        "field": "timestamp",
        "interval": "minute"
      }
    }
  }
}

#질의 시 format 속성으로 반환되는 날짜형식을 변경할 수 있음. 이 때 미리 정의된 형식 내에서 지정해야함.
GET /apache-web-log/_search?size=0
{
 "daily_request_count": {
      "date_histogram": {
        "field": "timestamp",
        "interval": "day",
        "format": "yyyy-MM-dd"
      }
    }
  }
}

#기존 시간은 미국 시간으로 맞춰져 있으므로 한국시간으로 변경해서 시행
#타임존 지원
GET /apache-web-log/_search?size=0
{
  "aggs": {
    "daily_request_count": {
      "date_histogram": {
        "field": "timestamp",
        "interval": "day",
        "time_zone": "+09:00"
      }
    }
  }
}


#타임존과 다르게 offset을 사용해 집계 기준이 되는 날짜 값의 시작 일자 조정 
#예를 들어 결과로 반환되는 날짜값에 3시간을 더하기위해 offset 속성에 +3h 지정
GET apache-web-log/_search?size=0
{
  "aggs": {
    "daily_request_count": {
      "date_histogram": {
        "field": "timestamp",
        "interval": "day",
        "offset": "+3h"
      }
    }
  }
}

#텀즈 집계
#버킷이 동적으로 생성되는 다중 버킷집계로 집계시 지정한 필드에 대해 빈도수가 높은 컴의 순위로 결과가 반환됨.
#아파치 서버로 얼마만큼의 요청이 들어왔는지 국가별 집계
#텀즈 집계의 필드값으로 text와 keyword가 있는데 text 데이터 타입의 경우 형태소 분석기를 통해 분석하는 과정이 항상 동반되기 때문에 반드시 형태소 분석이 필요없는 keyword 데이터 타입을 사용해야만 함.

GET /apache-web-log/_search?size=0
{
  "aggs": {
    "request count by country": {
      "terms": {
        "field": "geoip.country_name.keyword"
      }
    }
  }
}

#집계 수행 후 sum_other_doc_count라는 항목에 집계되지 않은 항목들의 합이 표시됨
#size 속성의 기본값이 10개보다 더 많은 결과를 반환 받기 위해서는 size 값을 지정해야 함.

#집계 수행시 각 샤드에 집계요청을 전달하고 각 샤드는 집계 결과에 대해 정렬을 수행한 자체 뷰를 가지게 됨. 이것들을 병합해서 최종뷰를 만들기 때문에 포함되지 않은 문서가 존재할 경우 집계 결과가 정확하지 않을 수 있음.

#집계시 size를 100으로 했다면 샤드별로 상위 100개의 집계 결과를 반환하게 될 것임.
GET /apache-web-log/_search?size=0
{
  "aggs": {
    "request count by country": {
      "terms": {
        "field": "geoip.country_name.keyword",
        "size": 100
      }
    }
  }
}
#사이즈를 늘리면 그만큼 집계의 정확도가 올라가나 버킷에 더 많은 양의 데이터를 담아야 하기 때문에 메모리 사용량과 결과를 계산하는데 드는 처리비용 또한 증가

#파이프라인 집계
#다른 집계로 생성된 버킷을 참조해서 집계 수행. 집계 도는 중첩된 집계를 통해 생성된 버킷을 사용해 추가적으로 계산 수행. 
#파이프라인 집계를 수행할 대는 buckets_path 파라미터를 사용해 참조할 집계의 경로를 지정함으로써 체인 형식으로 집계 간의 연산이 이뤄짐. 파이프라인 집계는 모든 집계가 완료된 후에 생성된 버킷을 사용하기 때문에 하위 집계를 가질 수는 없짐나 다른 파이프라인 집계와는 다른 buckets_path를 통해 참조하도록 지정할 수 있음. 즉 다른 집계를 통해 생성된 버킷을 사용해 또 다른 집계를 수행.
#파이프라인에는 형제집계와 부모집계가 존재

#형제 집계
#기존 버킷에 추가되는 형태가 아니라 동일 선상의 위치에 새 집계가 생성되는 파이프라인 집계

#아파치 웹 로그에서 분 단위로 합산된 데이터량 중 가장 큰 데이터량을 구하고 싶은경우
#기존에는 date_histogram과 그 하위집계로 sum 집계를 수행해 가장 큰 값을 추출

#파이프라인 집계중 최대버킷 집계를 통해 분 단위 데이터량 합산과 가장 큰 데이터량 구하기
GET /apache-web-log/_search?size=0
{
  "aggs": {
    "histo": {
      "date_histogram": {
        "field": "timestamp",
        "interval": "minute"
      },
      "aggs": {
        "bytes_sum": {
          "sum": {
            "field": "bytes"
          }
        }
      }
    },
    "max_bytes": {
      "max_bucket": {
        "buckets_path": "histo>bytes_sum"
      }
    }
  }
}

#위 예제에서 bucket path에 histo>bytes_sum을 지정해 가장 큰 값을 구할 수 있음. histo는 가장 상위 집계인 date_histogram의 이름이고, bytes_sum은 그 하위 집계인 sum 집계의 이름. 여기서 sum 집계는 결과가 하나만 존재하는 단일 메트릭 집계이기 때문에 집계 이름만으로 참조할 수 있지만 stats와 같은 다중 메트릭 집계의 경우 메트릭명까지 지정해야 함.

#bytes_stats라는 이름의 stats 집계에서 평균 값을 참조하려는 경우 buckets_path에 histo>bytes_stats.avg라고 지정
#date_histogram의 집계명인 histo의 하위 집계로 집계결과 버킷이 생성되었고, 이와 동일한 위치에 max_bytes라는 최대 버킷 집계의 결과도 추가됨. 이처럼 동일한 위치에 새로운 집계 결과가 추가되는 것이 형제집계.

#부모집계
#집계를 통해 생성된 버킷을 사용해 계산을 수행하고, 그 결과를 기존 집계에 반영

#아파치 웹 로그를 통해 수집된 데이터가 시간이 지남에 따라 변화하는 값의 변경폭 추이를 확인하고 싶은 경우 파생 집계를 활용할 수 있음. 
#파생집계는 부모 히스토그램 또는 날짜 히스토그램 집계에서 지정된 메트릭의 파생값을 계산하는 상위 파이프라인 집계
#부모 히스토그램 집계의 측정 항목에 대해 작동하고, 히스토그램 집계에 의한 각 버킷의 집계 값을 비교해서 차이를 계산. 지정된 메트릭은 숫자여야 하고 상위에 해당하는 집계(부모 히스토그램)의 min_doc_count가 0보다 큰 값으로 설정되는 경우 일부 간격이 결과에서 생략될 수가 있기 때문에 min_doc_count 값을 0으로 설정해야 함.
#파생 집계의 경우 선행되는 데이터가 없으면 집계를 수행할 수 없는데, 실제 데이터를 다루다보면 종종 노이즈가 포함되기도 하고, 필요한 필드에 값이 존재하지 않을 수도 있음. 이러한 부분을 갭이라고 함. 쉽게말해 데이터가 존재하지 않는 부분을 의미. 

#갭이 발생한 경우 파이프라인 집계에 원하는 동작을 알리는 메커니즘이 필요. 이러한 역할을 하는것이 갭 정책. 모든 파이프라인 집계에서는 gap_policy 파라미터를 허용.
#skip: 누락된 데이터를 버킷이 존재하지 않는 것으로 간주. 버킷을 건너뛰고 다음으로 사용 가능한 겂을 사용해 계산을 계속해서 수행
#insert_zeros: 누락된 값을 0으로 대체하며 파이프라인 집계 계산은 정상적으로 진행

#
GET /apache-web-log/_search?size=0
{
  "aggs": {
    "histo": {
      "date_histogram": {
        "field": "timestamp",
        "interval": "day"
      },
      "aggs": {
        "bytes_sum": {
          "sum": {
            "field": "bytes"
          }
        },
        "sum_deriv": {
          "derivative": {
            "buckets_path": "bytes_sum"
          }
        }
      }
    }
  }
}

#버킷의 첫번재 집계 결과에는 비교할 이전 데이터가 존재하지 않았기 때문에 파생 집계 결과가 반환되지 않음. 
#버킷의 이전 값인 414~와 현재 집계값인 788~을 비교해서 374~라는 집계결과 반환

#버킷 셀렉터
#현재 버킷을 상위 버킷에 적용해서 유지할지 말지
#True아님 false로 반환

#버킷 스크립트 집계는 추가 필터를 적용하는 거라고 생각하면 됨

