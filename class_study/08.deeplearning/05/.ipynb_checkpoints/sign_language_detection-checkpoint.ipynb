{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영어 수화 알파벳 추론\n",
    "- colab 학습한 모델을 이용해 추론\n",
    "\n",
    "## pre request \n",
    "- tensorflow 설치 \n",
    "- tensorflow object detection api2 설치 (윈도우즈 설치 md 참조)\n",
    "- pip install pyyaml >> labelmap파일 읽어들일때 tensorflow object detection에서 내부적으로 사용하기 때문에 깔아줘야함.\n",
    "\n",
    "## 학습한 컴퓨터에서 (colab) 가져올 것\n",
    "- 학습한 weights: checkpoint 파일들\n",
    "- pipeline.config\n",
    "- label_map.pbtxt\n",
    "- label map 파일: label_map.pbtxt\n",
    "\n",
    "# 경로변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_CONFIG_PATH = 'config/pipeline.config'\n",
    "LABELMAP_FILE_PATH = 'config/label_map.pbtxt'\n",
    "CHECKPOINT_DIR_PATH = 'checkpoint'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#no module named 뜨면 환경변수 잡아주면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt #colab에서는 이미지를 띄울 수 없으므로 사용\n",
    "\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util #labelmap의 내용을 읽어오는 함수\n",
    "from object_detection.utils import visualization_utils as viz_utils #결과를 이미지에 출력하는 모듈\n",
    "from object_detection.utils import config_util #pipeline.config.loading\n",
    "from object_detection.builders import model_builder #pipline.config를 이용해 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델생성 + weight restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config_util' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ff20bcc8c3c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#pipeline.config 읽어오기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mconfigs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_configs_from_pipeline_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPIPELINE_CONFIG_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#config를 이용해 모델생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'config_util' is not defined"
     ]
    }
   ],
   "source": [
    "#pipeline/config를 이용해 model build\n",
    "\n",
    "#pipeline.config 읽어오기\n",
    "configs = config_util.get_configs_from_pipeline_file(PIPELINE_CONFIG_PATH)\n",
    "\n",
    "#config를 이용해 모델생성\n",
    "detection_model = model_builder.build(model_config = configs['model'], is_training=False)\n",
    "#모델 속성만 가져오고 is training은 트레인 가능한 모델로 할거냐는데 우리는 이미 트레인했고 추론만 할거라서 False\n",
    "\n",
    "#생성된 모델의 weight들을 학습한 weight들로 덮어쓰기\n",
    "#학습된 checkpoint(weight)를 loading\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "#기존에 학습한 모델의 weight를 불러와서 model/checkpoint의 가장 마지막 학습 모델에 덮어씀\n",
    "ckpt.restore(os.path.join(CHECK_POINT_PATH, 'ckpt-51')).expect_partial()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# detection 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#추론하는 함수 \n",
    "#tensorflow 모델의 추론 속도를 빠르게 해주는 detector(주의 케라스 모델 대상이 아님)\n",
    "#tf.function\n",
    "def detect_func(image):\n",
    "    \"\"\"\n",
    "  image(tensor)를 받아서 추론 후 그 결과를 반환하는 함수\n",
    "  1. preprocessing \n",
    "  2. predict \n",
    "  3. postprocessing -> 이 결과를 반환\n",
    "    \"\"\"\n",
    "    image, shape = detection_model.preprocess(image)\n",
    "    pred =detection_model.predict(image, shape)\n",
    "    result = detection_model.postprocess(pred, shape)\n",
    "    return resul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Map 파일 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image 로딩 -> tensor변환 - detect_func()이용해서 추론\n",
    "filepath - ''\n",
    "\n",
    "image_np = cv2.cvtColor(cv2.imread(filepath), cv2.COLOR_BGR2RGB)\n",
    "input_tensor = tf.convert_to_tensor(image_np[np.newaxis,...], dtype=tf.float32)\n",
    "print(input_tensor.shape, input_tensor.dtype)\n",
    "pred = detect_func(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pred), pred.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Detection 작업 처리\n",
    "- 이미지 추론\n",
    "- 추론\n",
    "- 추론결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_detections = pred['num_detections']\n",
    "num_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred['detections_boxes'].shape\n",
    "#예측한 100개의 객체, 4개의 속성으로 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#위의 데이터 구조에서 맨앞의 1은 필요없음\n",
    "num_detections = int(pred.pop('num_detections'))\n",
    "num_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = {key:value[0, : num_detections].numpy() for key,value in pred.items()}\n",
    "\n",
    "detections['num_detections']=num_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections['detection_classes'].shape\n",
    "detections['detection_classes']=detections['detection_classes'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confidence.score 물체가 박스에 있을 확률 (객체가 무엇인지는 모르겠으나)\n",
    "detections['detection_scores'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A라는 것\n",
    "detections['detection_classes'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections['detection_boxes'][0]*320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labelmap.pbtxt 파일의 내용 읽어오기\n",
    "category_index = label_map_util.create_category_index_from_labelmap(LABELMAP_FILE_PATH)\n",
    "category_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#검출한 결과를 원본 영상에 그리기(bounding box, class label)\n",
    "MIN_CONF_THRESHOLD = 0.6 #detection_scores(confidence score)가 지정한 값 이상인 bounding box만 그리기\n",
    "#object_detection.utils.visualization_utils.visualize_boxes_and_labels_on_image_array()\n",
    "\n",
    "img = viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np, #원본이미지\n",
    "    detections['detection_boxes'] #bounding box좌표\n",
    "    detections['detection_classes'] +1 #label\n",
    "    #+1한 이유는 기존에 추론한 것으로 A는 0으로 읽기때문 \n",
    "    #근데 카테고리 인덱스는 1부터 시작하기 때문\n",
    "    #굳이 category index시작을 0으로 안한 이유는 0은 배경으로 하기 때문에 반드시 cateogry_index는 이대로 사용해야 하는 것\n",
    "    #post process를 거쳤을 대 0이 A가 되는데 실제 label을 기준으로 찾기 위해 +1\n",
    "    detections['detection_scores'], #confidence score\n",
    "    category_index, #label map\n",
    "    use_normalized_coordinates=True, #bounding box 좌표가 normalized 되었는지 여부\n",
    "    max_boxes_to_draw=5 #이미지위에 최대 몇개의 bounding box를 그릴 것인지 #디폴트는 20\n",
    "    min_score_thresh = MIN_CONF_THRESHOLD #confidence score가 지정한 값 이상인 것만 그리기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_path = '?_detect.jpg'\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)\n",
    "plt.savefig(save_file_path) #저장\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections['detection_scores']\n",
    "detections['detection_classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#강사 ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#라이브러리 import \n",
    "\n",
    "#모델 생성+weight resotre\n",
    "configs = config_util.get_configs_from_pipeline_file(PIPELINE_CONFIG_PATH)\n",
    "#model 설정을 이용해 모델 생성\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "#생성한 모델에 학습한 weight들 resotre\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(CHECKPOINT_DIR_PATH, 'ckpt-51')).expect_partial()\n",
    "\n",
    "#detection 함수 정의\n",
    "def detect_function(image):\n",
    "    #전처리\n",
    "    image, shape = detection_model.preprocess(image)\n",
    "    #추론\n",
    "    pred = detection_model.predict(image, shape)\n",
    "    #후처리                             #추론결과를 넣어야함 \n",
    "    result = detection_model.postprocess(pred, shape)\n",
    "    return result\n",
    "\n",
    "#Label Map 파일 로딩\n",
    "category_index = label_map_util.create_category_index_from_labelmap(LABELMAP_FILE_PATH)\n",
    "#category_index는 뒤에서 시각화 할때 사용\n",
    "\n",
    "#Image Detection 작업 처리\n",
    "\"\"\"\n",
    "-이미지 로딩\n",
    "-추론\n",
    "-추론결과를 시각화\n",
    "\"\"\"\n",
    "test_img = 'test_img/a.jpg'\n",
    "img_np = cv2.cvtColor(cv2.imread(test_img), cv2.COLOR_BGR2RGB)\n",
    "input_tensor = tf.convert_to_tensor(img_np[np.newaxis, ...], dtype=tf.float32)\n",
    "pred = detect_function(input_tensor)\n",
    "#type(pred)\n",
    "\n",
    "num_detections = int(pred.pop('num_detections'))\n",
    "#num_detections\n",
    "\n",
    "detections = {key: value[0, :num_detections].numpy() for key, value in pred.items()}\n",
    "detections['num_detections']=num_detections\n",
    "detections['detections_classes'] = detections['detections_classes'].astype(np.int64) \n",
    "\n",
    "#시각화\n",
    "img = viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    img_np, \n",
    "    detections['detection_boxes'],\n",
    "    detections['detections_classes']+1,\n",
    "    detections['detection_scores'],\n",
    "    category_index,\n",
    "    use_normalized_coordinate=True,\n",
    "    max_boxes_to_draw=5,\n",
    "    min_score_thresh = 0.6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
